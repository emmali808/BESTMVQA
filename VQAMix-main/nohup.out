saved_model_SLAKE/BAN_MEVF
Namespace(RAD_dir='/home/coder/projects/Med-VQA/data_SLAKE', activation='relu', ae_alpha=0.001, ae_model_path='pretrained_ae.pth', alpha=1.0, autoencoder=True, batch_size=32, clip_norm=0.25, dropout=0.5, epochs=80, eps_cnn=1e-05, feat_dim=32, five_fold=False, gamma=2, gpu=0, input=None, lr=0.03, maml=True, maml_model_path='pretrained_maml.pth', model='BAN', momentum_cnn=0.05, num_hid=1024, num_stacks=2, op='c', output='saved_model_SLAKE/BAN_MEVF', pow=2, print_interval=40, qc_model_path='./saved_models/QC/rad_best.pth', question_len=12, record_id=None, rescale_factor=1.5, rnn='LSTM', seed=3, tfidf=True, update_freq='1', use_RAD=True, use_ablation=False, use_ablation_q=False, use_ablation_v=False, use_counter=False, use_grad_cam=False, use_kl_mix=False, use_mix=True, use_mix_all=False, use_mix_cond=True, use_mix_cond_q=True, use_mix_cond_v=False, use_mix_cond_vq_in=False, use_mix_cond_vq_union=False, use_partial_label=False, use_rescale=False, use_sep_mix=False)
loading dictionary from /home/coder/projects/Med-VQA/data_SLAKE/dictionary.pkl
loading MAML image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images84x84.pkl
loading DAE image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images128x128.pkl
loading MAML image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images84x84.pkl
loading DAE image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images128x128.pkl
load initial weights MAML from: /home/coder/projects/Med-VQA/data_SLAKE/pretrained_maml.pth
load initial weights DAE from: /home/coder/projects/Med-VQA/data_SLAKE/pretrained_ae.pth
loading dictionary from /home/coder/projects/Med-VQA/data_SLAKE/dictionary.pkl
Loading embedding tfidf and weights from file
Load embedding tfidf and weights from file successfully
Namespace(RAD_dir='/home/coder/projects/Med-VQA/data_SLAKE', activation='relu', ae_alpha=0.001, ae_model_path='pretrained_ae.pth', alpha=1.0, autoencoder=True, batch_size=32, clip_norm=0.25, device=device(type='cuda', index=0), dropout=0.5, epochs=80, eps_cnn=1e-05, feat_dim=64, five_fold=False, gamma=2, gpu=0, input=None, lr=0.03, maml=True, maml_model_path='pretrained_maml.pth', model='BAN', momentum_cnn=0.05, num_hid=1024, num_stacks=2, op='c', output='saved_model_SLAKE/BAN_MEVF', pow=2, print_interval=40, qc_model_path='./saved_models/QC/rad_best.pth', question_len=12, record_id=None, rescale_factor=1.5, rnn='LSTM', seed=3, tfidf=True, update_freq='1', use_RAD=True, use_ablation=False, use_ablation_q=False, use_ablation_v=False, use_counter=False, use_grad_cam=False, use_kl_mix=False, use_mix=True, use_mix_all=False, use_mix_cond=True, use_mix_cond_q=True, use_mix_cond_v=False, use_mix_cond_vq_in=False, use_mix_cond_vq_union=False, use_partial_label=False, use_rescale=False, use_sep_mix=False)
nParams=	18691591
optim: adamax lr=0.0300, decay_step=3, decay_rate=0.75, grad_clip=0.25
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'language_model.WordEmbedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Iter: 40, Loss 0.041143, Num updates: 40, Wall time: 8.50, ETA: 0m 7s (- 0m 29s)
Iter: 80, Loss 0.026333, Num updates: 80, Wall time: 14.77, ETA: 0m 14s (- 0m 19s)
Iter: 120, Loss 0.021228, Num updates: 120, Wall time: 20.72, ETA: 0m 19s (- 0m 11s)
Iter: 160, Loss 0.018637, Num updates: 160, Wall time: 26.75, ETA: 0m 25s (- 0m 4s)
Evaluating...
epoch 0, time: 74.89
	train_loss: 0.0176, score: 16.48
Traceback (most recent call last):
  File "main.py", line 214, in <module>
    train(args, model, train_loader, eval_loader, args.epochs, args.output, optim, epoch, qc_model)
  File "/home/coder/projects/VQAMix-main/train.py", line 117, in train
    cursor.execute(sql)
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/pymysql/cursors.py", line 158, in execute
    result = self._query(query)
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/pymysql/cursors.py", line 325, in _query
    conn.query(q)
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/pymysql/connections.py", line 549, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/pymysql/connections.py", line 779, in _read_query_result
    result.read()
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/pymysql/connections.py", line 1157, in read
    first_packet = self.connection._read_packet()
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/pymysql/connections.py", line 729, in _read_packet
    packet.raise_for_error()
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/pymysql/protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/pymysql/err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.OperationalError: (1054, "Unknown column 'None' in 'field list'")
saved_model_SLAKE/BAN_MEVF
Namespace(RAD_dir='/home/coder/projects/Med-VQA/data_SLAKE', activation='relu', ae_alpha=0.001, ae_model_path='pretrained_ae.pth', alpha=1.0, autoencoder=True, batch_size=32, clip_norm=0.25, dropout=0.5, epochs=80, eps_cnn=1e-05, feat_dim=32, five_fold=False, gamma=2, gpu=0, input=None, lr=0.03, maml=True, maml_model_path='pretrained_maml.pth', model='BAN', momentum_cnn=0.05, num_hid=1024, num_stacks=2, op='c', output='saved_model_SLAKE/BAN_MEVF', pow=2, print_interval=40, qc_model_path='./saved_models/QC/rad_best.pth', question_len=12, record_id=None, rescale_factor=1.5, rnn='LSTM', seed=3, tfidf=True, update_freq='1', use_RAD=True, use_ablation=False, use_ablation_q=False, use_ablation_v=False, use_counter=False, use_grad_cam=False, use_kl_mix=False, use_mix=True, use_mix_all=False, use_mix_cond=True, use_mix_cond_q=True, use_mix_cond_v=False, use_mix_cond_vq_in=False, use_mix_cond_vq_union=False, use_partial_label=False, use_rescale=False, use_sep_mix=False)
loading dictionary from /home/coder/projects/Med-VQA/data_SLAKE/dictionary.pkl
loading MAML image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images84x84.pkl
loading DAE image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images128x128.pkl
loading MAML image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images84x84.pkl
loading DAE image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images128x128.pkl
load initial weights MAML from: /home/coder/projects/Med-VQA/data_SLAKE/pretrained_maml.pth
load initial weights DAE from: /home/coder/projects/Med-VQA/data_SLAKE/pretrained_ae.pth
loading dictionary from /home/coder/projects/Med-VQA/data_SLAKE/dictionary.pkl
Loading embedding tfidf and weights from file
Load embedding tfidf and weights from file successfully
Namespace(RAD_dir='/home/coder/projects/Med-VQA/data_SLAKE', activation='relu', ae_alpha=0.001, ae_model_path='pretrained_ae.pth', alpha=1.0, autoencoder=True, batch_size=32, clip_norm=0.25, device=device(type='cuda', index=0), dropout=0.5, epochs=80, eps_cnn=1e-05, feat_dim=64, five_fold=False, gamma=2, gpu=0, input=None, lr=0.03, maml=True, maml_model_path='pretrained_maml.pth', model='BAN', momentum_cnn=0.05, num_hid=1024, num_stacks=2, op='c', output='saved_model_SLAKE/BAN_MEVF', pow=2, print_interval=40, qc_model_path='./saved_models/QC/rad_best.pth', question_len=12, record_id=None, rescale_factor=1.5, rnn='LSTM', seed=3, tfidf=True, update_freq='1', use_RAD=True, use_ablation=False, use_ablation_q=False, use_ablation_v=False, use_counter=False, use_grad_cam=False, use_kl_mix=False, use_mix=True, use_mix_all=False, use_mix_cond=True, use_mix_cond_q=True, use_mix_cond_v=False, use_mix_cond_vq_in=False, use_mix_cond_vq_union=False, use_partial_label=False, use_rescale=False, use_sep_mix=False)
nParams=	18691591
optim: adamax lr=0.0300, decay_step=3, decay_rate=0.75, grad_clip=0.25
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'language_model.WordEmbedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Iter: 40, Loss 0.041143, Num updates: 40, Wall time: 8.90, ETA: 0m 8s (- 0m 31s)
Iter: 80, Loss 0.026333, Num updates: 80, Wall time: 13.90, ETA: 0m 13s (- 0m 18s)
Iter: 120, Loss 0.021228, Num updates: 120, Wall time: 19.32, ETA: 0m 18s (- 0m 10s)
Iter: 160, Loss 0.018637, Num updates: 160, Wall time: 24.75, ETA: 0m 24s (- 0m 4s)
Evaluating...
epoch 0, time: 67.39
	train_loss: 0.0176, score: 16.48
Traceback (most recent call last):
  File "main.py", line 214, in <module>
    train(args, model, train_loader, eval_loader, args.epochs, args.output, optim, epoch, qc_model)
  File "/home/coder/projects/VQAMix-main/train.py", line 117, in train
    cursor.execute(sql)
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/pymysql/cursors.py", line 158, in execute
    result = self._query(query)
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/pymysql/cursors.py", line 325, in _query
    conn.query(q)
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/pymysql/connections.py", line 549, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/pymysql/connections.py", line 779, in _read_query_result
    result.read()
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/pymysql/connections.py", line 1157, in read
    first_packet = self.connection._read_packet()
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/pymysql/connections.py", line 729, in _read_packet
    packet.raise_for_error()
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/pymysql/protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/pymysql/err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.OperationalError: (1054, "Unknown column 'None' in 'field list'")
saved_model_SLAKE/BAN_MEVF
Namespace(RAD_dir='/home/coder/projects/Med-VQA/data_SLAKE', activation='relu', ae_alpha=0.001, ae_model_path='pretrained_ae.pth', alpha=1.0, autoencoder=True, batch_size=32, clip_norm=0.25, dropout=0.5, epochs=80, eps_cnn=1e-05, feat_dim=32, five_fold=False, gamma=2, gpu=0, input=None, lr=0.03, maml=True, maml_model_path='pretrained_maml.pth', model='BAN', momentum_cnn=0.05, num_hid=1024, num_stacks=2, op='c', output='saved_model_SLAKE/BAN_MEVF', pow=2, print_interval=40, qc_model_path='./saved_models/QC/rad_best.pth', question_len=12, record_id=2, rescale_factor=1.5, rnn='LSTM', seed=3, tfidf=True, update_freq='1', use_RAD=True, use_ablation=False, use_ablation_q=False, use_ablation_v=False, use_counter=False, use_grad_cam=False, use_kl_mix=False, use_mix=True, use_mix_all=False, use_mix_cond=True, use_mix_cond_q=True, use_mix_cond_v=False, use_mix_cond_vq_in=False, use_mix_cond_vq_union=False, use_partial_label=False, use_rescale=False, use_sep_mix=False)
loading dictionary from /home/coder/projects/Med-VQA/data_SLAKE/dictionary.pkl
loading MAML image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images84x84.pkl
loading DAE image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images128x128.pkl
loading MAML image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images84x84.pkl
loading DAE image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images128x128.pkl
load initial weights MAML from: /home/coder/projects/Med-VQA/data_SLAKE/pretrained_maml.pth
load initial weights DAE from: /home/coder/projects/Med-VQA/data_SLAKE/pretrained_ae.pth
loading dictionary from /home/coder/projects/Med-VQA/data_SLAKE/dictionary.pkl
Loading embedding tfidf and weights from file
Load embedding tfidf and weights from file successfully
Namespace(RAD_dir='/home/coder/projects/Med-VQA/data_SLAKE', activation='relu', ae_alpha=0.001, ae_model_path='pretrained_ae.pth', alpha=1.0, autoencoder=True, batch_size=32, clip_norm=0.25, device=device(type='cuda', index=0), dropout=0.5, epochs=80, eps_cnn=1e-05, feat_dim=64, five_fold=False, gamma=2, gpu=0, input=None, lr=0.03, maml=True, maml_model_path='pretrained_maml.pth', model='BAN', momentum_cnn=0.05, num_hid=1024, num_stacks=2, op='c', output='saved_model_SLAKE/BAN_MEVF', pow=2, print_interval=40, qc_model_path='./saved_models/QC/rad_best.pth', question_len=12, record_id=2, rescale_factor=1.5, rnn='LSTM', seed=3, tfidf=True, update_freq='1', use_RAD=True, use_ablation=False, use_ablation_q=False, use_ablation_v=False, use_counter=False, use_grad_cam=False, use_kl_mix=False, use_mix=True, use_mix_all=False, use_mix_cond=True, use_mix_cond_q=True, use_mix_cond_v=False, use_mix_cond_vq_in=False, use_mix_cond_vq_union=False, use_partial_label=False, use_rescale=False, use_sep_mix=False)
nParams=	18691591
optim: adamax lr=0.0300, decay_step=3, decay_rate=0.75, grad_clip=0.25
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'language_model.WordEmbedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Iter: 40, Loss 0.041049, Num updates: 40, Wall time: 5.22, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.026280, Num updates: 80, Wall time: 8.74, ETA: 0m 8s (- 0m 11s)
Iter: 120, Loss 0.021176, Num updates: 120, Wall time: 12.42, ETA: 0m 11s (- 0m 6s)
Iter: 160, Loss 0.018576, Num updates: 160, Wall time: 15.78, ETA: 0m 15s (- 0m 2s)
Evaluating...
epoch 0, time: 38.70
	train_loss: 0.0175, score: 16.63
	eval score: 4.10 (15.69)
Iter: 40, Loss 0.009808, Num updates: 40, Wall time: 45.73, ETA: 0m 4s (- 0m 18s)
Iter: 80, Loss 0.009943, Num updates: 80, Wall time: 49.26, ETA: 0m 8s (- 0m 11s)
Iter: 120, Loss 0.009952, Num updates: 120, Wall time: 52.51, ETA: 0m 11s (- 0m 6s)
Iter: 160, Loss 0.009931, Num updates: 160, Wall time: 55.90, ETA: 0m 14s (- 0m 2s)
Evaluating...
epoch 1, time: 40.39
	train_loss: 0.0099, score: 20.59
	eval score: 6.09 (15.69)
Iter: 40, Loss 0.009013, Num updates: 40, Wall time: 89.00, ETA: 0m 5s (- 0m 21s)
Iter: 80, Loss 0.009146, Num updates: 80, Wall time: 93.59, ETA: 0m 10s (- 0m 14s)
Iter: 120, Loss 0.009088, Num updates: 120, Wall time: 98.18, ETA: 0m 14s (- 0m 8s)
Iter: 160, Loss 0.008939, Num updates: 160, Wall time: 101.88, ETA: 0m 18s (- 0m 3s)
Evaluating...
epoch 2, time: 42.50
	train_loss: 0.0090, score: 22.64
	eval score: 7.85 (15.69)
Iter: 40, Loss 0.008311, Num updates: 40, Wall time: 132.21, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.008345, Num updates: 80, Wall time: 135.82, ETA: 0m 8s (- 0m 11s)
Iter: 120, Loss 0.008335, Num updates: 120, Wall time: 139.41, ETA: 0m 11s (- 0m 6s)
Iter: 160, Loss 0.008333, Num updates: 160, Wall time: 142.96, ETA: 0m 15s (- 0m 2s)
Evaluating...
epoch 3, time: 39.28
	train_loss: 0.0083, score: 22.94
	eval score: 8.89 (15.69)
Iter: 40, Loss 0.007659, Num updates: 40, Wall time: 173.24, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.007847, Num updates: 80, Wall time: 176.92, ETA: 0m 8s (- 0m 11s)
Iter: 120, Loss 0.007878, Num updates: 120, Wall time: 180.46, ETA: 0m 11s (- 0m 6s)
Iter: 160, Loss 0.007892, Num updates: 160, Wall time: 184.01, ETA: 0m 15s (- 0m 2s)
Evaluating...
epoch 4, time: 36.30
	train_loss: 0.0079, score: 23.04
	eval score: 8.65 (15.69)
Iter: 40, Loss 0.007522, Num updates: 40, Wall time: 209.38, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.007583, Num updates: 80, Wall time: 212.50, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.007642, Num updates: 120, Wall time: 215.96, ETA: 0m 10s (- 0m 6s)
Iter: 160, Loss 0.007603, Num updates: 160, Wall time: 219.35, ETA: 0m 14s (- 0m 2s)
Evaluating...
epoch 5, time: 35.17
	train_loss: 0.0076, score: 24.35
	eval score: 9.20 (15.69)
Iter: 40, Loss 0.007376, Num updates: 40, Wall time: 246.44, ETA: 0m 4s (- 0m 18s)
Iter: 80, Loss 0.007321, Num updates: 80, Wall time: 249.98, ETA: 0m 8s (- 0m 11s)
Iter: 120, Loss 0.007371, Num updates: 120, Wall time: 253.14, ETA: 0m 11s (- 0m 6s)
Iter: 160, Loss 0.007368, Num updates: 160, Wall time: 256.60, ETA: 0m 14s (- 0m 2s)
Evaluating...
epoch 6, time: 34.44
	train_loss: 0.0074, score: 23.96
	eval score: 9.08 (15.69)
Iter: 40, Loss 0.007183, Num updates: 40, Wall time: 280.84, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.007262, Num updates: 80, Wall time: 283.90, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.007236, Num updates: 120, Wall time: 286.87, ETA: 0m 10s (- 0m 6s)
Iter: 160, Loss 0.007218, Num updates: 160, Wall time: 290.00, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 7, time: 32.43
	train_loss: 0.0072, score: 23.95
	eval score: 9.66 (15.69)
Iter: 40, Loss 0.006912, Num updates: 40, Wall time: 314.75, ETA: 0m 4s (- 0m 15s)
Iter: 80, Loss 0.006973, Num updates: 80, Wall time: 317.68, ETA: 0m 7s (- 0m 9s)
Iter: 120, Loss 0.007003, Num updates: 120, Wall time: 320.77, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.007018, Num updates: 160, Wall time: 324.06, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 8, time: 34.51
	train_loss: 0.0071, score: 25.03
	eval score: 9.88 (15.69)
Iter: 40, Loss 0.006772, Num updates: 40, Wall time: 351.16, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.006857, Num updates: 80, Wall time: 354.42, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.006879, Num updates: 120, Wall time: 357.58, ETA: 0m 10s (- 0m 6s)
Iter: 160, Loss 0.006872, Num updates: 160, Wall time: 360.88, ETA: 0m 14s (- 0m 2s)
Evaluating...
epoch 9, time: 34.33
	train_loss: 0.0069, score: 24.65
	eval score: 10.03 (15.69)
Iter: 40, Loss 0.006732, Num updates: 40, Wall time: 387.33, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.006762, Num updates: 80, Wall time: 390.72, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.006788, Num updates: 120, Wall time: 394.08, ETA: 0m 11s (- 0m 6s)
Iter: 160, Loss 0.006776, Num updates: 160, Wall time: 397.43, ETA: 0m 14s (- 0m 2s)
Evaluating...
epoch 10, time: 34.31
	train_loss: 0.0068, score: 25.43
	eval score: 10.34 (15.69)
Iter: 40, Loss 0.006548, Num updates: 40, Wall time: 423.30, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.006674, Num updates: 80, Wall time: 426.61, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.006664, Num updates: 120, Wall time: 430.01, ETA: 0m 11s (- 0m 6s)
Iter: 160, Loss 0.006667, Num updates: 160, Wall time: 433.35, ETA: 0m 14s (- 0m 2s)
Evaluating...
epoch 11, time: 35.06
	train_loss: 0.0067, score: 25.92
	eval score: 10.74 (15.69)
Iter: 40, Loss 0.006386, Num updates: 40, Wall time: 460.18, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.006469, Num updates: 80, Wall time: 463.80, ETA: 0m 8s (- 0m 11s)
Iter: 120, Loss 0.006496, Num updates: 120, Wall time: 466.99, ETA: 0m 11s (- 0m 6s)
Iter: 160, Loss 0.006540, Num updates: 160, Wall time: 470.49, ETA: 0m 14s (- 0m 2s)
Evaluating...
epoch 12, time: 35.33
	train_loss: 0.0066, score: 26.29
	eval score: 10.99 (15.69)
Iter: 40, Loss 0.006402, Num updates: 40, Wall time: 497.74, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.006541, Num updates: 80, Wall time: 501.67, ETA: 0m 8s (- 0m 11s)
Iter: 120, Loss 0.006537, Num updates: 120, Wall time: 505.03, ETA: 0m 11s (- 0m 6s)
Iter: 160, Loss 0.006516, Num updates: 160, Wall time: 508.70, ETA: 0m 15s (- 0m 2s)
Evaluating...
epoch 13, time: 35.42
	train_loss: 0.0066, score: 26.64
	eval score: 10.93 (15.69)
Iter: 40, Loss 0.006176, Num updates: 40, Wall time: 533.74, ETA: 0m 4s (- 0m 18s)
Iter: 80, Loss 0.006293, Num updates: 80, Wall time: 537.39, ETA: 0m 8s (- 0m 11s)
Iter: 120, Loss 0.006388, Num updates: 120, Wall time: 540.54, ETA: 0m 11s (- 0m 6s)
Iter: 160, Loss 0.006407, Num updates: 160, Wall time: 543.98, ETA: 0m 15s (- 0m 2s)
Evaluating...
epoch 14, time: 36.30
	train_loss: 0.0064, score: 27.42
	eval score: 10.95 (15.69)
Iter: 40, Loss 0.006158, Num updates: 40, Wall time: 570.41, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.006314, Num updates: 80, Wall time: 573.57, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.006321, Num updates: 120, Wall time: 576.77, ETA: 0m 11s (- 0m 6s)
Iter: 160, Loss 0.006320, Num updates: 160, Wall time: 580.04, ETA: 0m 14s (- 0m 2s)
Evaluating...
epoch 15, time: 34.94
	train_loss: 0.0064, score: 27.64
	eval score: 11.00 (15.69)
Iter: 40, Loss 0.006200, Num updates: 40, Wall time: 607.00, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.006260, Num updates: 80, Wall time: 610.53, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.006287, Num updates: 120, Wall time: 613.95, ETA: 0m 11s (- 0m 6s)
Iter: 160, Loss 0.006310, Num updates: 160, Wall time: 617.41, ETA: 0m 14s (- 0m 2s)
Evaluating...
epoch 16, time: 33.64
	train_loss: 0.0063, score: 27.21
	eval score: 11.12 (15.69)
Iter: 40, Loss 0.006069, Num updates: 40, Wall time: 642.56, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.006134, Num updates: 80, Wall time: 645.97, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.006211, Num updates: 120, Wall time: 649.10, ETA: 0m 11s (- 0m 6s)
Iter: 160, Loss 0.006221, Num updates: 160, Wall time: 652.38, ETA: 0m 14s (- 0m 2s)
Evaluating...
epoch 17, time: 32.02
	train_loss: 0.0063, score: 26.39
	eval score: 11.45 (15.69)
Iter: 40, Loss 0.006003, Num updates: 40, Wall time: 676.47, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.006082, Num updates: 80, Wall time: 679.74, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.006153, Num updates: 120, Wall time: 682.83, ETA: 0m 11s (- 0m 6s)
Iter: 160, Loss 0.006167, Num updates: 160, Wall time: 686.11, ETA: 0m 14s (- 0m 2s)
Evaluating...
epoch 18, time: 37.35
	train_loss: 0.0062, score: 27.81
	eval score: 11.48 (15.69)
Iter: 40, Loss 0.005915, Num updates: 40, Wall time: 715.43, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.005972, Num updates: 80, Wall time: 719.07, ETA: 0m 8s (- 0m 11s)
Iter: 120, Loss 0.006039, Num updates: 120, Wall time: 722.42, ETA: 0m 11s (- 0m 6s)
Iter: 160, Loss 0.006096, Num updates: 160, Wall time: 725.85, ETA: 0m 14s (- 0m 2s)
Evaluating...
epoch 19, time: 42.42
	train_loss: 0.0061, score: 26.92
	eval score: 11.64 (15.69)
Iter: 40, Loss 0.005877, Num updates: 40, Wall time: 760.95, ETA: 0m 5s (- 0m 19s)
Iter: 80, Loss 0.006005, Num updates: 80, Wall time: 764.63, ETA: 0m 8s (- 0m 12s)
Iter: 120, Loss 0.006055, Num updates: 120, Wall time: 767.84, ETA: 0m 12s (- 0m 6s)
Iter: 160, Loss 0.006067, Num updates: 160, Wall time: 771.28, ETA: 0m 15s (- 0m 2s)
Evaluating...
epoch 20, time: 37.00
	train_loss: 0.0061, score: 27.77
	eval score: 11.60 (15.69)
Iter: 40, Loss 0.005882, Num updates: 40, Wall time: 797.48, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.005968, Num updates: 80, Wall time: 800.66, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.006003, Num updates: 120, Wall time: 803.97, ETA: 0m 10s (- 0m 6s)
Iter: 160, Loss 0.006014, Num updates: 160, Wall time: 807.62, ETA: 0m 14s (- 0m 2s)
Evaluating...
epoch 21, time: 37.74
	train_loss: 0.0060, score: 28.98
	eval score: 11.60 (15.69)
Iter: 40, Loss 0.005912, Num updates: 40, Wall time: 836.23, ETA: 0m 5s (- 0m 19s)
Iter: 80, Loss 0.005893, Num updates: 80, Wall time: 840.03, ETA: 0m 9s (- 0m 12s)
Iter: 120, Loss 0.005909, Num updates: 120, Wall time: 843.94, ETA: 0m 12s (- 0m 7s)
Iter: 160, Loss 0.005951, Num updates: 160, Wall time: 847.66, ETA: 0m 16s (- 0m 2s)
Evaluating...
epoch 22, time: 40.67
	train_loss: 0.0060, score: 28.24
	eval score: 11.08 (15.69)
Iter: 40, Loss 0.005770, Num updates: 40, Wall time: 876.73, ETA: 0m 4s (- 0m 18s)
Iter: 80, Loss 0.005839, Num updates: 80, Wall time: 880.28, ETA: 0m 8s (- 0m 11s)
Iter: 120, Loss 0.005884, Num updates: 120, Wall time: 883.58, ETA: 0m 11s (- 0m 6s)
Iter: 160, Loss 0.005904, Num updates: 160, Wall time: 886.78, ETA: 0m 14s (- 0m 2s)
Evaluating...
epoch 23, time: 37.10
	train_loss: 0.0060, score: 28.07
	eval score: 11.70 (15.69)
Iter: 40, Loss 0.005712, Num updates: 40, Wall time: 915.01, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.005817, Num updates: 80, Wall time: 918.82, ETA: 0m 8s (- 0m 11s)
Iter: 120, Loss 0.005860, Num updates: 120, Wall time: 922.00, ETA: 0m 11s (- 0m 6s)
Iter: 160, Loss 0.005873, Num updates: 160, Wall time: 925.38, ETA: 0m 14s (- 0m 2s)
Evaluating...
epoch 24, time: 46.04
	train_loss: 0.0059, score: 28.24
	eval score: 11.54 (15.69)
Iter: 40, Loss 0.005689, Num updates: 40, Wall time: 963.46, ETA: 0m 6s (- 0m 24s)
Iter: 80, Loss 0.005781, Num updates: 80, Wall time: 968.92, ETA: 0m 11s (- 0m 16s)
Iter: 120, Loss 0.005798, Num updates: 120, Wall time: 973.74, ETA: 0m 16s (- 0m 9s)
Iter: 160, Loss 0.005813, Num updates: 160, Wall time: 977.33, ETA: 0m 20s (- 0m 3s)
Evaluating...
epoch 25, time: 39.74
	train_loss: 0.0059, score: 29.03
	eval score: 11.74 (15.69)
Iter: 40, Loss 0.005698, Num updates: 40, Wall time: 1002.62, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.005770, Num updates: 80, Wall time: 1006.53, ETA: 0m 8s (- 0m 11s)
Iter: 120, Loss 0.005816, Num updates: 120, Wall time: 1009.91, ETA: 0m 11s (- 0m 6s)
Iter: 160, Loss 0.005786, Num updates: 160, Wall time: 1013.27, ETA: 0m 15s (- 0m 2s)
Evaluating...
epoch 26, time: 35.12
	train_loss: 0.0058, score: 28.81
	eval score: 11.77 (15.69)
Iter: 40, Loss 0.005563, Num updates: 40, Wall time: 1039.68, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.005670, Num updates: 80, Wall time: 1042.90, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.005750, Num updates: 120, Wall time: 1046.33, ETA: 0m 11s (- 0m 6s)
Iter: 160, Loss 0.005753, Num updates: 160, Wall time: 1049.78, ETA: 0m 14s (- 0m 2s)
Evaluating...
epoch 27, time: 35.02
	train_loss: 0.0058, score: 30.10
	eval score: 11.98 (15.69)
Iter: 40, Loss 0.005550, Num updates: 40, Wall time: 1076.50, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.005664, Num updates: 80, Wall time: 1079.80, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.005703, Num updates: 120, Wall time: 1083.09, ETA: 0m 11s (- 0m 6s)
Iter: 160, Loss 0.005742, Num updates: 160, Wall time: 1086.21, ETA: 0m 14s (- 0m 2s)
Evaluating...
epoch 28, time: 35.17
	train_loss: 0.0058, score: 28.88
	eval score: 11.88 (15.69)
Iter: 40, Loss 0.005572, Num updates: 40, Wall time: 1111.96, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.005679, Num updates: 80, Wall time: 1115.45, ETA: 0m 8s (- 0m 11s)
Iter: 120, Loss 0.005683, Num updates: 120, Wall time: 1118.85, ETA: 0m 11s (- 0m 6s)
Iter: 160, Loss 0.005706, Num updates: 160, Wall time: 1122.52, ETA: 0m 15s (- 0m 2s)
Evaluating...
epoch 29, time: 37.93
	train_loss: 0.0057, score: 29.01
	eval score: 11.67 (15.69)
Iter: 40, Loss 0.005567, Num updates: 40, Wall time: 1150.66, ETA: 0m 5s (- 0m 19s)
Iter: 80, Loss 0.005639, Num updates: 80, Wall time: 1154.30, ETA: 0m 8s (- 0m 11s)
Iter: 120, Loss 0.005656, Num updates: 120, Wall time: 1157.60, ETA: 0m 12s (- 0m 6s)
Iter: 160, Loss 0.005676, Num updates: 160, Wall time: 1160.91, ETA: 0m 15s (- 0m 2s)
Evaluating...
epoch 30, time: 37.40
	train_loss: 0.0057, score: 29.06
	eval score: 12.07 (15.69)
Iter: 40, Loss 0.005441, Num updates: 40, Wall time: 1189.49, ETA: 0m 4s (- 0m 18s)
Iter: 80, Loss 0.005585, Num updates: 80, Wall time: 1193.93, ETA: 0m 9s (- 0m 12s)
Iter: 120, Loss 0.005620, Num updates: 120, Wall time: 1198.14, ETA: 0m 13s (- 0m 7s)
Iter: 160, Loss 0.005645, Num updates: 160, Wall time: 1202.09, ETA: 0m 17s (- 0m 3s)
Evaluating...
epoch 31, time: 39.94
	train_loss: 0.0057, score: 29.03
	eval score: 11.83 (15.69)
Iter: 40, Loss 0.005407, Num updates: 40, Wall time: 1229.88, ETA: 0m 5s (- 0m 19s)
Iter: 80, Loss 0.005529, Num updates: 80, Wall time: 1233.47, ETA: 0m 8s (- 0m 11s)
Iter: 120, Loss 0.005566, Num updates: 120, Wall time: 1237.05, ETA: 0m 12s (- 0m 6s)
Iter: 160, Loss 0.005588, Num updates: 160, Wall time: 1240.87, ETA: 0m 16s (- 0m 2s)
Evaluating...
epoch 32, time: 39.61
	train_loss: 0.0056, score: 27.51
	eval score: 11.89 (15.69)
Iter: 40, Loss 0.005404, Num updates: 40, Wall time: 1269.52, ETA: 0m 4s (- 0m 18s)
Iter: 80, Loss 0.005499, Num updates: 80, Wall time: 1273.36, ETA: 0m 8s (- 0m 11s)
Iter: 120, Loss 0.005545, Num updates: 120, Wall time: 1277.11, ETA: 0m 12s (- 0m 7s)
Iter: 160, Loss 0.005563, Num updates: 160, Wall time: 1280.81, ETA: 0m 16s (- 0m 2s)
Evaluating...
epoch 33, time: 38.32
	train_loss: 0.0056, score: 28.61
	eval score: 11.94 (15.69)
Iter: 40, Loss 0.005303, Num updates: 40, Wall time: 1308.71, ETA: 0m 5s (- 0m 19s)
Iter: 80, Loss 0.005450, Num updates: 80, Wall time: 1312.46, ETA: 0m 8s (- 0m 12s)
Iter: 120, Loss 0.005474, Num updates: 120, Wall time: 1315.78, ETA: 0m 12s (- 0m 7s)
Iter: 160, Loss 0.005509, Num updates: 160, Wall time: 1319.13, ETA: 0m 15s (- 0m 2s)
Evaluating...
epoch 34, time: 39.77
	train_loss: 0.0056, score: 29.86
	eval score: 12.07 (15.69)
Iter: 40, Loss 0.005435, Num updates: 40, Wall time: 1348.36, ETA: 0m 4s (- 0m 18s)
Iter: 80, Loss 0.005489, Num updates: 80, Wall time: 1352.24, ETA: 0m 8s (- 0m 11s)
Iter: 120, Loss 0.005523, Num updates: 120, Wall time: 1356.05, ETA: 0m 12s (- 0m 7s)
Iter: 160, Loss 0.005534, Num updates: 160, Wall time: 1359.85, ETA: 0m 16s (- 0m 2s)
Evaluating...
epoch 35, time: 41.47
	train_loss: 0.0056, score: 28.88
	eval score: 12.08 (15.69)
Iter: 40, Loss 0.005337, Num updates: 40, Wall time: 1391.96, ETA: 0m 5s (- 0m 20s)
Iter: 80, Loss 0.005458, Num updates: 80, Wall time: 1395.72, ETA: 0m 9s (- 0m 12s)
Iter: 120, Loss 0.005488, Num updates: 120, Wall time: 1399.74, ETA: 0m 13s (- 0m 7s)
Iter: 160, Loss 0.005516, Num updates: 160, Wall time: 1403.78, ETA: 0m 17s (- 0m 3s)
Evaluating...
epoch 36, time: 43.21
	train_loss: 0.0055, score: 28.59
	eval score: 11.76 (15.69)
Iter: 40, Loss 0.005330, Num updates: 40, Wall time: 1435.58, ETA: 0m 5s (- 0m 20s)
Iter: 80, Loss 0.005419, Num updates: 80, Wall time: 1439.24, ETA: 0m 9s (- 0m 12s)
Iter: 120, Loss 0.005460, Num updates: 120, Wall time: 1443.14, ETA: 0m 13s (- 0m 7s)
Iter: 160, Loss 0.005454, Num updates: 160, Wall time: 1447.21, ETA: 0m 17s (- 0m 3s)
Evaluating...
epoch 37, time: 40.74
	train_loss: 0.0055, score: 29.16
	eval score: 11.95 (15.69)
Iter: 40, Loss 0.005278, Num updates: 40, Wall time: 1476.15, ETA: 0m 5s (- 0m 19s)
Iter: 80, Loss 0.005391, Num updates: 80, Wall time: 1480.52, ETA: 0m 9s (- 0m 12s)
Iter: 120, Loss 0.005420, Num updates: 120, Wall time: 1484.20, ETA: 0m 13s (- 0m 7s)
Iter: 160, Loss 0.005428, Num updates: 160, Wall time: 1488.06, ETA: 0m 16s (- 0m 2s)
Evaluating...
epoch 38, time: 41.49
	train_loss: 0.0055, score: 29.06
	eval score: 12.16 (15.69)
Iter: 40, Loss 0.005239, Num updates: 40, Wall time: 1519.24, ETA: 0m 4s (- 0m 18s)
Iter: 80, Loss 0.005335, Num updates: 80, Wall time: 1523.07, ETA: 0m 8s (- 0m 11s)
Iter: 120, Loss 0.005380, Num updates: 120, Wall time: 1526.73, ETA: 0m 12s (- 0m 7s)
Iter: 160, Loss 0.005402, Num updates: 160, Wall time: 1530.87, ETA: 0m 16s (- 0m 2s)
Evaluating...
epoch 39, time: 40.30
	train_loss: 0.0054, score: 29.85
	eval score: 12.10 (15.69)
Iter: 40, Loss 0.005290, Num updates: 40, Wall time: 1559.24, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.005369, Num updates: 80, Wall time: 1562.78, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.005367, Num updates: 120, Wall time: 1566.56, ETA: 0m 11s (- 0m 6s)
Iter: 160, Loss 0.005377, Num updates: 160, Wall time: 1569.91, ETA: 0m 14s (- 0m 2s)
Evaluating...
epoch 40, time: 39.16
	train_loss: 0.0054, score: 29.78
	eval score: 11.95 (15.69)
Iter: 40, Loss 0.005199, Num updates: 40, Wall time: 1599.83, ETA: 0m 5s (- 0m 20s)
Iter: 80, Loss 0.005353, Num updates: 80, Wall time: 1604.04, ETA: 0m 9s (- 0m 13s)
Iter: 120, Loss 0.005367, Num updates: 120, Wall time: 1607.79, ETA: 0m 13s (- 0m 7s)
Iter: 160, Loss 0.005384, Num updates: 160, Wall time: 1611.90, ETA: 0m 17s (- 0m 3s)
Evaluating...
epoch 41, time: 42.54
	train_loss: 0.0054, score: 29.90
	eval score: 12.07 (15.69)
Iter: 40, Loss 0.005295, Num updates: 40, Wall time: 1641.68, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.005362, Num updates: 80, Wall time: 1645.01, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.005354, Num updates: 120, Wall time: 1648.63, ETA: 0m 11s (- 0m 6s)
Iter: 160, Loss 0.005345, Num updates: 160, Wall time: 1652.10, ETA: 0m 14s (- 0m 2s)
Evaluating...
epoch 42, time: 37.76
	train_loss: 0.0054, score: 29.41
	eval score: 12.05 (15.69)
Iter: 40, Loss 0.005287, Num updates: 40, Wall time: 1680.00, ETA: 0m 4s (- 0m 18s)
Iter: 80, Loss 0.005296, Num updates: 80, Wall time: 1684.17, ETA: 0m 9s (- 0m 12s)
Iter: 120, Loss 0.005322, Num updates: 120, Wall time: 1688.05, ETA: 0m 12s (- 0m 7s)
Iter: 160, Loss 0.005332, Num updates: 160, Wall time: 1691.87, ETA: 0m 16s (- 0m 2s)
Evaluating...
epoch 43, time: 36.24
	train_loss: 0.0054, score: 28.76
	eval score: 12.19 (15.69)
Iter: 40, Loss 0.005189, Num updates: 40, Wall time: 1718.52, ETA: 0m 5s (- 0m 19s)
Iter: 80, Loss 0.005243, Num updates: 80, Wall time: 1722.38, ETA: 0m 8s (- 0m 12s)
Iter: 120, Loss 0.005266, Num updates: 120, Wall time: 1725.75, ETA: 0m 12s (- 0m 7s)
Iter: 160, Loss 0.005296, Num updates: 160, Wall time: 1729.33, ETA: 0m 15s (- 0m 2s)
Evaluating...
epoch 44, time: 39.89
	train_loss: 0.0053, score: 29.80
	eval score: 12.20 (15.69)
Iter: 40, Loss 0.005164, Num updates: 40, Wall time: 1760.63, ETA: 0m 5s (- 0m 20s)
Iter: 80, Loss 0.005237, Num updates: 80, Wall time: 1764.39, ETA: 0m 9s (- 0m 12s)
Iter: 120, Loss 0.005260, Num updates: 120, Wall time: 1768.27, ETA: 0m 13s (- 0m 7s)
Iter: 160, Loss 0.005280, Num updates: 160, Wall time: 1772.31, ETA: 0m 17s (- 0m 3s)
Evaluating...
epoch 45, time: 44.63
	train_loss: 0.0053, score: 29.85
	eval score: 12.17 (15.69)
Iter: 40, Loss 0.005148, Num updates: 40, Wall time: 1806.01, ETA: 0m 5s (- 0m 22s)
Iter: 80, Loss 0.005227, Num updates: 80, Wall time: 1810.52, ETA: 0m 10s (- 0m 14s)
Iter: 120, Loss 0.005261, Num updates: 120, Wall time: 1814.82, ETA: 0m 14s (- 0m 8s)
Iter: 160, Loss 0.005262, Num updates: 160, Wall time: 1819.65, ETA: 0m 19s (- 0m 3s)
Evaluating...
epoch 46, time: 47.32
	train_loss: 0.0053, score: 29.70
	eval score: 12.13 (15.69)
Iter: 40, Loss 0.005224, Num updates: 40, Wall time: 1851.98, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.005286, Num updates: 80, Wall time: 1855.23, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.005312, Num updates: 120, Wall time: 1858.68, ETA: 0m 11s (- 0m 6s)
Iter: 160, Loss 0.005299, Num updates: 160, Wall time: 1861.96, ETA: 0m 14s (- 0m 2s)
Evaluating...
epoch 47, time: 37.91
	train_loss: 0.0053, score: 29.23
	eval score: 12.14 (15.69)
Iter: 40, Loss 0.005083, Num updates: 40, Wall time: 1890.76, ETA: 0m 5s (- 0m 18s)
Iter: 80, Loss 0.005129, Num updates: 80, Wall time: 1894.15, ETA: 0m 8s (- 0m 11s)
Iter: 120, Loss 0.005171, Num updates: 120, Wall time: 1897.45, ETA: 0m 11s (- 0m 6s)
Iter: 160, Loss 0.005214, Num updates: 160, Wall time: 1901.01, ETA: 0m 15s (- 0m 2s)
Evaluating...
epoch 48, time: 39.46
	train_loss: 0.0053, score: 29.03
	eval score: 12.22 (15.69)
Iter: 40, Loss 0.005053, Num updates: 40, Wall time: 1932.19, ETA: 0m 5s (- 0m 19s)
Iter: 80, Loss 0.005153, Num updates: 80, Wall time: 1935.90, ETA: 0m 8s (- 0m 11s)
Iter: 120, Loss 0.005177, Num updates: 120, Wall time: 1940.22, ETA: 0m 13s (- 0m 7s)
Iter: 160, Loss 0.005197, Num updates: 160, Wall time: 1944.14, ETA: 0m 16s (- 0m 2s)
Evaluating...
epoch 49, time: 43.77
	train_loss: 0.0052, score: 28.06
	eval score: 12.32 (15.69)
Iter: 40, Loss 0.005069, Num updates: 40, Wall time: 1978.78, ETA: 0m 5s (- 0m 22s)
Iter: 80, Loss 0.005144, Num updates: 80, Wall time: 1983.37, ETA: 0m 10s (- 0m 14s)
Iter: 120, Loss 0.005151, Num updates: 120, Wall time: 1988.17, ETA: 0m 15s (- 0m 8s)
Iter: 160, Loss 0.005174, Num updates: 160, Wall time: 1992.63, ETA: 0m 19s (- 0m 3s)
Evaluating...
epoch 50, time: 50.26
	train_loss: 0.0052, score: 29.23
	eval score: 12.45 (15.69)
Iter: 40, Loss 0.004946, Num updates: 40, Wall time: 2031.28, ETA: 0m 6s (- 0m 23s)
Iter: 80, Loss 0.005122, Num updates: 80, Wall time: 2036.10, ETA: 0m 11s (- 0m 15s)
Iter: 120, Loss 0.005151, Num updates: 120, Wall time: 2040.37, ETA: 0m 15s (- 0m 8s)
Iter: 160, Loss 0.005165, Num updates: 160, Wall time: 2045.62, ETA: 0m 20s (- 0m 3s)
Evaluating...
epoch 51, time: 52.26
	train_loss: 0.0052, score: 29.06
	eval score: 12.48 (15.69)
Iter: 40, Loss 0.005076, Num updates: 40, Wall time: 2086.36, ETA: 0m 6s (- 0m 25s)
Iter: 80, Loss 0.005128, Num updates: 80, Wall time: 2090.83, ETA: 0m 11s (- 0m 15s)
Iter: 120, Loss 0.005163, Num updates: 120, Wall time: 2095.55, ETA: 0m 15s (- 0m 9s)
Iter: 160, Loss 0.005170, Num updates: 160, Wall time: 2100.14, ETA: 0m 20s (- 0m 3s)
Evaluating...
epoch 52, time: 53.23
	train_loss: 0.0052, score: 29.11
	eval score: 12.32 (15.69)
Iter: 40, Loss 0.005009, Num updates: 40, Wall time: 2139.44, ETA: 0m 6s (- 0m 23s)
Iter: 80, Loss 0.005083, Num updates: 80, Wall time: 2144.07, ETA: 0m 10s (- 0m 14s)
Iter: 120, Loss 0.005116, Num updates: 120, Wall time: 2148.41, ETA: 0m 15s (- 0m 8s)
Iter: 160, Loss 0.005121, Num updates: 160, Wall time: 2153.22, ETA: 0m 20s (- 0m 3s)
Evaluating...
epoch 53, time: 54.78
	train_loss: 0.0052, score: 29.14
	eval score: 12.19 (15.69)
Iter: 40, Loss 0.005020, Num updates: 40, Wall time: 2194.45, ETA: 0m 6s (- 0m 23s)
Iter: 80, Loss 0.005091, Num updates: 80, Wall time: 2199.41, ETA: 0m 11s (- 0m 15s)
Iter: 120, Loss 0.005121, Num updates: 120, Wall time: 2203.99, ETA: 0m 15s (- 0m 9s)
Iter: 160, Loss 0.005119, Num updates: 160, Wall time: 2208.61, ETA: 0m 20s (- 0m 3s)
Evaluating...
epoch 54, time: 53.30
	train_loss: 0.0052, score: 28.19
	eval score: 12.35 (15.69)
Iter: 40, Loss 0.004991, Num updates: 40, Wall time: 2246.85, ETA: 0m 5s (- 0m 19s)
Iter: 80, Loss 0.005070, Num updates: 80, Wall time: 2250.71, ETA: 0m 9s (- 0m 12s)
Iter: 120, Loss 0.005097, Num updates: 120, Wall time: 2254.76, ETA: 0m 13s (- 0m 7s)
Iter: 160, Loss 0.005121, Num updates: 160, Wall time: 2259.15, ETA: 0m 17s (- 0m 3s)
Evaluating...
epoch 55, time: 54.34
	train_loss: 0.0052, score: 28.33
	eval score: 12.28 (15.69)
Iter: 40, Loss 0.005003, Num updates: 40, Wall time: 2303.24, ETA: 0m 6s (- 0m 26s)
Iter: 80, Loss 0.005092, Num updates: 80, Wall time: 2308.28, ETA: 0m 12s (- 0m 16s)
Iter: 120, Loss 0.005099, Num updates: 120, Wall time: 2313.62, ETA: 0m 17s (- 0m 9s)
Iter: 160, Loss 0.005118, Num updates: 160, Wall time: 2318.63, ETA: 0m 22s (- 0m 3s)
Evaluating...
epoch 56, time: 64.07
	train_loss: 0.0051, score: 28.34
	eval score: 12.54 (15.69)
Iter: 40, Loss 0.004931, Num updates: 40, Wall time: 2369.41, ETA: 0m 6s (- 0m 26s)
Iter: 80, Loss 0.005024, Num updates: 80, Wall time: 2373.93, ETA: 0m 11s (- 0m 15s)
Iter: 120, Loss 0.005045, Num updates: 120, Wall time: 2378.41, ETA: 0m 15s (- 0m 9s)
Iter: 160, Loss 0.005071, Num updates: 160, Wall time: 2383.50, ETA: 0m 21s (- 0m 3s)
Evaluating...
epoch 57, time: 57.13
	train_loss: 0.0051, score: 28.51
	eval score: 12.10 (15.69)
Iter: 40, Loss 0.005013, Num updates: 40, Wall time: 2427.29, ETA: 0m 7s (- 0m 28s)
Iter: 80, Loss 0.005057, Num updates: 80, Wall time: 2432.97, ETA: 0m 13s (- 0m 17s)
Iter: 120, Loss 0.005085, Num updates: 120, Wall time: 2438.05, ETA: 0m 18s (- 0m 10s)
Iter: 160, Loss 0.005083, Num updates: 160, Wall time: 2443.00, ETA: 0m 23s (- 0m 4s)
Evaluating...
epoch 58, time: 62.37
	train_loss: 0.0051, score: 28.44
	eval score: 12.28 (15.69)
Iter: 40, Loss 0.005001, Num updates: 40, Wall time: 2489.78, ETA: 0m 7s (- 0m 27s)
Iter: 80, Loss 0.005052, Num updates: 80, Wall time: 2495.58, ETA: 0m 13s (- 0m 17s)
Iter: 120, Loss 0.005062, Num updates: 120, Wall time: 2500.91, ETA: 0m 18s (- 0m 10s)
Iter: 160, Loss 0.005062, Num updates: 160, Wall time: 2506.79, ETA: 0m 24s (- 0m 4s)
Evaluating...
epoch 59, time: 60.34
	train_loss: 0.0051, score: 28.44
	eval score: 12.29 (15.69)
Iter: 40, Loss 0.004970, Num updates: 40, Wall time: 2549.82, ETA: 0m 6s (- 0m 25s)
Iter: 80, Loss 0.005032, Num updates: 80, Wall time: 2554.20, ETA: 0m 11s (- 0m 15s)
Iter: 120, Loss 0.005024, Num updates: 120, Wall time: 2558.59, ETA: 0m 15s (- 0m 8s)
Iter: 160, Loss 0.005049, Num updates: 160, Wall time: 2564.08, ETA: 0m 21s (- 0m 3s)
Evaluating...
epoch 60, time: 51.88
	train_loss: 0.0051, score: 28.76
	eval score: 12.42 (15.69)
Iter: 40, Loss 0.004965, Num updates: 40, Wall time: 2600.86, ETA: 0m 5s (- 0m 21s)
Iter: 80, Loss 0.004984, Num updates: 80, Wall time: 2605.19, ETA: 0m 10s (- 0m 13s)
Iter: 120, Loss 0.005013, Num updates: 120, Wall time: 2609.63, ETA: 0m 14s (- 0m 8s)
Iter: 160, Loss 0.005032, Num updates: 160, Wall time: 2614.08, ETA: 0m 18s (- 0m 3s)
Evaluating...
epoch 61, time: 52.76
	train_loss: 0.0051, score: 27.34
	eval score: 12.34 (15.69)
Iter: 40, Loss 0.004891, Num updates: 40, Wall time: 2654.86, ETA: 0m 6s (- 0m 25s)
Iter: 80, Loss 0.004944, Num updates: 80, Wall time: 2658.81, ETA: 0m 10s (- 0m 14s)
Iter: 120, Loss 0.004986, Num updates: 120, Wall time: 2663.38, ETA: 0m 15s (- 0m 8s)
Iter: 160, Loss 0.005003, Num updates: 160, Wall time: 2667.68, ETA: 0m 19s (- 0m 3s)
Evaluating...
epoch 62, time: 52.55
	train_loss: 0.0050, score: 28.83
	eval score: 12.53 (15.69)
Iter: 40, Loss 0.004937, Num updates: 40, Wall time: 2709.78, ETA: 0m 8s (- 0m 33s)
Iter: 80, Loss 0.004967, Num updates: 80, Wall time: 2715.76, ETA: 0m 14s (- 0m 20s)
Iter: 120, Loss 0.004999, Num updates: 120, Wall time: 2720.23, ETA: 0m 19s (- 0m 11s)
Iter: 160, Loss 0.005012, Num updates: 160, Wall time: 2724.25, ETA: 0m 23s (- 0m 4s)
Evaluating...
epoch 63, time: 54.76
	train_loss: 0.0050, score: 27.69
	eval score: 12.34 (15.69)
Iter: 40, Loss 0.004909, Num updates: 40, Wall time: 2762.46, ETA: 0m 6s (- 0m 24s)
Iter: 80, Loss 0.004968, Num updates: 80, Wall time: 2766.92, ETA: 0m 11s (- 0m 15s)
Iter: 120, Loss 0.004953, Num updates: 120, Wall time: 2771.05, ETA: 0m 15s (- 0m 8s)
Iter: 160, Loss 0.004962, Num updates: 160, Wall time: 2774.77, ETA: 0m 18s (- 0m 3s)
Evaluating...
epoch 64, time: 50.19
	train_loss: 0.0050, score: 28.31
	eval score: 12.42 (15.69)
Iter: 40, Loss 0.004831, Num updates: 40, Wall time: 2813.75, ETA: 0m 7s (- 0m 28s)
Iter: 80, Loss 0.004906, Num updates: 80, Wall time: 2818.50, ETA: 0m 12s (- 0m 16s)
Iter: 120, Loss 0.004947, Num updates: 120, Wall time: 2823.66, ETA: 0m 17s (- 0m 9s)
Iter: 160, Loss 0.004950, Num updates: 160, Wall time: 2828.12, ETA: 0m 21s (- 0m 3s)
Evaluating...
epoch 65, time: 54.60
	train_loss: 0.0050, score: 27.67
	eval score: 12.32 (15.69)
Iter: 40, Loss 0.004815, Num updates: 40, Wall time: 2867.37, ETA: 0m 6s (- 0m 23s)
Iter: 80, Loss 0.004883, Num updates: 80, Wall time: 2871.75, ETA: 0m 10s (- 0m 14s)
Iter: 120, Loss 0.004923, Num updates: 120, Wall time: 2875.86, ETA: 0m 14s (- 0m 8s)
Iter: 160, Loss 0.004943, Num updates: 160, Wall time: 2880.60, ETA: 0m 19s (- 0m 3s)
Evaluating...
epoch 66, time: 52.60
	train_loss: 0.0050, score: 28.43
	eval score: 12.45 (15.69)
Iter: 40, Loss 0.004939, Num updates: 40, Wall time: 2920.13, ETA: 0m 6s (- 0m 23s)
Iter: 80, Loss 0.004970, Num updates: 80, Wall time: 2924.26, ETA: 0m 10s (- 0m 14s)
Iter: 120, Loss 0.004952, Num updates: 120, Wall time: 2928.63, ETA: 0m 14s (- 0m 8s)
Iter: 160, Loss 0.004969, Num updates: 160, Wall time: 2933.10, ETA: 0m 19s (- 0m 3s)
Evaluating...
epoch 67, time: 51.55
	train_loss: 0.0050, score: 28.64
	eval score: 12.42 (15.69)
Iter: 40, Loss 0.004893, Num updates: 40, Wall time: 2972.54, ETA: 0m 6s (- 0m 25s)
Iter: 80, Loss 0.004916, Num updates: 80, Wall time: 2977.03, ETA: 0m 11s (- 0m 15s)
Iter: 120, Loss 0.004958, Num updates: 120, Wall time: 2981.41, ETA: 0m 15s (- 0m 8s)
Iter: 160, Loss 0.004962, Num updates: 160, Wall time: 2985.80, ETA: 0m 20s (- 0m 3s)
Evaluating...
epoch 68, time: 51.78
	train_loss: 0.0050, score: 27.82
	eval score: 12.44 (15.69)
Iter: 40, Loss 0.004865, Num updates: 40, Wall time: 3024.46, ETA: 0m 6s (- 0m 25s)
Iter: 80, Loss 0.004883, Num updates: 80, Wall time: 3028.47, ETA: 0m 10s (- 0m 14s)
Iter: 120, Loss 0.004912, Num updates: 120, Wall time: 3032.52, ETA: 0m 14s (- 0m 8s)
Iter: 160, Loss 0.004927, Num updates: 160, Wall time: 3036.78, ETA: 0m 18s (- 0m 3s)
Evaluating...
epoch 69, time: 52.86
	train_loss: 0.0050, score: 28.01
	eval score: 12.44 (15.69)
Iter: 40, Loss 0.004790, Num updates: 40, Wall time: 3077.67, ETA: 0m 6s (- 0m 25s)
Iter: 80, Loss 0.004871, Num updates: 80, Wall time: 3081.83, ETA: 0m 10s (- 0m 14s)
Iter: 120, Loss 0.004903, Num updates: 120, Wall time: 3086.38, ETA: 0m 15s (- 0m 8s)
Iter: 160, Loss 0.004916, Num updates: 160, Wall time: 3090.63, ETA: 0m 19s (- 0m 3s)
Evaluating...
epoch 70, time: 49.93
	train_loss: 0.0049, score: 28.04
	eval score: 12.48 (15.69)
Iter: 40, Loss 0.004780, Num updates: 40, Wall time: 3127.74, ETA: 0m 6s (- 0m 25s)
Iter: 80, Loss 0.004878, Num updates: 80, Wall time: 3132.25, ETA: 0m 11s (- 0m 15s)
Iter: 120, Loss 0.004902, Num updates: 120, Wall time: 3136.79, ETA: 0m 15s (- 0m 8s)
Iter: 160, Loss 0.004924, Num updates: 160, Wall time: 3141.27, ETA: 0m 20s (- 0m 3s)
Evaluating...
epoch 71, time: 51.26
	train_loss: 0.0050, score: 28.54
	eval score: 12.45 (15.69)
Iter: 40, Loss 0.004739, Num updates: 40, Wall time: 3178.40, ETA: 0m 5s (- 0m 22s)
Iter: 80, Loss 0.004814, Num updates: 80, Wall time: 3182.26, ETA: 0m 9s (- 0m 13s)
Iter: 120, Loss 0.004872, Num updates: 120, Wall time: 3187.01, ETA: 0m 14s (- 0m 8s)
Iter: 160, Loss 0.004897, Num updates: 160, Wall time: 3191.02, ETA: 0m 18s (- 0m 3s)
Evaluating...
epoch 72, time: 47.18
	train_loss: 0.0049, score: 28.18
	eval score: 12.54 (15.69)
Iter: 40, Loss 0.004796, Num updates: 40, Wall time: 3226.74, ETA: 0m 6s (- 0m 25s)
Iter: 80, Loss 0.004889, Num updates: 80, Wall time: 3231.31, ETA: 0m 11s (- 0m 15s)
Iter: 120, Loss 0.004889, Num updates: 120, Wall time: 3235.44, ETA: 0m 15s (- 0m 8s)
Iter: 160, Loss 0.004901, Num updates: 160, Wall time: 3239.60, ETA: 0m 19s (- 0m 3s)
Evaluating...
epoch 73, time: 48.05
	train_loss: 0.0049, score: 27.37
	eval score: 12.34 (15.69)
Iter: 40, Loss 0.004753, Num updates: 40, Wall time: 3274.96, ETA: 0m 6s (- 0m 25s)
Iter: 80, Loss 0.004808, Num updates: 80, Wall time: 3279.35, ETA: 0m 11s (- 0m 15s)
Iter: 120, Loss 0.004850, Num updates: 120, Wall time: 3283.36, ETA: 0m 15s (- 0m 8s)
Iter: 160, Loss 0.004885, Num updates: 160, Wall time: 3287.86, ETA: 0m 19s (- 0m 3s)
Evaluating...
epoch 74, time: 51.96
	train_loss: 0.0049, score: 27.64
	eval score: 12.53 (15.69)
Iter: 40, Loss 0.004770, Num updates: 40, Wall time: 3327.31, ETA: 0m 6s (- 0m 25s)
Iter: 80, Loss 0.004819, Num updates: 80, Wall time: 3331.12, ETA: 0m 10s (- 0m 14s)
Iter: 120, Loss 0.004864, Num updates: 120, Wall time: 3335.05, ETA: 0m 14s (- 0m 8s)
Iter: 160, Loss 0.004882, Num updates: 160, Wall time: 3339.59, ETA: 0m 19s (- 0m 3s)
Evaluating...
epoch 75, time: 50.18
	train_loss: 0.0049, score: 26.60
	eval score: 12.56 (15.69)
Iter: 40, Loss 0.004810, Num updates: 40, Wall time: 3379.70, ETA: 0m 6s (- 0m 25s)
Iter: 80, Loss 0.004820, Num updates: 80, Wall time: 3384.43, ETA: 0m 11s (- 0m 15s)
Iter: 120, Loss 0.004849, Num updates: 120, Wall time: 3389.39, ETA: 0m 16s (- 0m 9s)
Iter: 160, Loss 0.004876, Num updates: 160, Wall time: 3394.15, ETA: 0m 21s (- 0m 3s)
Evaluating...
epoch 76, time: 52.43
	train_loss: 0.0049, score: 27.02
	eval score: 12.44 (15.69)
Iter: 40, Loss 0.004720, Num updates: 40, Wall time: 3431.90, ETA: 0m 6s (- 0m 23s)
Iter: 80, Loss 0.004791, Num updates: 80, Wall time: 3436.43, ETA: 0m 10s (- 0m 14s)
Iter: 120, Loss 0.004820, Num updates: 120, Wall time: 3441.65, ETA: 0m 16s (- 0m 9s)
Iter: 160, Loss 0.004846, Num updates: 160, Wall time: 3446.67, ETA: 0m 21s (- 0m 3s)
Evaluating...
epoch 77, time: 50.61
	train_loss: 0.0049, score: 26.34
	eval score: 12.53 (15.69)
Iter: 40, Loss 0.004787, Num updates: 40, Wall time: 3481.24, ETA: 0m 4s (- 0m 18s)
Iter: 80, Loss 0.004820, Num updates: 80, Wall time: 3484.81, ETA: 0m 8s (- 0m 11s)
Iter: 120, Loss 0.004842, Num updates: 120, Wall time: 3488.08, ETA: 0m 11s (- 0m 6s)
Iter: 160, Loss 0.004858, Num updates: 160, Wall time: 3491.28, ETA: 0m 14s (- 0m 2s)
Evaluating...
epoch 78, time: 36.76
	train_loss: 0.0049, score: 27.19
	eval score: 12.39 (15.69)
Iter: 40, Loss 0.004796, Num updates: 40, Wall time: 3518.77, ETA: 0m 5s (- 0m 20s)
Iter: 80, Loss 0.004867, Num updates: 80, Wall time: 3522.51, ETA: 0m 9s (- 0m 12s)
Iter: 120, Loss 0.004858, Num updates: 120, Wall time: 3526.02, ETA: 0m 12s (- 0m 7s)
Iter: 160, Loss 0.004866, Num updates: 160, Wall time: 3529.35, ETA: 0m 15s (- 0m 2s)
Evaluating...
epoch 79, time: 40.04
	train_loss: 0.0049, score: 27.27
	eval score: 12.57 (15.69)
0.01753,0.00993,0.00898,0.00832,0.0079,0.00762,0.0074,0.00724,0.00707,0.00692,0.0068,0.00671,0.00661,0.00655,0.00643,0.00636,0.00632,0.00627,0.00619,0.00614,0.0061,0.00604,0.00599,0.00596,0.0059,0.00586,0.00584,0.00579,0.00576,0.00573,0.00573,0.00568,0.00564,0.00562,0.00556,0.00556,0.00555,0.0055,0.00548,0.00543,0.00542,0.00542,0.00539,0.00537,0.00533,0.00531,0.00529,0.00533,0.00526,0.00525,0.00521,0.0052,0.00519,0.00515,0.00516,0.00516,0.00514,0.00512,0.00511,0.00509,0.00508,0.00506,0.00503,0.00504,0.005,0.005,0.00498,0.005,0.005,0.00496,0.00494,0.00495,0.00492,0.00494,0.00491,0.00491,0.00491,0.00488,0.00489,0.0049
0.0026,0.0021,0.00169,0.0015,0.00144,0.00133,0.00129,0.00124,0.00121,0.00116,0.00114,0.00111,0.00107,0.00108,0.00105,0.00105,0.00104,0.00102,0.00103,0.00101,0.00101,0.00101,0.00106,0.00104,0.001,0.00098,0.001,0.00096,0.00099,0.00099,0.00098,0.00098,0.00097,0.00096,0.00098,0.00098,0.00099,0.00098,0.00095,0.00095,0.00098,0.00096,0.00102,0.00098,0.00098,0.00097,0.00098,0.00097,0.00097,0.00098,0.00098,0.00098,0.00099,0.00101,0.001,0.00099,0.00099,0.00101,0.001,0.00101,0.00099,0.00102,0.00096,0.00103,0.00101,0.00101,0.001,0.00103,0.00101,0.00102,0.00103,0.00103,0.00101,0.00102,0.00102,0.00103,0.00102,0.00101,0.00102,0.00102
saved_model_SLAKE/BAN_MEVF
Namespace(RAD_dir='/home/coder/projects/Med-VQA/data_SLAKE', activation='relu', ae_alpha=0.001, ae_model_path='pretrained_ae.pth', alpha=1.0, autoencoder=True, batch_size=32, clip_norm=0.25, dropout=0.5, epochs=80, eps_cnn=1e-05, feat_dim=32, five_fold=False, gamma=2, gpu=0, input=None, lr=0.03, maml=True, maml_model_path='pretrained_maml.pth', model='SAN', momentum_cnn=0.05, num_hid=1024, num_stacks=2, op='c', output='saved_model_SLAKE/BAN_MEVF', pow=2, print_interval=40, qc_model_path='./saved_models/QC/rad_best.pth', question_len=12, record_id=2, rescale_factor=1.5, rnn='LSTM', seed=3, tfidf=True, update_freq='1', use_RAD=True, use_ablation=False, use_ablation_q=False, use_ablation_v=False, use_counter=False, use_grad_cam=False, use_kl_mix=False, use_mix=True, use_mix_all=False, use_mix_cond=True, use_mix_cond_q=True, use_mix_cond_v=False, use_mix_cond_vq_in=False, use_mix_cond_vq_union=False, use_partial_label=False, use_rescale=False, use_sep_mix=False)
loading dictionary from /home/coder/projects/Med-VQA/data_SLAKE/dictionary.pkl
loading MAML image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images84x84.pkl
loading DAE image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images128x128.pkl
loading MAML image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images84x84.pkl
loading DAE image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images128x128.pkl
load initial weights MAML from: /home/coder/projects/Med-VQA/data_SLAKE/pretrained_maml.pth
Traceback (most recent call last):
  File "main.py", line 189, in <module>
    model = getattr(base_model, constructor)(train_dset, args)
  File "/home/coder/projects/VQAMix-main/base_model.py", line 237, in build_SAN
    maml_v_emb.load_state_dict(torch.load(weight_path))
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py", line 579, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/home/coder/projects/Med-VQA/data_SLAKE/pretrained_maml.pth'
saved_model_SLAKE/BAN_MEVF
Namespace(RAD_dir='/home/coder/projects/Med-VQA/data_SLAKE', activation='relu', ae_alpha=0.001, ae_model_path='pretrained_ae.pth', alpha=1.0, autoencoder=True, batch_size=32, clip_norm=0.25, dropout=0.5, epochs=80, eps_cnn=1e-05, feat_dim=32, five_fold=False, gamma=2, gpu=0, input=None, lr=0.03, maml=True, maml_model_path='pretrained_maml.weights', model='SAN', momentum_cnn=0.05, num_hid=1024, num_stacks=2, op='c', output='saved_model_SLAKE/BAN_MEVF', pow=2, print_interval=40, qc_model_path='./saved_models/QC/rad_best.pth', question_len=12, record_id=2, rescale_factor=1.5, rnn='LSTM', seed=3, tfidf=True, update_freq='1', use_RAD=True, use_ablation=False, use_ablation_q=False, use_ablation_v=False, use_counter=False, use_grad_cam=False, use_kl_mix=False, use_mix=True, use_mix_all=False, use_mix_cond=True, use_mix_cond_q=True, use_mix_cond_v=False, use_mix_cond_vq_in=False, use_mix_cond_vq_union=False, use_partial_label=False, use_rescale=False, use_sep_mix=False)
loading dictionary from /home/coder/projects/Med-VQA/data_SLAKE/dictionary.pkl
loading MAML image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images84x84.pkl
loading DAE image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images128x128.pkl
loading MAML image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images84x84.pkl
loading DAE image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images128x128.pkl
load initial weights MAML from: /home/coder/projects/Med-VQA/data_SLAKE/pretrained_maml.weights
Traceback (most recent call last):
  File "main.py", line 189, in <module>
    model = getattr(base_model, constructor)(train_dset, args)
  File "/home/coder/projects/VQAMix-main/base_model.py", line 237, in build_SAN
    maml_v_emb.load_state_dict(torch.load(weight_path))
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py", line 593, in load
    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py", line 764, in _legacy_load
    raise RuntimeError("Invalid magic number; corrupt file?")
RuntimeError: Invalid magic number; corrupt file?
saved_model_SLAKE/BAN_MEVF
Namespace(RAD_dir='/home/coder/projects/Med-VQA/data_SLAKE', activation='relu', ae_alpha=0.001, ae_model_path='pretrained_ae.pth', alpha=1.0, autoencoder=True, batch_size=32, clip_norm=0.25, dropout=0.5, epochs=80, eps_cnn=1e-05, feat_dim=32, five_fold=False, gamma=2, gpu=0, input=None, lr=0.03, maml=True, maml_model_path='pretrained_maml.pth', model='SAN', momentum_cnn=0.05, num_hid=1024, num_stacks=2, op='c', output='saved_model_SLAKE/BAN_MEVF', pow=2, print_interval=40, qc_model_path='./saved_models/QC/rad_best.pth', question_len=12, record_id=2, rescale_factor=1.5, rnn='LSTM', seed=3, tfidf=True, update_freq='1', use_RAD=True, use_ablation=False, use_ablation_q=False, use_ablation_v=False, use_counter=False, use_grad_cam=False, use_kl_mix=False, use_mix=True, use_mix_all=False, use_mix_cond=True, use_mix_cond_q=True, use_mix_cond_v=False, use_mix_cond_vq_in=False, use_mix_cond_vq_union=False, use_partial_label=False, use_rescale=False, use_sep_mix=False)
loading dictionary from /home/coder/projects/Med-VQA/data_SLAKE/dictionary.pkl
loading MAML image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images84x84.pkl
loading DAE image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images128x128.pkl
loading MAML image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images84x84.pkl
loading DAE image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images128x128.pkl
load initial weights MAML from: /home/coder/projects/Med-VQA/data_SLAKE/pretrained_maml.pth
Traceback (most recent call last):
  File "main.py", line 189, in <module>
    model = getattr(base_model, constructor)(train_dset, args)
  File "/home/coder/projects/VQAMix-main/base_model.py", line 237, in build_SAN
    maml_v_emb.load_state_dict(torch.load(weight_path))
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py", line 579, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/home/coder/projects/Med-VQA/data_SLAKE/pretrained_maml.pth'
saved_model_SLAKE/BAN_MEVF
Namespace(RAD_dir='/home/coder/projects/Med-VQA/data_SLAKE', activation='relu', ae_alpha=0.001, ae_model_path='pretrained_ae.pth', alpha=1.0, autoencoder=True, batch_size=32, clip_norm=0.25, dropout=0.5, epochs=80, eps_cnn=1e-05, feat_dim=32, five_fold=False, gamma=2, gpu=0, input=None, lr=0.03, maml=True, maml_model_path='pretrained_maml.weights', model='SAN', momentum_cnn=0.05, num_hid=1024, num_stacks=2, op='c', output='saved_model_SLAKE/BAN_MEVF', pow=2, print_interval=40, qc_model_path='./saved_models/QC/rad_best.pth', question_len=12, record_id=2, rescale_factor=1.5, rnn='LSTM', seed=3, tfidf=True, update_freq='1', use_RAD=True, use_ablation=False, use_ablation_q=False, use_ablation_v=False, use_counter=False, use_grad_cam=False, use_kl_mix=False, use_mix=True, use_mix_all=False, use_mix_cond=True, use_mix_cond_q=True, use_mix_cond_v=False, use_mix_cond_vq_in=False, use_mix_cond_vq_union=False, use_partial_label=False, use_rescale=False, use_sep_mix=False)
loading dictionary from /home/coder/projects/Med-VQA/data_SLAKE/dictionary.pkl
loading MAML image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images84x84.pkl
loading DAE image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images128x128.pkl
loading MAML image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images84x84.pkl
loading DAE image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images128x128.pkl
load initial weights MAML from: /home/coder/projects/Med-VQA/data_SLAKE/pretrained_maml.weights
Traceback (most recent call last):
  File "main.py", line 189, in <module>
    model = getattr(base_model, constructor)(train_dset, args)
  File "/home/coder/projects/VQAMix-main/base_model.py", line 237, in build_SAN
    maml_v_emb.load_state_dict(torch.load(weight_path))
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py", line 593, in load
    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py", line 764, in _legacy_load
    raise RuntimeError("Invalid magic number; corrupt file?")
RuntimeError: Invalid magic number; corrupt file?
saved_model_SLAKE/BAN_MEVF
Namespace(RAD_dir='/home/coder/projects/Med-VQA/data_SLAKE', activation='relu', ae_alpha=0.001, ae_model_path='pretrained_ae.pth', alpha=1.0, autoencoder=True, batch_size=32, clip_norm=0.25, dropout=0.5, epochs=80, eps_cnn=1e-05, feat_dim=32, five_fold=False, gamma=2, gpu=0, input=None, lr=0.03, maml=True, maml_model_path='pretrained_maml.weights', model='BAN', momentum_cnn=0.05, num_hid=1024, num_stacks=2, op='c', output='saved_model_SLAKE/BAN_MEVF', pow=2, print_interval=40, qc_model_path='./saved_models/QC/rad_best.pth', question_len=12, record_id=None, rescale_factor=1.5, rnn='LSTM', seed=3, tfidf=True, update_freq='1', use_RAD=True, use_ablation=False, use_ablation_q=False, use_ablation_v=False, use_counter=False, use_grad_cam=False, use_kl_mix=False, use_mix=True, use_mix_all=False, use_mix_cond=True, use_mix_cond_q=True, use_mix_cond_v=False, use_mix_cond_vq_in=False, use_mix_cond_vq_union=False, use_partial_label=False, use_rescale=False, use_sep_mix=False)
loading dictionary from /home/coder/projects/Med-VQA/data_SLAKE/dictionary.pkl
loading MAML image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images84x84.pkl
loading DAE image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images128x128.pkl
loading MAML image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images84x84.pkl
loading DAE image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images128x128.pkl
load initial weights MAML from: /home/coder/projects/Med-VQA/data_SLAKE/pretrained_maml.weights
Traceback (most recent call last):
  File "main.py", line 189, in <module>
    model = getattr(base_model, constructor)(train_dset, args)
  File "/home/coder/projects/VQAMix-main/base_model.py", line 175, in build_BAN
    maml_v_emb = SimpleCNN(weight_path[:-4]+'.weights', args.eps_cnn, args.momentum_cnn)
  File "/home/coder/projects/VQAMix-main/simple_cnn.py", line 16, in __init__
    weights = self.load_weight(weight_path)
  File "/home/coder/projects/VQAMix-main/simple_cnn.py", line 27, in load_weight
    return pickle.load(open(path, 'rb'))
FileNotFoundError: [Errno 2] No such file or directory: '/home/coder/projects/Med-VQA/data_SLAKE/pretrained_maml.wei.weights'
saved_model_SLAKE/BAN_MEVF
Namespace(RAD_dir='/home/coder/projects/Med-VQA/data_SLAKE', activation='relu', ae_alpha=0.001, ae_model_path='pretrained_ae.pth', alpha=1.0, autoencoder=True, batch_size=32, clip_norm=0.25, dropout=0.5, epochs=80, eps_cnn=1e-05, feat_dim=32, five_fold=False, gamma=2, gpu=0, input=None, lr=0.03, maml=True, maml_model_path='pretrained_maml.weights', model='SAN', momentum_cnn=0.05, num_hid=1024, num_stacks=2, op='c', output='saved_model_SLAKE/BAN_MEVF', pow=2, print_interval=40, qc_model_path='./saved_models/QC/rad_best.pth', question_len=12, record_id=2, rescale_factor=1.5, rnn='LSTM', seed=3, tfidf=True, update_freq='1', use_RAD=True, use_ablation=False, use_ablation_q=False, use_ablation_v=False, use_counter=False, use_grad_cam=False, use_kl_mix=False, use_mix=True, use_mix_all=False, use_mix_cond=True, use_mix_cond_q=True, use_mix_cond_v=False, use_mix_cond_vq_in=False, use_mix_cond_vq_union=False, use_partial_label=False, use_rescale=False, use_sep_mix=False)
loading dictionary from /home/coder/projects/Med-VQA/data_SLAKE/dictionary.pkl
loading MAML image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images84x84.pkl
loading DAE image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images128x128.pkl
loading MAML image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images84x84.pkl
loading DAE image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images128x128.pkl
load initial weights MAML from: /home/coder/projects/Med-VQA/data_SLAKE/pretrained_maml.weights
Traceback (most recent call last):
  File "main.py", line 189, in <module>
    model = getattr(base_model, constructor)(train_dset, args)
  File "/home/coder/projects/VQAMix-main/base_model.py", line 240, in build_SAN
    maml_v_emb.load_state_dict(torch.load(weight_path))
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py", line 593, in load
    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py", line 764, in _legacy_load
    raise RuntimeError("Invalid magic number; corrupt file?")
RuntimeError: Invalid magic number; corrupt file?
saved_model_SLAKE/BAN_MEVF
Namespace(RAD_dir='/home/coder/projects/Med-VQA/data_SLAKE', activation='relu', ae_alpha=0.001, ae_model_path='pretrained_ae.pth', alpha=1.0, autoencoder=True, batch_size=32, clip_norm=0.25, dropout=0.5, epochs=80, eps_cnn=1e-05, feat_dim=32, five_fold=False, gamma=2, gpu=0, input=None, lr=0.03, maml=True, maml_model_path='pretrained_maml.weights', model='SAN', momentum_cnn=0.05, num_hid=1024, num_stacks=2, op='c', output='saved_model_SLAKE/BAN_MEVF', pow=2, print_interval=40, qc_model_path='./saved_models/QC/rad_best.pth', question_len=12, record_id=2, rescale_factor=1.5, rnn='LSTM', seed=3, tfidf=True, update_freq='1', use_RAD=True, use_ablation=False, use_ablation_q=False, use_ablation_v=False, use_counter=False, use_grad_cam=False, use_kl_mix=False, use_mix=True, use_mix_all=False, use_mix_cond=True, use_mix_cond_q=True, use_mix_cond_v=False, use_mix_cond_vq_in=False, use_mix_cond_vq_union=False, use_partial_label=False, use_rescale=False, use_sep_mix=False)
loading dictionary from /home/coder/projects/Med-VQA/data_SLAKE/dictionary.pkl
loading MAML image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images84x84.pkl
loading DAE image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images128x128.pkl
loading MAML image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images84x84.pkl
loading DAE image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images128x128.pkl
load initial weights MAML from: /home/coder/projects/Med-VQA/data_SLAKE/pretrained_maml.weights
load initial weights DAE from: /home/coder/projects/Med-VQA/data_SLAKE/pretrained_ae.pth
loading dictionary from /home/coder/projects/Med-VQA/data_SLAKE/dictionary.pkl
Loading embedding tfidf and weights from file
Load embedding tfidf and weights from file successfully
Namespace(RAD_dir='/home/coder/projects/Med-VQA/data_SLAKE', activation='relu', ae_alpha=0.001, ae_model_path='pretrained_ae.pth', alpha=1.0, autoencoder=True, batch_size=32, clip_norm=0.25, device=device(type='cuda', index=0), dropout=0.5, epochs=80, eps_cnn=1e-05, feat_dim=64, five_fold=False, gamma=2, gpu=0, input=None, lr=0.03, maml=True, maml_model_path='pretrained_maml.weights', model='SAN', momentum_cnn=0.05, num_hid=1024, num_stacks=2, op='c', output='saved_model_SLAKE/BAN_MEVF', pow=2, print_interval=40, qc_model_path='./saved_models/QC/rad_best.pth', question_len=12, record_id=2, rescale_factor=1.5, rnn='LSTM', seed=3, tfidf=True, update_freq='1', use_RAD=True, use_ablation=False, use_ablation_q=False, use_ablation_v=False, use_counter=False, use_grad_cam=False, use_kl_mix=False, use_mix=True, use_mix_all=False, use_mix_cond=True, use_mix_cond_q=True, use_mix_cond_v=False, use_mix_cond_vq_in=False, use_mix_cond_vq_union=False, use_partial_label=False, use_rescale=False, use_sep_mix=False)
nParams=	12516830
optim: adamax lr=0.0300, decay_step=3, decay_rate=0.75, grad_clip=0.25
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'language_model.WordEmbedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Traceback (most recent call last):
  File "main.py", line 214, in <module>
    train(args, model, train_loader, eval_loader, args.epochs, args.output, optim, epoch, qc_model)
  File "/home/coder/projects/VQAMix-main/train.py", line 93, in train
    loss, batch_score = trainer.train_step(sample)
  File "/home/coder/projects/VQAMix-main/trainer.py", line 180, in train_step
    loss, batch_score = self._forward(sample)
  File "/home/coder/projects/VQAMix-main/trainer.py", line 207, in _forward
    features, decoder = self.model(mixed_v, sample[1], lam, index)
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/coder/projects/VQAMix-main/base_model.py", line 153, in forward
    att = self.v_att(v_emb, q_emb)
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/coder/projects/VQAMix-main/attention.py", line 75, in forward
    img_emb_1 = self.fc12(img_feat)
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 94, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/nn/functional.py", line 1753, in linear
    return torch._C._nn.linear(input, weight, bias)
RuntimeError: mat1 dim 1 must match mat2 dim 0
saved_model_SLAKE/BAN_MEVF
Namespace(RAD_dir='/home/coder/projects/Med-VQA/data_SLAKE', activation='relu', ae_alpha=0.001, ae_model_path='pretrained_ae.pth', alpha=1.0, autoencoder=True, batch_size=32, clip_norm=0.25, dropout=0.5, epochs=80, eps_cnn=1e-05, feat_dim=32, five_fold=False, gamma=2, gpu=0, input=None, lr=0.03, maml=True, maml_model_path='pretrained_maml.weights', model='SAN', momentum_cnn=0.05, num_hid=1024, num_stacks=2, op='c', output='saved_model_SLAKE/BAN_MEVF', pow=2, print_interval=40, qc_model_path='./saved_models/QC/rad_best.pth', question_len=12, record_id=2, rescale_factor=1.5, rnn='LSTM', seed=3, tfidf=True, update_freq='1', use_RAD=True, use_ablation=False, use_ablation_q=False, use_ablation_v=False, use_counter=False, use_grad_cam=False, use_kl_mix=False, use_mix=True, use_mix_all=False, use_mix_cond=True, use_mix_cond_q=True, use_mix_cond_v=False, use_mix_cond_vq_in=False, use_mix_cond_vq_union=False, use_partial_label=False, use_rescale=False, use_sep_mix=False)
loading dictionary from /home/coder/projects/Med-VQA/data_SLAKE/dictionary.pkl
loading MAML image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images84x84.pkl
loading DAE image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images128x128.pkl
loading MAML image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images84x84.pkl
loading DAE image data from file: /home/coder/projects/Med-VQA/data_SLAKE/images128x128.pkl
load initial weights MAML from: /home/coder/projects/Med-VQA/data_SLAKE/pretrained_maml.weights
load initial weights DAE from: /home/coder/projects/Med-VQA/data_SLAKE/pretrained_ae.pth
loading dictionary from /home/coder/projects/Med-VQA/data_SLAKE/dictionary.pkl
Loading embedding tfidf and weights from file
Load embedding tfidf and weights from file successfully
Namespace(RAD_dir='/home/coder/projects/Med-VQA/data_SLAKE', activation='relu', ae_alpha=0.001, ae_model_path='pretrained_ae.pth', alpha=1.0, autoencoder=True, batch_size=32, clip_norm=0.25, device=device(type='cuda', index=0), dropout=0.5, epochs=80, eps_cnn=1e-05, feat_dim=64, five_fold=False, gamma=2, gpu=0, input=None, lr=0.03, maml=True, maml_model_path='pretrained_maml.weights', model='SAN', momentum_cnn=0.05, num_hid=1024, num_stacks=2, op='c', output='saved_model_SLAKE/BAN_MEVF', pow=2, print_interval=40, qc_model_path='./saved_models/QC/rad_best.pth', question_len=12, record_id=2, rescale_factor=1.5, rnn='LSTM', seed=3, tfidf=True, update_freq='1', use_RAD=True, use_ablation=False, use_ablation_q=False, use_ablation_v=False, use_counter=False, use_grad_cam=False, use_kl_mix=False, use_mix=True, use_mix_all=False, use_mix_cond=True, use_mix_cond_q=True, use_mix_cond_v=False, use_mix_cond_vq_in=False, use_mix_cond_vq_union=False, use_partial_label=False, use_rescale=False, use_sep_mix=False)
nParams=	13041150
optim: adamax lr=0.0300, decay_step=3, decay_rate=0.75, grad_clip=0.25
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'language_model.WordEmbedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Iter: 40, Loss 0.041809, Num updates: 40, Wall time: 5.34, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.026677, Num updates: 80, Wall time: 8.20, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.021343, Num updates: 120, Wall time: 10.96, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.018611, Num updates: 160, Wall time: 13.98, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 0, time: 31.54
	train_loss: 0.0175, score: 17.68
	eval score: 5.13 (15.69)
Iter: 40, Loss 0.009624, Num updates: 40, Wall time: 38.25, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.009727, Num updates: 80, Wall time: 41.05, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.009730, Num updates: 120, Wall time: 43.85, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.009652, Num updates: 160, Wall time: 46.97, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 1, time: 30.09
	train_loss: 0.0097, score: 22.09
	eval score: 5.10 (15.69)
Iter: 40, Loss 0.009210, Num updates: 40, Wall time: 68.51, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.009308, Num updates: 80, Wall time: 71.33, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.009284, Num updates: 120, Wall time: 74.35, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.009210, Num updates: 160, Wall time: 77.40, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 2, time: 30.97
	train_loss: 0.0092, score: 23.03
	eval score: 6.91 (15.69)
Iter: 40, Loss 0.008616, Num updates: 40, Wall time: 100.89, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.008638, Num updates: 80, Wall time: 104.01, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.008693, Num updates: 120, Wall time: 106.95, ETA: 0m 10s (- 0m 6s)
Iter: 160, Loss 0.008639, Num updates: 160, Wall time: 109.82, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 3, time: 27.77
	train_loss: 0.0087, score: 22.89
	eval score: 7.63 (15.69)
Iter: 40, Loss 0.008160, Num updates: 40, Wall time: 129.98, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.008150, Num updates: 80, Wall time: 132.85, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.008188, Num updates: 120, Wall time: 135.98, ETA: 0m 10s (- 0m 6s)
Iter: 160, Loss 0.008214, Num updates: 160, Wall time: 138.97, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 4, time: 29.90
	train_loss: 0.0083, score: 24.43
	eval score: 8.42 (15.69)
Iter: 40, Loss 0.007906, Num updates: 40, Wall time: 161.07, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.007890, Num updates: 80, Wall time: 164.06, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.007870, Num updates: 120, Wall time: 167.10, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.007923, Num updates: 160, Wall time: 170.11, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 5, time: 29.82
	train_loss: 0.0080, score: 24.16
	eval score: 8.73 (15.69)
Iter: 40, Loss 0.007568, Num updates: 40, Wall time: 192.54, ETA: 0m 4s (- 0m 18s)
Iter: 80, Loss 0.007668, Num updates: 80, Wall time: 195.42, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.007734, Num updates: 120, Wall time: 198.28, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.007696, Num updates: 160, Wall time: 201.22, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 6, time: 30.18
	train_loss: 0.0077, score: 24.10
	eval score: 8.18 (15.69)
Iter: 40, Loss 0.007349, Num updates: 40, Wall time: 222.75, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.007447, Num updates: 80, Wall time: 225.48, ETA: 0m 7s (- 0m 9s)
Iter: 120, Loss 0.007504, Num updates: 120, Wall time: 228.49, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.007519, Num updates: 160, Wall time: 231.42, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 7, time: 30.02
	train_loss: 0.0076, score: 24.77
	eval score: 9.23 (15.69)
Iter: 40, Loss 0.007356, Num updates: 40, Wall time: 254.08, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.007343, Num updates: 80, Wall time: 257.07, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.007343, Num updates: 120, Wall time: 260.11, ETA: 0m 10s (- 0m 6s)
Iter: 160, Loss 0.007352, Num updates: 160, Wall time: 262.73, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 8, time: 30.81
	train_loss: 0.0074, score: 24.92
	eval score: 9.75 (15.69)
Iter: 40, Loss 0.006879, Num updates: 40, Wall time: 286.28, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.007090, Num updates: 80, Wall time: 289.16, ETA: 0m 7s (- 0m 9s)
Iter: 120, Loss 0.007185, Num updates: 120, Wall time: 292.11, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.007167, Num updates: 160, Wall time: 294.90, ETA: 0m 12s (- 0m 2s)
Evaluating...
epoch 9, time: 29.61
	train_loss: 0.0072, score: 24.62
	eval score: 9.57 (15.69)
Iter: 40, Loss 0.007026, Num updates: 40, Wall time: 316.24, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.007009, Num updates: 80, Wall time: 319.41, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.007032, Num updates: 120, Wall time: 322.17, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.007072, Num updates: 160, Wall time: 324.96, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 10, time: 29.63
	train_loss: 0.0071, score: 25.60
	eval score: 9.95 (15.69)
Iter: 40, Loss 0.006842, Num updates: 40, Wall time: 347.31, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.006938, Num updates: 80, Wall time: 350.49, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.006934, Num updates: 120, Wall time: 353.59, ETA: 0m 10s (- 0m 6s)
Iter: 160, Loss 0.006958, Num updates: 160, Wall time: 356.70, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 11, time: 30.09
	train_loss: 0.0070, score: 26.34
	eval score: 10.09 (15.69)
Iter: 40, Loss 0.006781, Num updates: 40, Wall time: 378.76, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.006772, Num updates: 80, Wall time: 381.51, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.006860, Num updates: 120, Wall time: 384.24, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.006849, Num updates: 160, Wall time: 387.05, ETA: 0m 12s (- 0m 2s)
Evaluating...
epoch 12, time: 29.65
	train_loss: 0.0069, score: 26.09
	eval score: 10.72 (15.69)
Iter: 40, Loss 0.006518, Num updates: 40, Wall time: 410.12, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.006752, Num updates: 80, Wall time: 412.81, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.006800, Num updates: 120, Wall time: 415.67, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.006808, Num updates: 160, Wall time: 418.71, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 13, time: 29.95
	train_loss: 0.0068, score: 26.17
	eval score: 10.09 (15.69)
Iter: 40, Loss 0.006377, Num updates: 40, Wall time: 439.98, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.006572, Num updates: 80, Wall time: 443.17, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.006653, Num updates: 120, Wall time: 446.11, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.006665, Num updates: 160, Wall time: 448.76, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 14, time: 30.47
	train_loss: 0.0067, score: 27.04
	eval score: 10.35 (15.69)
Iter: 40, Loss 0.006423, Num updates: 40, Wall time: 470.96, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.006527, Num updates: 80, Wall time: 474.15, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.006587, Num updates: 120, Wall time: 477.16, ETA: 0m 10s (- 0m 6s)
Iter: 160, Loss 0.006611, Num updates: 160, Wall time: 480.08, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 15, time: 30.90
	train_loss: 0.0066, score: 27.21
	eval score: 10.81 (15.69)
Iter: 40, Loss 0.006391, Num updates: 40, Wall time: 502.81, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.006462, Num updates: 80, Wall time: 505.65, ETA: 0m 7s (- 0m 9s)
Iter: 120, Loss 0.006459, Num updates: 120, Wall time: 508.63, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.006505, Num updates: 160, Wall time: 511.52, ETA: 0m 12s (- 0m 2s)
Evaluating...
epoch 16, time: 31.58
	train_loss: 0.0065, score: 27.22
	eval score: 10.34 (15.69)
Iter: 40, Loss 0.006354, Num updates: 40, Wall time: 535.12, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.006411, Num updates: 80, Wall time: 538.09, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.006421, Num updates: 120, Wall time: 540.92, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.006442, Num updates: 160, Wall time: 543.68, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 17, time: 30.83
	train_loss: 0.0065, score: 27.27
	eval score: 10.92 (15.69)
Iter: 40, Loss 0.006115, Num updates: 40, Wall time: 566.74, ETA: 0m 4s (- 0m 15s)
Iter: 80, Loss 0.006295, Num updates: 80, Wall time: 569.64, ETA: 0m 7s (- 0m 9s)
Iter: 120, Loss 0.006330, Num updates: 120, Wall time: 572.88, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.006369, Num updates: 160, Wall time: 575.90, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 18, time: 29.40
	train_loss: 0.0064, score: 27.14
	eval score: 10.58 (15.69)
Iter: 40, Loss 0.006160, Num updates: 40, Wall time: 596.60, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.006219, Num updates: 80, Wall time: 599.72, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.006292, Num updates: 120, Wall time: 602.78, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.006329, Num updates: 160, Wall time: 605.67, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 19, time: 31.31
	train_loss: 0.0064, score: 28.39
	eval score: 10.93 (15.69)
Iter: 40, Loss 0.006251, Num updates: 40, Wall time: 629.68, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.006292, Num updates: 80, Wall time: 632.32, ETA: 0m 7s (- 0m 9s)
Iter: 120, Loss 0.006321, Num updates: 120, Wall time: 635.15, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.006293, Num updates: 160, Wall time: 638.05, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 20, time: 30.10
	train_loss: 0.0063, score: 28.26
	eval score: 10.99 (15.69)
Iter: 40, Loss 0.006028, Num updates: 40, Wall time: 660.71, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.006182, Num updates: 80, Wall time: 663.38, ETA: 0m 6s (- 0m 9s)
Iter: 120, Loss 0.006227, Num updates: 120, Wall time: 666.12, ETA: 0m 9s (- 0m 5s)
Iter: 160, Loss 0.006238, Num updates: 160, Wall time: 668.94, ETA: 0m 12s (- 0m 2s)
Evaluating...
epoch 21, time: 29.20
	train_loss: 0.0063, score: 28.63
	eval score: 11.27 (15.69)
Iter: 40, Loss 0.005996, Num updates: 40, Wall time: 691.58, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.006097, Num updates: 80, Wall time: 694.56, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.006169, Num updates: 120, Wall time: 697.38, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.006175, Num updates: 160, Wall time: 700.15, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 22, time: 29.63
	train_loss: 0.0062, score: 28.76
	eval score: 11.30 (15.69)
Iter: 40, Loss 0.005950, Num updates: 40, Wall time: 722.23, ETA: 0m 4s (- 0m 15s)
Iter: 80, Loss 0.006044, Num updates: 80, Wall time: 725.07, ETA: 0m 6s (- 0m 9s)
Iter: 120, Loss 0.006113, Num updates: 120, Wall time: 728.24, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.006125, Num updates: 160, Wall time: 731.30, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 23, time: 32.34
	train_loss: 0.0062, score: 28.61
	eval score: 11.24 (15.69)
Iter: 40, Loss 0.005878, Num updates: 40, Wall time: 754.78, ETA: 0m 4s (- 0m 15s)
Iter: 80, Loss 0.006019, Num updates: 80, Wall time: 757.62, ETA: 0m 6s (- 0m 9s)
Iter: 120, Loss 0.006042, Num updates: 120, Wall time: 760.43, ETA: 0m 9s (- 0m 5s)
Iter: 160, Loss 0.006062, Num updates: 160, Wall time: 763.32, ETA: 0m 12s (- 0m 2s)
Evaluating...
epoch 24, time: 29.24
	train_loss: 0.0061, score: 28.26
	eval score: 11.39 (15.69)
Iter: 40, Loss 0.006024, Num updates: 40, Wall time: 785.92, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.006025, Num updates: 80, Wall time: 788.70, ETA: 0m 7s (- 0m 9s)
Iter: 120, Loss 0.006038, Num updates: 120, Wall time: 791.33, ETA: 0m 9s (- 0m 5s)
Iter: 160, Loss 0.006046, Num updates: 160, Wall time: 794.35, ETA: 0m 12s (- 0m 2s)
Evaluating...
epoch 25, time: 28.56
	train_loss: 0.0061, score: 29.50
	eval score: 11.18 (15.69)
Iter: 40, Loss 0.005973, Num updates: 40, Wall time: 814.96, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.005983, Num updates: 80, Wall time: 817.84, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.005978, Num updates: 120, Wall time: 820.55, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.005983, Num updates: 160, Wall time: 823.71, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 26, time: 29.56
	train_loss: 0.0060, score: 28.58
	eval score: 11.36 (15.69)
Iter: 40, Loss 0.005826, Num updates: 40, Wall time: 844.83, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.005889, Num updates: 80, Wall time: 847.71, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.005934, Num updates: 120, Wall time: 850.78, ETA: 0m 10s (- 0m 6s)
Iter: 160, Loss 0.005959, Num updates: 160, Wall time: 853.63, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 27, time: 29.17
	train_loss: 0.0060, score: 29.58
	eval score: 11.27 (15.69)
Iter: 40, Loss 0.005778, Num updates: 40, Wall time: 873.70, ETA: 0m 4s (- 0m 15s)
Iter: 80, Loss 0.005839, Num updates: 80, Wall time: 876.63, ETA: 0m 7s (- 0m 9s)
Iter: 120, Loss 0.005885, Num updates: 120, Wall time: 879.64, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.005891, Num updates: 160, Wall time: 882.60, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 28, time: 30.49
	train_loss: 0.0059, score: 30.13
	eval score: 11.14 (15.69)
Iter: 40, Loss 0.005708, Num updates: 40, Wall time: 904.92, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.005789, Num updates: 80, Wall time: 907.87, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.005843, Num updates: 120, Wall time: 910.94, ETA: 0m 10s (- 0m 6s)
Iter: 160, Loss 0.005869, Num updates: 160, Wall time: 913.68, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 29, time: 28.87
	train_loss: 0.0059, score: 29.75
	eval score: 11.20 (15.69)
Iter: 40, Loss 0.005678, Num updates: 40, Wall time: 933.95, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.005802, Num updates: 80, Wall time: 936.86, ETA: 0m 7s (- 0m 9s)
Iter: 120, Loss 0.005828, Num updates: 120, Wall time: 939.73, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.005849, Num updates: 160, Wall time: 942.73, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 30, time: 28.91
	train_loss: 0.0059, score: 29.88
	eval score: 11.27 (15.69)
Iter: 40, Loss 0.005575, Num updates: 40, Wall time: 963.21, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.005689, Num updates: 80, Wall time: 965.84, ETA: 0m 7s (- 0m 9s)
Iter: 120, Loss 0.005746, Num updates: 120, Wall time: 968.65, ETA: 0m 9s (- 0m 5s)
Iter: 160, Loss 0.005818, Num updates: 160, Wall time: 971.49, ETA: 0m 12s (- 0m 2s)
Evaluating...
epoch 31, time: 29.40
	train_loss: 0.0059, score: 30.40
	eval score: 11.43 (15.69)
Iter: 40, Loss 0.005645, Num updates: 40, Wall time: 993.68, ETA: 0m 4s (- 0m 15s)
Iter: 80, Loss 0.005708, Num updates: 80, Wall time: 996.76, ETA: 0m 7s (- 0m 9s)
Iter: 120, Loss 0.005742, Num updates: 120, Wall time: 999.83, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.005762, Num updates: 160, Wall time: 1002.88, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 32, time: 29.61
	train_loss: 0.0058, score: 29.81
	eval score: 11.18 (15.69)
Iter: 40, Loss 0.005621, Num updates: 40, Wall time: 1023.95, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.005676, Num updates: 80, Wall time: 1026.80, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.005733, Num updates: 120, Wall time: 1029.74, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.005756, Num updates: 160, Wall time: 1032.64, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 33, time: 31.01
	train_loss: 0.0058, score: 31.43
	eval score: 11.33 (15.69)
Iter: 40, Loss 0.005631, Num updates: 40, Wall time: 1055.37, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.005703, Num updates: 80, Wall time: 1058.36, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.005675, Num updates: 120, Wall time: 1061.37, ETA: 0m 10s (- 0m 6s)
Iter: 160, Loss 0.005715, Num updates: 160, Wall time: 1064.40, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 34, time: 29.98
	train_loss: 0.0057, score: 30.31
	eval score: 11.55 (15.69)
Iter: 40, Loss 0.005559, Num updates: 40, Wall time: 1086.01, ETA: 0m 4s (- 0m 15s)
Iter: 80, Loss 0.005634, Num updates: 80, Wall time: 1088.86, ETA: 0m 6s (- 0m 9s)
Iter: 120, Loss 0.005672, Num updates: 120, Wall time: 1091.80, ETA: 0m 9s (- 0m 5s)
Iter: 160, Loss 0.005696, Num updates: 160, Wall time: 1094.56, ETA: 0m 12s (- 0m 2s)
Evaluating...
epoch 35, time: 28.52
	train_loss: 0.0057, score: 30.13
	eval score: 11.48 (15.69)
Iter: 40, Loss 0.005534, Num updates: 40, Wall time: 1114.72, ETA: 0m 3s (- 0m 15s)
Iter: 80, Loss 0.005645, Num updates: 80, Wall time: 1117.59, ETA: 0m 6s (- 0m 9s)
Iter: 120, Loss 0.005658, Num updates: 120, Wall time: 1120.58, ETA: 0m 9s (- 0m 5s)
Iter: 160, Loss 0.005674, Num updates: 160, Wall time: 1123.21, ETA: 0m 12s (- 0m 2s)
Evaluating...
epoch 36, time: 29.17
	train_loss: 0.0057, score: 30.50
	eval score: 11.60 (15.69)
Iter: 40, Loss 0.005520, Num updates: 40, Wall time: 1145.80, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.005588, Num updates: 80, Wall time: 1148.68, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.005621, Num updates: 120, Wall time: 1151.65, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.005627, Num updates: 160, Wall time: 1154.64, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 37, time: 28.46
	train_loss: 0.0057, score: 30.51
	eval score: 11.39 (15.69)
Iter: 40, Loss 0.005491, Num updates: 40, Wall time: 1174.92, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.005555, Num updates: 80, Wall time: 1177.94, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.005590, Num updates: 120, Wall time: 1180.69, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.005609, Num updates: 160, Wall time: 1183.74, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 38, time: 30.88
	train_loss: 0.0057, score: 30.82
	eval score: 11.51 (15.69)
Iter: 40, Loss 0.005485, Num updates: 40, Wall time: 1206.22, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.005545, Num updates: 80, Wall time: 1209.03, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.005544, Num updates: 120, Wall time: 1211.93, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.005569, Num updates: 160, Wall time: 1215.00, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 39, time: 29.39
	train_loss: 0.0056, score: 30.82
	eval score: 11.60 (15.69)
Iter: 40, Loss 0.005444, Num updates: 40, Wall time: 1235.32, ETA: 0m 4s (- 0m 15s)
Iter: 80, Loss 0.005501, Num updates: 80, Wall time: 1238.16, ETA: 0m 6s (- 0m 9s)
Iter: 120, Loss 0.005541, Num updates: 120, Wall time: 1241.12, ETA: 0m 9s (- 0m 5s)
Iter: 160, Loss 0.005564, Num updates: 160, Wall time: 1244.02, ETA: 0m 12s (- 0m 2s)
Evaluating...
epoch 40, time: 29.85
	train_loss: 0.0056, score: 31.23
	eval score: 11.67 (15.69)
Iter: 40, Loss 0.005411, Num updates: 40, Wall time: 1266.85, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.005519, Num updates: 80, Wall time: 1269.53, ETA: 0m 7s (- 0m 9s)
Iter: 120, Loss 0.005514, Num updates: 120, Wall time: 1272.34, ETA: 0m 9s (- 0m 5s)
Iter: 160, Loss 0.005521, Num updates: 160, Wall time: 1275.07, ETA: 0m 12s (- 0m 2s)
Evaluating...
epoch 41, time: 30.59
	train_loss: 0.0056, score: 30.82
	eval score: 11.49 (15.69)
Iter: 40, Loss 0.005367, Num updates: 40, Wall time: 1297.65, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.005459, Num updates: 80, Wall time: 1300.64, ETA: 0m 7s (- 0m 9s)
Iter: 120, Loss 0.005503, Num updates: 120, Wall time: 1303.51, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.005513, Num updates: 160, Wall time: 1306.32, ETA: 0m 12s (- 0m 2s)
Evaluating...
epoch 42, time: 29.73
	train_loss: 0.0056, score: 30.25
	eval score: 11.63 (15.69)
Iter: 40, Loss 0.005363, Num updates: 40, Wall time: 1327.85, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.005426, Num updates: 80, Wall time: 1330.84, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.005478, Num updates: 120, Wall time: 1333.71, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.005496, Num updates: 160, Wall time: 1336.83, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 43, time: 28.94
	train_loss: 0.0055, score: 30.50
	eval score: 11.60 (15.69)
Iter: 40, Loss 0.005310, Num updates: 40, Wall time: 1356.95, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.005418, Num updates: 80, Wall time: 1359.74, ETA: 0m 7s (- 0m 9s)
Iter: 120, Loss 0.005431, Num updates: 120, Wall time: 1362.55, ETA: 0m 9s (- 0m 5s)
Iter: 160, Loss 0.005449, Num updates: 160, Wall time: 1365.39, ETA: 0m 12s (- 0m 2s)
Evaluating...
epoch 44, time: 30.33
	train_loss: 0.0055, score: 30.87
	eval score: 11.64 (15.69)
Iter: 40, Loss 0.005292, Num updates: 40, Wall time: 1387.43, ETA: 0m 4s (- 0m 15s)
Iter: 80, Loss 0.005393, Num updates: 80, Wall time: 1390.48, ETA: 0m 7s (- 0m 9s)
Iter: 120, Loss 0.005422, Num updates: 120, Wall time: 1393.36, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.005444, Num updates: 160, Wall time: 1396.25, ETA: 0m 12s (- 0m 2s)
Evaluating...
epoch 45, time: 29.48
	train_loss: 0.0055, score: 30.85
	eval score: 11.70 (15.69)
Iter: 40, Loss 0.005283, Num updates: 40, Wall time: 1418.64, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.005389, Num updates: 80, Wall time: 1421.66, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.005422, Num updates: 120, Wall time: 1424.46, ETA: 0m 10s (- 0m 6s)
Iter: 160, Loss 0.005429, Num updates: 160, Wall time: 1427.53, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 46, time: 27.89
	train_loss: 0.0055, score: 31.30
	eval score: 11.71 (15.69)
Iter: 40, Loss 0.005320, Num updates: 40, Wall time: 1447.67, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.005363, Num updates: 80, Wall time: 1450.50, ETA: 0m 7s (- 0m 9s)
Iter: 120, Loss 0.005386, Num updates: 120, Wall time: 1453.57, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.005415, Num updates: 160, Wall time: 1456.41, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 47, time: 29.29
	train_loss: 0.0055, score: 31.20
	eval score: 11.64 (15.69)
Iter: 40, Loss 0.005314, Num updates: 40, Wall time: 1477.14, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.005350, Num updates: 80, Wall time: 1479.99, ETA: 0m 7s (- 0m 9s)
Iter: 120, Loss 0.005366, Num updates: 120, Wall time: 1482.83, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.005381, Num updates: 160, Wall time: 1485.70, ETA: 0m 12s (- 0m 2s)
Evaluating...
epoch 48, time: 29.05
	train_loss: 0.0054, score: 30.85
	eval score: 11.71 (15.69)
Iter: 40, Loss 0.005295, Num updates: 40, Wall time: 1506.74, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.005292, Num updates: 80, Wall time: 1509.37, ETA: 0m 7s (- 0m 9s)
Iter: 120, Loss 0.005329, Num updates: 120, Wall time: 1512.06, ETA: 0m 9s (- 0m 5s)
Iter: 160, Loss 0.005352, Num updates: 160, Wall time: 1514.99, ETA: 0m 12s (- 0m 2s)
Evaluating...
epoch 49, time: 29.63
	train_loss: 0.0054, score: 31.18
	eval score: 11.67 (15.69)
Iter: 40, Loss 0.005249, Num updates: 40, Wall time: 1536.40, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.005330, Num updates: 80, Wall time: 1539.23, ETA: 0m 7s (- 0m 9s)
Iter: 120, Loss 0.005364, Num updates: 120, Wall time: 1541.78, ETA: 0m 9s (- 0m 5s)
Iter: 160, Loss 0.005365, Num updates: 160, Wall time: 1544.80, ETA: 0m 12s (- 0m 2s)
Evaluating...
epoch 50, time: 29.84
	train_loss: 0.0054, score: 30.60
	eval score: 11.68 (15.69)
Iter: 40, Loss 0.005187, Num updates: 40, Wall time: 1566.61, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.005306, Num updates: 80, Wall time: 1569.36, ETA: 0m 7s (- 0m 9s)
Iter: 120, Loss 0.005343, Num updates: 120, Wall time: 1572.30, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.005359, Num updates: 160, Wall time: 1575.12, ETA: 0m 12s (- 0m 2s)
Evaluating...
epoch 51, time: 30.39
	train_loss: 0.0054, score: 30.16
	eval score: 11.74 (15.69)
Iter: 40, Loss 0.005170, Num updates: 40, Wall time: 1597.56, ETA: 0m 3s (- 0m 14s)
Iter: 80, Loss 0.005279, Num updates: 80, Wall time: 1600.47, ETA: 0m 6s (- 0m 9s)
Iter: 120, Loss 0.005276, Num updates: 120, Wall time: 1603.31, ETA: 0m 9s (- 0m 5s)
Iter: 160, Loss 0.005307, Num updates: 160, Wall time: 1606.11, ETA: 0m 12s (- 0m 2s)
Evaluating...
epoch 52, time: 29.08
	train_loss: 0.0053, score: 31.22
	eval score: 11.92 (15.69)
Iter: 40, Loss 0.005227, Num updates: 40, Wall time: 1628.61, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.005241, Num updates: 80, Wall time: 1631.34, ETA: 0m 7s (- 0m 9s)
Iter: 120, Loss 0.005268, Num updates: 120, Wall time: 1634.41, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.005296, Num updates: 160, Wall time: 1637.44, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 53, time: 29.03
	train_loss: 0.0053, score: 31.38
	eval score: 11.74 (15.69)
Iter: 40, Loss 0.005170, Num updates: 40, Wall time: 1657.80, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.005260, Num updates: 80, Wall time: 1660.76, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.005291, Num updates: 120, Wall time: 1663.45, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.005296, Num updates: 160, Wall time: 1666.06, ETA: 0m 12s (- 0m 2s)
Evaluating...
epoch 54, time: 29.18
	train_loss: 0.0053, score: 32.05
	eval score: 11.80 (15.69)
Iter: 40, Loss 0.005172, Num updates: 40, Wall time: 1687.36, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.005251, Num updates: 80, Wall time: 1690.37, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.005267, Num updates: 120, Wall time: 1693.00, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.005283, Num updates: 160, Wall time: 1695.98, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 55, time: 29.29
	train_loss: 0.0053, score: 30.67
	eval score: 11.95 (15.69)
Iter: 40, Loss 0.005136, Num updates: 40, Wall time: 1718.38, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.005208, Num updates: 80, Wall time: 1721.33, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.005245, Num updates: 120, Wall time: 1724.13, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.005261, Num updates: 160, Wall time: 1727.06, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 56, time: 30.53
	train_loss: 0.0053, score: 31.15
	eval score: 11.79 (15.69)
Iter: 40, Loss 0.005095, Num updates: 40, Wall time: 1748.68, ETA: 0m 4s (- 0m 15s)
Iter: 80, Loss 0.005171, Num updates: 80, Wall time: 1751.69, ETA: 0m 7s (- 0m 9s)
Iter: 120, Loss 0.005213, Num updates: 120, Wall time: 1754.84, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.005227, Num updates: 160, Wall time: 1757.98, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 57, time: 31.16
	train_loss: 0.0053, score: 31.70
	eval score: 11.85 (15.69)
Iter: 40, Loss 0.005127, Num updates: 40, Wall time: 1780.51, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.005197, Num updates: 80, Wall time: 1783.38, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.005236, Num updates: 120, Wall time: 1786.31, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.005238, Num updates: 160, Wall time: 1789.19, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 58, time: 29.97
	train_loss: 0.0053, score: 31.89
	eval score: 11.94 (15.69)
Iter: 40, Loss 0.005098, Num updates: 40, Wall time: 1810.79, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.005165, Num updates: 80, Wall time: 1813.79, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.005223, Num updates: 120, Wall time: 1816.75, ETA: 0m 10s (- 0m 6s)
Iter: 160, Loss 0.005238, Num updates: 160, Wall time: 1819.67, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 59, time: 27.76
	train_loss: 0.0053, score: 30.41
	eval score: 11.80 (15.69)
Iter: 40, Loss 0.005072, Num updates: 40, Wall time: 1838.59, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.005138, Num updates: 80, Wall time: 1841.25, ETA: 0m 7s (- 0m 9s)
Iter: 120, Loss 0.005170, Num updates: 120, Wall time: 1844.03, ETA: 0m 9s (- 0m 5s)
Iter: 160, Loss 0.005190, Num updates: 160, Wall time: 1846.82, ETA: 0m 12s (- 0m 2s)
Evaluating...
epoch 60, time: 29.55
	train_loss: 0.0052, score: 31.35
	eval score: 11.98 (15.69)
Iter: 40, Loss 0.005075, Num updates: 40, Wall time: 1869.18, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.005136, Num updates: 80, Wall time: 1871.95, ETA: 0m 7s (- 0m 9s)
Iter: 120, Loss 0.005187, Num updates: 120, Wall time: 1874.64, ETA: 0m 9s (- 0m 5s)
Iter: 160, Loss 0.005199, Num updates: 160, Wall time: 1877.42, ETA: 0m 12s (- 0m 2s)
Evaluating...
epoch 61, time: 29.23
	train_loss: 0.0052, score: 31.25
	eval score: 11.77 (15.69)
Iter: 40, Loss 0.005020, Num updates: 40, Wall time: 1899.08, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.005102, Num updates: 80, Wall time: 1902.39, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.005160, Num updates: 120, Wall time: 1905.29, ETA: 0m 10s (- 0m 6s)
Iter: 160, Loss 0.005175, Num updates: 160, Wall time: 1908.09, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 62, time: 29.71
	train_loss: 0.0052, score: 31.58
	eval score: 11.77 (15.69)
Iter: 40, Loss 0.004995, Num updates: 40, Wall time: 1929.02, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.005098, Num updates: 80, Wall time: 1932.07, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.005158, Num updates: 120, Wall time: 1934.91, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.005166, Num updates: 160, Wall time: 1937.83, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 63, time: 30.13
	train_loss: 0.0052, score: 30.67
	eval score: 12.02 (15.69)
Iter: 40, Loss 0.005004, Num updates: 40, Wall time: 1960.83, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.005121, Num updates: 80, Wall time: 1963.92, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.005145, Num updates: 120, Wall time: 1966.74, ETA: 0m 10s (- 0m 6s)
Iter: 160, Loss 0.005174, Num updates: 160, Wall time: 1969.68, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 64, time: 29.35
	train_loss: 0.0052, score: 31.10
	eval score: 11.88 (15.69)
Iter: 40, Loss 0.005063, Num updates: 40, Wall time: 1990.38, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.005115, Num updates: 80, Wall time: 1993.37, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.005153, Num updates: 120, Wall time: 1996.36, ETA: 0m 10s (- 0m 6s)
Iter: 160, Loss 0.005179, Num updates: 160, Wall time: 1999.49, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 65, time: 29.99
	train_loss: 0.0052, score: 31.02
	eval score: 11.88 (15.69)
Iter: 40, Loss 0.004997, Num updates: 40, Wall time: 2019.95, ETA: 0m 3s (- 0m 14s)
Iter: 80, Loss 0.005076, Num updates: 80, Wall time: 2022.71, ETA: 0m 6s (- 0m 9s)
Iter: 120, Loss 0.005118, Num updates: 120, Wall time: 2025.29, ETA: 0m 9s (- 0m 5s)
Iter: 160, Loss 0.005125, Num updates: 160, Wall time: 2028.11, ETA: 0m 12s (- 0m 2s)
Evaluating...
epoch 66, time: 28.26
	train_loss: 0.0052, score: 31.48
	eval score: 12.05 (15.69)
Iter: 40, Loss 0.005005, Num updates: 40, Wall time: 2049.73, ETA: 0m 4s (- 0m 15s)
Iter: 80, Loss 0.005110, Num updates: 80, Wall time: 2052.57, ETA: 0m 6s (- 0m 9s)
Iter: 120, Loss 0.005143, Num updates: 120, Wall time: 2055.53, ETA: 0m 9s (- 0m 5s)
Iter: 160, Loss 0.005158, Num updates: 160, Wall time: 2058.45, ETA: 0m 12s (- 0m 2s)
Evaluating...
epoch 67, time: 31.87
	train_loss: 0.0052, score: 30.95
	eval score: 12.20 (15.69)
Iter: 40, Loss 0.005021, Num updates: 40, Wall time: 2083.00, ETA: 0m 4s (- 0m 15s)
Iter: 80, Loss 0.005090, Num updates: 80, Wall time: 2085.79, ETA: 0m 6s (- 0m 9s)
Iter: 120, Loss 0.005114, Num updates: 120, Wall time: 2088.89, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.005133, Num updates: 160, Wall time: 2091.79, ETA: 0m 12s (- 0m 2s)
Evaluating...
epoch 68, time: 29.74
	train_loss: 0.0052, score: 31.70
	eval score: 11.92 (15.69)
Iter: 40, Loss 0.005000, Num updates: 40, Wall time: 2113.29, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.005093, Num updates: 80, Wall time: 2116.22, ETA: 0m 7s (- 0m 9s)
Iter: 120, Loss 0.005125, Num updates: 120, Wall time: 2119.17, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.005123, Num updates: 160, Wall time: 2122.14, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 69, time: 30.14
	train_loss: 0.0052, score: 31.10
	eval score: 11.95 (15.69)
Iter: 40, Loss 0.005036, Num updates: 40, Wall time: 2143.61, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.005083, Num updates: 80, Wall time: 2146.52, ETA: 0m 7s (- 0m 9s)
Iter: 120, Loss 0.005111, Num updates: 120, Wall time: 2149.66, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.005135, Num updates: 160, Wall time: 2152.80, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 70, time: 31.14
	train_loss: 0.0052, score: 30.85
	eval score: 11.79 (15.69)
Iter: 40, Loss 0.004988, Num updates: 40, Wall time: 2174.89, ETA: 0m 4s (- 0m 15s)
Iter: 80, Loss 0.005037, Num updates: 80, Wall time: 2177.88, ETA: 0m 7s (- 0m 9s)
Iter: 120, Loss 0.005063, Num updates: 120, Wall time: 2180.81, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.005082, Num updates: 160, Wall time: 2183.75, ETA: 0m 12s (- 0m 2s)
Evaluating...
epoch 71, time: 30.01
	train_loss: 0.0051, score: 31.20
	eval score: 12.01 (15.69)
Iter: 40, Loss 0.004978, Num updates: 40, Wall time: 2205.53, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.005030, Num updates: 80, Wall time: 2208.52, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.005090, Num updates: 120, Wall time: 2211.45, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.005112, Num updates: 160, Wall time: 2214.38, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 72, time: 29.96
	train_loss: 0.0051, score: 31.63
	eval score: 11.97 (15.69)
Iter: 40, Loss 0.004980, Num updates: 40, Wall time: 2235.48, ETA: 0m 4s (- 0m 15s)
Iter: 80, Loss 0.005048, Num updates: 80, Wall time: 2238.43, ETA: 0m 7s (- 0m 9s)
Iter: 120, Loss 0.005061, Num updates: 120, Wall time: 2241.20, ETA: 0m 9s (- 0m 5s)
Iter: 160, Loss 0.005075, Num updates: 160, Wall time: 2244.07, ETA: 0m 12s (- 0m 2s)
Evaluating...
epoch 73, time: 29.01
	train_loss: 0.0051, score: 32.35
	eval score: 12.07 (15.69)
Iter: 40, Loss 0.004907, Num updates: 40, Wall time: 2265.22, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.004997, Num updates: 80, Wall time: 2268.11, ETA: 0m 7s (- 0m 10s)
Iter: 120, Loss 0.005055, Num updates: 120, Wall time: 2271.27, ETA: 0m 10s (- 0m 6s)
Iter: 160, Loss 0.005072, Num updates: 160, Wall time: 2274.43, ETA: 0m 13s (- 0m 2s)
Evaluating...
epoch 74, time: 29.12
	train_loss: 0.0051, score: 30.80
	eval score: 12.08 (15.69)
Iter: 40, Loss 0.004937, Num updates: 40, Wall time: 2294.59, ETA: 0m 4s (- 0m 17s)
Iter: 80, Loss 0.005010, Num updates: 80, Wall time: 2297.21, ETA: 0m 7s (- 0m 9s)
Iter: 120, Loss 0.005058, Num updates: 120, Wall time: 2300.14, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.005073, Num updates: 160, Wall time: 2302.94, ETA: 0m 12s (- 0m 2s)
Evaluating...
epoch 75, time: 30.38
	train_loss: 0.0051, score: 30.38
	eval score: 11.97 (15.69)
Iter: 40, Loss 0.004943, Num updates: 40, Wall time: 2324.95, ETA: 0m 4s (- 0m 15s)
Iter: 80, Loss 0.005011, Num updates: 80, Wall time: 2327.86, ETA: 0m 7s (- 0m 9s)
Iter: 120, Loss 0.005032, Num updates: 120, Wall time: 2330.80, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.005056, Num updates: 160, Wall time: 2333.76, ETA: 0m 12s (- 0m 2s)
Evaluating...
epoch 76, time: 30.20
	train_loss: 0.0051, score: 31.80
	eval score: 12.05 (15.69)
Iter: 40, Loss 0.004926, Num updates: 40, Wall time: 2355.70, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.005016, Num updates: 80, Wall time: 2358.59, ETA: 0m 7s (- 0m 9s)
Iter: 120, Loss 0.005037, Num updates: 120, Wall time: 2361.22, ETA: 0m 9s (- 0m 5s)
Iter: 160, Loss 0.005039, Num updates: 160, Wall time: 2364.00, ETA: 0m 12s (- 0m 2s)
Evaluating...
epoch 77, time: 28.80
	train_loss: 0.0051, score: 31.17
	eval score: 12.00 (15.69)
Iter: 40, Loss 0.004925, Num updates: 40, Wall time: 2384.70, ETA: 0m 4s (- 0m 16s)
Iter: 80, Loss 0.004982, Num updates: 80, Wall time: 2387.58, ETA: 0m 7s (- 0m 9s)
Iter: 120, Loss 0.005009, Num updates: 120, Wall time: 2390.71, ETA: 0m 10s (- 0m 5s)
Iter: 160, Loss 0.005044, Num updates: 160, Wall time: 2393.33, ETA: 0m 12s (- 0m 2s)
Evaluating...
epoch 78, time: 29.91
	train_loss: 0.0051, score: 31.30
	eval score: 11.95 (15.69)
Iter: 40, Loss 0.004945, Num updates: 40, Wall time: 2414.67, ETA: 0m 4s (- 0m 15s)
Iter: 80, Loss 0.004988, Num updates: 80, Wall time: 2417.46, ETA: 0m 6s (- 0m 9s)
Iter: 120, Loss 0.005020, Num updates: 120, Wall time: 2420.34, ETA: 0m 9s (- 0m 5s)
Iter: 160, Loss 0.005040, Num updates: 160, Wall time: 2423.20, ETA: 0m 12s (- 0m 2s)
Evaluating...
epoch 79, time: 29.66
	train_loss: 0.0051, score: 30.85
	eval score: 11.97 (15.69)
0.01749,0.0097,0.00923,0.00867,0.00826,0.00799,0.00774,0.00755,0.00739,0.0072,0.00711,0.00699,0.0069,0.00683,0.00671,0.00665,0.00655,0.00649,0.00642,0.00637,0.00633,0.00626,0.00621,0.00617,0.00611,0.00608,0.00603,0.00599,0.00594,0.00591,0.00589,0.00586,0.00581,0.00578,0.00574,0.00572,0.0057,0.00566,0.00565,0.0056,0.00559,0.00556,0.00556,0.00554,0.0055,0.00549,0.00546,0.00545,0.00542,0.00539,0.0054,0.00539,0.00534,0.00533,0.00533,0.00533,0.00529,0.00528,0.00528,0.00528,0.00525,0.00524,0.00523,0.00521,0.00521,0.00521,0.00517,0.00518,0.00518,0.00516,0.00516,0.00514,0.00514,0.00511,0.00511,0.00511,0.0051,0.00507,0.00507,0.00508
0.0024,0.00248,0.00201,0.00178,0.00159,0.00156,0.00158,0.00142,0.00139,0.00138,0.0013,0.00127,0.00123,0.0012,0.00118,0.0012,0.00119,0.0012,0.00118,0.00123,0.00118,0.0011,0.0011,0.00121,0.00108,0.00111,0.00108,0.00109,0.00107,0.0011,0.0011,0.00112,0.00117,0.00113,0.00112,0.00112,0.00116,0.00109,0.00109,0.00111,0.0011,0.00119,0.00111,0.00111,0.00111,0.00108,0.00113,0.0011,0.00111,0.0011,0.00115,0.00111,0.0011,0.0011,0.00112,0.0011,0.00114,0.00115,0.00113,0.00111,0.00112,0.00112,0.00116,0.00113,0.00112,0.00113,0.00111,0.00117,0.00115,0.00115,0.00117,0.00111,0.00115,0.00113,0.00114,0.00113,0.0011,0.00113,0.00117,0.00113
saved_model_Med2019/BAN_MEVF
Namespace(RAD_dir='/home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019', activation='relu', ae_alpha=0.001, ae_model_path='pretrained_ae.pth', alpha=1.0, autoencoder=True, batch_size=32, clip_norm=0.25, dropout=0.5, epochs=80, eps_cnn=1e-05, feat_dim=32, five_fold=False, gamma=2, gpu=0, input=None, lr=0.03, maml=True, maml_model_path='pretrained_maml.weights', model='BAN', momentum_cnn=0.05, num_hid=1024, num_stacks=2, op='c', output='saved_model_Med2019/BAN_MEVF', pow=2, print_interval=40, qc_model_path='./saved_models/QC/rad_best.pth', question_len=12, record_id=None, rescale_factor=1.5, rnn='LSTM', seed=3, tfidf=True, update_freq='1', use_RAD=True, use_ablation=False, use_ablation_q=False, use_ablation_v=False, use_counter=False, use_grad_cam=False, use_kl_mix=False, use_mix=True, use_mix_all=False, use_mix_cond=True, use_mix_cond_q=True, use_mix_cond_v=False, use_mix_cond_vq_in=False, use_mix_cond_vq_union=False, use_partial_label=False, use_rescale=False, use_sep_mix=False)
loading dictionary from /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/dictionary.pkl
loading MAML image data from file: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/images84x84.pkl
loading DAE image data from file: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/images128x128.pkl
loading MAML image data from file: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/images84x84.pkl
loading DAE image data from file: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/images128x128.pkl
load initial weights MAML from: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/pretrained_maml.weights
load initial weights DAE from: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/pretrained_ae.pth
loading dictionary from /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/dictionary.pkl
Loading embedding tfidf and weights from file
Load embedding tfidf and weights from file successfully
Namespace(RAD_dir='/home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019', activation='relu', ae_alpha=0.001, ae_model_path='pretrained_ae.pth', alpha=1.0, autoencoder=True, batch_size=32, clip_norm=0.25, device=device(type='cuda', index=0), dropout=0.5, epochs=80, eps_cnn=1e-05, feat_dim=64, five_fold=False, gamma=2, gpu=0, input=None, lr=0.03, maml=True, maml_model_path='pretrained_maml.weights', model='BAN', momentum_cnn=0.05, num_hid=1024, num_stacks=2, op='c', output='saved_model_Med2019/BAN_MEVF', pow=2, print_interval=40, qc_model_path='./saved_models/QC/rad_best.pth', question_len=12, record_id=None, rescale_factor=1.5, rnn='LSTM', seed=3, tfidf=True, update_freq='1', use_RAD=True, use_ablation=False, use_ablation_q=False, use_ablation_v=False, use_counter=False, use_grad_cam=False, use_kl_mix=False, use_mix=True, use_mix_all=False, use_mix_cond=True, use_mix_cond_q=True, use_mix_cond_v=False, use_mix_cond_vq_in=False, use_mix_cond_vq_union=False, use_partial_label=False, use_rescale=False, use_sep_mix=False)
nParams=	21342541
optim: adamax lr=0.0300, decay_step=3, decay_rate=0.75, grad_clip=0.25
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'language_model.WordEmbedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Iter: 40, Loss 0.021839, Num updates: 40, Wall time: 6.12, ETA: 0m 5s (- 0m 51s)
Iter: 80, Loss 0.012096, Num updates: 80, Wall time: 9.66, ETA: 0m 9s (- 0m 36s)
Iter: 120, Loss 0.008773, Num updates: 120, Wall time: 13.68, ETA: 0m 13s (- 0m 30s)
Iter: 160, Loss 0.007119, Num updates: 160, Wall time: 17.37, ETA: 0m 16s (- 0m 25s)
Iter: 200, Loss 0.006112, Num updates: 200, Wall time: 21.06, ETA: 0m 20s (- 0m 20s)
Iter: 240, Loss 0.005429, Num updates: 240, Wall time: 24.93, ETA: 0m 24s (- 0m 16s)
Iter: 280, Loss 0.004942, Num updates: 280, Wall time: 28.69, ETA: 0m 28s (- 0m 12s)
Iter: 320, Loss 0.004570, Num updates: 320, Wall time: 32.33, ETA: 0m 31s (- 0m 8s)
Iter: 360, Loss 0.004274, Num updates: 360, Wall time: 36.19, ETA: 0m 35s (- 0m 4s)
Iter: 400, Loss 0.004034, Num updates: 400, Wall time: 40.10, ETA: 0m 39s (- 0m 0s)
Evaluating...
epoch 0, time: 40.46
	train_loss: 0.0040, score: 14.34
Traceback (most recent call last):
  File "main.py", line 214, in <module>
    train(args, model, train_loader, eval_loader, args.epochs, args.output, optim, epoch, qc_model)
  File "/home/coder/projects/VQAMix-main/train.py", line 117, in train
    cursor.execute(sql)
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/pymysql/cursors.py", line 158, in execute
    result = self._query(query)
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/pymysql/cursors.py", line 325, in _query
    conn.query(q)
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/pymysql/connections.py", line 549, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/pymysql/connections.py", line 779, in _read_query_result
    result.read()
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/pymysql/connections.py", line 1157, in read
    first_packet = self.connection._read_packet()
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/pymysql/connections.py", line 729, in _read_packet
    packet.raise_for_error()
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/pymysql/protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/pymysql/err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.OperationalError: (1054, "Unknown column 'None' in 'field list'")
saved_model_Med2019/BAN_MEVF
Namespace(RAD_dir='/home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019', activation='relu', ae_alpha=0.001, ae_model_path='pretrained_ae.pth', alpha=1.0, autoencoder=True, batch_size=32, clip_norm=0.25, dropout=0.5, epochs=80, eps_cnn=1e-05, feat_dim=32, five_fold=False, gamma=2, gpu=0, input=None, lr=0.03, maml=True, maml_model_path='pretrained_maml.weights', model='BAN', momentum_cnn=0.05, num_hid=1024, num_stacks=2, op='c', output='saved_model_Med2019/BAN_MEVF', pow=2, print_interval=40, qc_model_path='./saved_models/QC/rad_best.pth', question_len=12, record_id=1, rescale_factor=1.5, rnn='LSTM', seed=3, tfidf=True, update_freq='1', use_RAD=True, use_ablation=False, use_ablation_q=False, use_ablation_v=False, use_counter=False, use_grad_cam=False, use_kl_mix=False, use_mix=True, use_mix_all=False, use_mix_cond=True, use_mix_cond_q=True, use_mix_cond_v=False, use_mix_cond_vq_in=False, use_mix_cond_vq_union=False, use_partial_label=False, use_rescale=False, use_sep_mix=False)
loading dictionary from /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/dictionary.pkl
loading MAML image data from file: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/images84x84.pkl
loading DAE image data from file: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/images128x128.pkl
loading MAML image data from file: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/images84x84.pkl
loading DAE image data from file: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/images128x128.pkl
load initial weights MAML from: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/pretrained_maml.weights
load initial weights DAE from: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/pretrained_ae.pth
loading dictionary from /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/dictionary.pkl
Loading embedding tfidf and weights from file
Load embedding tfidf and weights from file successfully
Namespace(RAD_dir='/home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019', activation='relu', ae_alpha=0.001, ae_model_path='pretrained_ae.pth', alpha=1.0, autoencoder=True, batch_size=32, clip_norm=0.25, device=device(type='cuda', index=0), dropout=0.5, epochs=80, eps_cnn=1e-05, feat_dim=64, five_fold=False, gamma=2, gpu=0, input=None, lr=0.03, maml=True, maml_model_path='pretrained_maml.weights', model='BAN', momentum_cnn=0.05, num_hid=1024, num_stacks=2, op='c', output='saved_model_Med2019/BAN_MEVF', pow=2, print_interval=40, qc_model_path='./saved_models/QC/rad_best.pth', question_len=12, record_id=1, rescale_factor=1.5, rnn='LSTM', seed=3, tfidf=True, update_freq='1', use_RAD=True, use_ablation=False, use_ablation_q=False, use_ablation_v=False, use_counter=False, use_grad_cam=False, use_kl_mix=False, use_mix=True, use_mix_all=False, use_mix_cond=True, use_mix_cond_q=True, use_mix_cond_v=False, use_mix_cond_vq_in=False, use_mix_cond_vq_union=False, use_partial_label=False, use_rescale=False, use_sep_mix=False)
nParams=	21342541
optim: adamax lr=0.0300, decay_step=3, decay_rate=0.75, grad_clip=0.25
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'language_model.WordEmbedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Iter: 40, Loss 0.021836, Num updates: 40, Wall time: 7.80, ETA: 0m 7s (- 1m 6s)
Iter: 80, Loss 0.012093, Num updates: 80, Wall time: 13.12, ETA: 0m 12s (- 0m 50s)
Iter: 120, Loss 0.008771, Num updates: 120, Wall time: 18.62, ETA: 0m 18s (- 0m 42s)
Iter: 160, Loss 0.007118, Num updates: 160, Wall time: 24.16, ETA: 0m 23s (- 0m 35s)
Iter: 200, Loss 0.006111, Num updates: 200, Wall time: 29.59, ETA: 0m 29s (- 0m 29s)
Iter: 240, Loss 0.005428, Num updates: 240, Wall time: 35.16, ETA: 0m 34s (- 0m 23s)
Iter: 280, Loss 0.004942, Num updates: 280, Wall time: 40.44, ETA: 0m 39s (- 0m 17s)
Iter: 320, Loss 0.004570, Num updates: 320, Wall time: 45.93, ETA: 0m 45s (- 0m 11s)
Iter: 360, Loss 0.004274, Num updates: 360, Wall time: 51.32, ETA: 0m 50s (- 0m 5s)
Iter: 400, Loss 0.004035, Num updates: 400, Wall time: 57.00, ETA: 0m 56s (- 0m 0s)
Evaluating...
epoch 0, time: 57.22
	train_loss: 0.0040, score: 14.30
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001795, Num updates: 40, Wall time: 64.45, ETA: 0m 6s (- 0m 59s)
Iter: 80, Loss 0.001810, Num updates: 80, Wall time: 69.58, ETA: 0m 11s (- 0m 46s)
Iter: 120, Loss 0.001800, Num updates: 120, Wall time: 74.94, ETA: 0m 16s (- 0m 39s)
Iter: 160, Loss 0.001798, Num updates: 160, Wall time: 80.26, ETA: 0m 22s (- 0m 33s)
Iter: 200, Loss 0.001802, Num updates: 200, Wall time: 85.60, ETA: 0m 27s (- 0m 27s)
Iter: 240, Loss 0.001796, Num updates: 240, Wall time: 90.91, ETA: 0m 32s (- 0m 22s)
Iter: 280, Loss 0.001800, Num updates: 280, Wall time: 96.15, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001801, Num updates: 320, Wall time: 101.61, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001796, Num updates: 360, Wall time: 107.02, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001790, Num updates: 400, Wall time: 112.69, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 1, time: 55.65
	train_loss: 0.0018, score: 20.14
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001694, Num updates: 40, Wall time: 120.27, ETA: 0m 6s (- 0m 58s)
Iter: 80, Loss 0.001719, Num updates: 80, Wall time: 125.41, ETA: 0m 11s (- 0m 46s)
Iter: 120, Loss 0.001735, Num updates: 120, Wall time: 131.24, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001725, Num updates: 160, Wall time: 136.91, ETA: 0m 23s (- 0m 34s)
Iter: 200, Loss 0.001716, Num updates: 200, Wall time: 142.34, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001714, Num updates: 240, Wall time: 147.82, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001715, Num updates: 280, Wall time: 153.24, ETA: 0m 39s (- 0m 17s)
Iter: 320, Loss 0.001716, Num updates: 320, Wall time: 158.44, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001717, Num updates: 360, Wall time: 163.74, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001715, Num updates: 400, Wall time: 168.57, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 2, time: 55.58
	train_loss: 0.0017, score: 21.07
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001612, Num updates: 40, Wall time: 176.39, ETA: 0m 6s (- 1m 1s)
Iter: 80, Loss 0.001646, Num updates: 80, Wall time: 181.76, ETA: 0m 12s (- 0m 48s)
Iter: 120, Loss 0.001646, Num updates: 120, Wall time: 187.27, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001656, Num updates: 160, Wall time: 192.90, ETA: 0m 23s (- 0m 35s)
Iter: 200, Loss 0.001666, Num updates: 200, Wall time: 198.40, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001667, Num updates: 240, Wall time: 203.96, ETA: 0m 34s (- 0m 23s)
Iter: 280, Loss 0.001666, Num updates: 280, Wall time: 209.00, ETA: 0m 39s (- 0m 17s)
Iter: 320, Loss 0.001669, Num updates: 320, Wall time: 214.09, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001669, Num updates: 360, Wall time: 219.65, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001671, Num updates: 400, Wall time: 225.05, ETA: 0m 55s (- 0m 0s)
Evaluating...
epoch 3, time: 56.24
	train_loss: 0.0017, score: 22.02
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001638, Num updates: 40, Wall time: 233.01, ETA: 0m 6s (- 1m 3s)
Iter: 80, Loss 0.001632, Num updates: 80, Wall time: 238.38, ETA: 0m 12s (- 0m 49s)
Iter: 120, Loss 0.001654, Num updates: 120, Wall time: 243.97, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001660, Num updates: 160, Wall time: 249.57, ETA: 0m 23s (- 0m 35s)
Iter: 200, Loss 0.001659, Num updates: 200, Wall time: 255.26, ETA: 0m 29s (- 0m 29s)
Iter: 240, Loss 0.001653, Num updates: 240, Wall time: 260.63, ETA: 0m 34s (- 0m 23s)
Iter: 280, Loss 0.001650, Num updates: 280, Wall time: 266.05, ETA: 0m 39s (- 0m 17s)
Iter: 320, Loss 0.001650, Num updates: 320, Wall time: 271.63, ETA: 0m 45s (- 0m 11s)
Iter: 360, Loss 0.001648, Num updates: 360, Wall time: 276.88, ETA: 0m 50s (- 0m 5s)
Iter: 400, Loss 0.001647, Num updates: 400, Wall time: 282.10, ETA: 0m 55s (- 0m 0s)
Evaluating...
epoch 4, time: 56.91
	train_loss: 0.0017, score: 21.98
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001636, Num updates: 40, Wall time: 289.84, ETA: 0m 6s (- 1m 0s)
Iter: 80, Loss 0.001628, Num updates: 80, Wall time: 295.39, ETA: 0m 12s (- 0m 49s)
Iter: 120, Loss 0.001616, Num updates: 120, Wall time: 300.96, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001618, Num updates: 160, Wall time: 306.11, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001621, Num updates: 200, Wall time: 311.55, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001615, Num updates: 240, Wall time: 317.08, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001616, Num updates: 280, Wall time: 322.38, ETA: 0m 39s (- 0m 16s)
Iter: 320, Loss 0.001618, Num updates: 320, Wall time: 328.06, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001624, Num updates: 360, Wall time: 333.69, ETA: 0m 50s (- 0m 5s)
Iter: 400, Loss 0.001624, Num updates: 400, Wall time: 339.04, ETA: 0m 55s (- 0m 0s)
Evaluating...
epoch 5, time: 57.01
	train_loss: 0.0016, score: 22.99
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001521, Num updates: 40, Wall time: 347.01, ETA: 0m 6s (- 0m 59s)
Iter: 80, Loss 0.001585, Num updates: 80, Wall time: 352.61, ETA: 0m 12s (- 0m 49s)
Iter: 120, Loss 0.001611, Num updates: 120, Wall time: 358.83, ETA: 0m 18s (- 0m 43s)
Iter: 160, Loss 0.001607, Num updates: 160, Wall time: 364.72, ETA: 0m 24s (- 0m 36s)
Iter: 200, Loss 0.001610, Num updates: 200, Wall time: 370.01, ETA: 0m 29s (- 0m 29s)
Iter: 240, Loss 0.001602, Num updates: 240, Wall time: 375.55, ETA: 0m 35s (- 0m 23s)
Iter: 280, Loss 0.001607, Num updates: 280, Wall time: 380.74, ETA: 0m 40s (- 0m 17s)
Iter: 320, Loss 0.001607, Num updates: 320, Wall time: 386.75, ETA: 0m 46s (- 0m 11s)
Iter: 360, Loss 0.001609, Num updates: 360, Wall time: 392.31, ETA: 0m 51s (- 0m 5s)
Iter: 400, Loss 0.001604, Num updates: 400, Wall time: 397.72, ETA: 0m 57s (- 0m 0s)
Evaluating...
epoch 6, time: 58.25
	train_loss: 0.0016, score: 23.33
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001553, Num updates: 40, Wall time: 405.49, ETA: 0m 6s (- 0m 59s)
Iter: 80, Loss 0.001575, Num updates: 80, Wall time: 410.97, ETA: 0m 11s (- 0m 48s)
Iter: 120, Loss 0.001587, Num updates: 120, Wall time: 416.57, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001586, Num updates: 160, Wall time: 423.08, ETA: 0m 24s (- 0m 36s)
Iter: 200, Loss 0.001584, Num updates: 200, Wall time: 428.62, ETA: 0m 29s (- 0m 29s)
Iter: 240, Loss 0.001587, Num updates: 240, Wall time: 434.17, ETA: 0m 35s (- 0m 23s)
Iter: 280, Loss 0.001583, Num updates: 280, Wall time: 439.54, ETA: 0m 40s (- 0m 17s)
Iter: 320, Loss 0.001590, Num updates: 320, Wall time: 445.03, ETA: 0m 45s (- 0m 11s)
Iter: 360, Loss 0.001588, Num updates: 360, Wall time: 450.37, ETA: 0m 51s (- 0m 5s)
Iter: 400, Loss 0.001587, Num updates: 400, Wall time: 455.77, ETA: 0m 56s (- 0m 0s)
Evaluating...
epoch 7, time: 57.98
	train_loss: 0.0016, score: 23.61
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001523, Num updates: 40, Wall time: 465.24, ETA: 0m 8s (- 1m 14s)
Iter: 80, Loss 0.001555, Num updates: 80, Wall time: 471.22, ETA: 0m 13s (- 0m 56s)
Iter: 120, Loss 0.001562, Num updates: 120, Wall time: 476.88, ETA: 0m 19s (- 0m 46s)
Iter: 160, Loss 0.001565, Num updates: 160, Wall time: 482.28, ETA: 0m 25s (- 0m 37s)
Iter: 200, Loss 0.001568, Num updates: 200, Wall time: 487.69, ETA: 0m 30s (- 0m 30s)
Iter: 240, Loss 0.001573, Num updates: 240, Wall time: 493.40, ETA: 0m 36s (- 0m 24s)
Iter: 280, Loss 0.001573, Num updates: 280, Wall time: 499.07, ETA: 0m 41s (- 0m 18s)
Iter: 320, Loss 0.001572, Num updates: 320, Wall time: 504.67, ETA: 0m 47s (- 0m 12s)
Iter: 360, Loss 0.001574, Num updates: 360, Wall time: 510.30, ETA: 0m 53s (- 0m 6s)
Iter: 400, Loss 0.001572, Num updates: 400, Wall time: 515.85, ETA: 0m 58s (- 0m 0s)
Evaluating...
epoch 8, time: 59.79
	train_loss: 0.0016, score: 23.67
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001487, Num updates: 40, Wall time: 525.77, ETA: 0m 8s (- 1m 18s)
Iter: 80, Loss 0.001506, Num updates: 80, Wall time: 533.07, ETA: 0m 15s (- 1m 4s)
Iter: 120, Loss 0.001520, Num updates: 120, Wall time: 540.24, ETA: 0m 22s (- 0m 54s)
Iter: 160, Loss 0.001539, Num updates: 160, Wall time: 547.63, ETA: 0m 30s (- 0m 46s)
Iter: 200, Loss 0.001547, Num updates: 200, Wall time: 555.13, ETA: 0m 37s (- 0m 38s)
Iter: 240, Loss 0.001552, Num updates: 240, Wall time: 561.90, ETA: 0m 44s (- 0m 30s)
Iter: 280, Loss 0.001558, Num updates: 280, Wall time: 569.01, ETA: 0m 51s (- 0m 22s)
Iter: 320, Loss 0.001559, Num updates: 320, Wall time: 576.44, ETA: 0m 59s (- 0m 15s)
Iter: 360, Loss 0.001559, Num updates: 360, Wall time: 583.69, ETA: 1m 6s (- 0m 7s)
Iter: 400, Loss 0.001556, Num updates: 400, Wall time: 591.02, ETA: 1m 13s (- 0m 0s)
Evaluating...
epoch 9, time: 74.92
	train_loss: 0.0016, score: 23.62
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001482, Num updates: 40, Wall time: 600.81, ETA: 0m 8s (- 1m 17s)
Iter: 80, Loss 0.001515, Num updates: 80, Wall time: 607.66, ETA: 0m 15s (- 1m 1s)
Iter: 120, Loss 0.001518, Num updates: 120, Wall time: 615.16, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001524, Num updates: 160, Wall time: 622.47, ETA: 0m 30s (- 0m 45s)
Iter: 200, Loss 0.001539, Num updates: 200, Wall time: 628.18, ETA: 0m 35s (- 0m 36s)
Iter: 240, Loss 0.001534, Num updates: 240, Wall time: 633.60, ETA: 0m 41s (- 0m 27s)
Iter: 280, Loss 0.001536, Num updates: 280, Wall time: 638.98, ETA: 0m 46s (- 0m 20s)
Iter: 320, Loss 0.001538, Num updates: 320, Wall time: 644.65, ETA: 0m 52s (- 0m 13s)
Iter: 360, Loss 0.001534, Num updates: 360, Wall time: 650.17, ETA: 0m 57s (- 0m 6s)
Iter: 400, Loss 0.001538, Num updates: 400, Wall time: 655.16, ETA: 1m 2s (- 0m 0s)
Evaluating...
epoch 10, time: 63.83
	train_loss: 0.0015, score: 24.55
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001507, Num updates: 40, Wall time: 663.07, ETA: 0m 6s (- 1m 0s)
Iter: 80, Loss 0.001518, Num updates: 80, Wall time: 668.73, ETA: 0m 12s (- 0m 49s)
Iter: 120, Loss 0.001525, Num updates: 120, Wall time: 674.23, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001516, Num updates: 160, Wall time: 680.90, ETA: 0m 24s (- 0m 37s)
Iter: 200, Loss 0.001513, Num updates: 200, Wall time: 687.92, ETA: 0m 31s (- 0m 31s)
Iter: 240, Loss 0.001517, Num updates: 240, Wall time: 695.09, ETA: 0m 38s (- 0m 26s)
Iter: 280, Loss 0.001520, Num updates: 280, Wall time: 702.49, ETA: 0m 46s (- 0m 19s)
Iter: 320, Loss 0.001513, Num updates: 320, Wall time: 709.42, ETA: 0m 52s (- 0m 13s)
Iter: 360, Loss 0.001516, Num updates: 360, Wall time: 716.18, ETA: 0m 59s (- 0m 6s)
Iter: 400, Loss 0.001519, Num updates: 400, Wall time: 723.55, ETA: 1m 7s (- 0m 0s)
Evaluating...
epoch 11, time: 67.97
	train_loss: 0.0015, score: 23.73
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001474, Num updates: 40, Wall time: 733.29, ETA: 0m 8s (- 1m 19s)
Iter: 80, Loss 0.001482, Num updates: 80, Wall time: 739.85, ETA: 0m 15s (- 1m 1s)
Iter: 120, Loss 0.001484, Num updates: 120, Wall time: 746.95, ETA: 0m 22s (- 0m 52s)
Iter: 160, Loss 0.001479, Num updates: 160, Wall time: 754.06, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001488, Num updates: 200, Wall time: 761.40, ETA: 0m 36s (- 0m 37s)
Iter: 240, Loss 0.001490, Num updates: 240, Wall time: 768.82, ETA: 0m 44s (- 0m 29s)
Iter: 280, Loss 0.001496, Num updates: 280, Wall time: 776.11, ETA: 0m 51s (- 0m 22s)
Iter: 320, Loss 0.001499, Num updates: 320, Wall time: 782.50, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001501, Num updates: 360, Wall time: 789.69, ETA: 1m 5s (- 0m 7s)
Iter: 400, Loss 0.001504, Num updates: 400, Wall time: 796.69, ETA: 1m 12s (- 0m 0s)
Evaluating...
epoch 12, time: 73.33
	train_loss: 0.0015, score: 24.09
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001437, Num updates: 40, Wall time: 807.46, ETA: 0m 9s (- 1m 25s)
Iter: 80, Loss 0.001444, Num updates: 80, Wall time: 814.78, ETA: 0m 16s (- 1m 7s)
Iter: 120, Loss 0.001460, Num updates: 120, Wall time: 822.05, ETA: 0m 23s (- 0m 56s)
Iter: 160, Loss 0.001469, Num updates: 160, Wall time: 829.46, ETA: 0m 31s (- 0m 47s)
Iter: 200, Loss 0.001480, Num updates: 200, Wall time: 836.35, ETA: 0m 38s (- 0m 38s)
Iter: 240, Loss 0.001478, Num updates: 240, Wall time: 844.09, ETA: 0m 45s (- 0m 30s)
Iter: 280, Loss 0.001480, Num updates: 280, Wall time: 850.61, ETA: 0m 52s (- 0m 22s)
Iter: 320, Loss 0.001483, Num updates: 320, Wall time: 858.61, ETA: 1m 0s (- 0m 15s)
Iter: 360, Loss 0.001482, Num updates: 360, Wall time: 865.41, ETA: 1m 7s (- 0m 7s)
Iter: 400, Loss 0.001487, Num updates: 400, Wall time: 872.94, ETA: 1m 14s (- 0m 0s)
Evaluating...
epoch 13, time: 75.68
	train_loss: 0.0015, score: 24.34
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001465, Num updates: 40, Wall time: 883.01, ETA: 0m 8s (- 1m 21s)
Iter: 80, Loss 0.001448, Num updates: 80, Wall time: 890.38, ETA: 0m 16s (- 1m 5s)
Iter: 120, Loss 0.001445, Num updates: 120, Wall time: 897.59, ETA: 0m 23s (- 0m 55s)
Iter: 160, Loss 0.001446, Num updates: 160, Wall time: 904.94, ETA: 0m 30s (- 0m 46s)
Iter: 200, Loss 0.001452, Num updates: 200, Wall time: 912.25, ETA: 0m 38s (- 0m 38s)
Iter: 240, Loss 0.001455, Num updates: 240, Wall time: 919.42, ETA: 0m 45s (- 0m 30s)
Iter: 280, Loss 0.001464, Num updates: 280, Wall time: 926.39, ETA: 0m 52s (- 0m 22s)
Iter: 320, Loss 0.001463, Num updates: 320, Wall time: 933.59, ETA: 0m 59s (- 0m 15s)
Iter: 360, Loss 0.001467, Num updates: 360, Wall time: 940.82, ETA: 1m 6s (- 0m 7s)
Iter: 400, Loss 0.001466, Num updates: 400, Wall time: 947.89, ETA: 1m 13s (- 0m 0s)
Evaluating...
epoch 14, time: 74.34
	train_loss: 0.0015, score: 25.05
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001479, Num updates: 40, Wall time: 957.98, ETA: 0m 9s (- 1m 25s)
Iter: 80, Loss 0.001457, Num updates: 80, Wall time: 964.72, ETA: 0m 15s (- 1m 4s)
Iter: 120, Loss 0.001454, Num updates: 120, Wall time: 972.17, ETA: 0m 23s (- 0m 55s)
Iter: 160, Loss 0.001457, Num updates: 160, Wall time: 979.37, ETA: 0m 30s (- 0m 46s)
Iter: 200, Loss 0.001460, Num updates: 200, Wall time: 986.72, ETA: 0m 37s (- 0m 38s)
Iter: 240, Loss 0.001463, Num updates: 240, Wall time: 993.95, ETA: 0m 45s (- 0m 30s)
Iter: 280, Loss 0.001463, Num updates: 280, Wall time: 1001.32, ETA: 0m 52s (- 0m 22s)
Iter: 320, Loss 0.001458, Num updates: 320, Wall time: 1008.50, ETA: 0m 59s (- 0m 15s)
Iter: 360, Loss 0.001454, Num updates: 360, Wall time: 1016.60, ETA: 1m 7s (- 0m 7s)
Iter: 400, Loss 0.001453, Num updates: 400, Wall time: 1024.07, ETA: 1m 15s (- 0m 0s)
Evaluating...
epoch 15, time: 76.67
	train_loss: 0.0015, score: 24.66
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001393, Num updates: 40, Wall time: 1035.44, ETA: 0m 9s (- 1m 30s)
Iter: 80, Loss 0.001410, Num updates: 80, Wall time: 1042.73, ETA: 0m 17s (- 1m 9s)
Iter: 120, Loss 0.001411, Num updates: 120, Wall time: 1050.04, ETA: 0m 24s (- 0m 57s)
Iter: 160, Loss 0.001421, Num updates: 160, Wall time: 1057.52, ETA: 0m 31s (- 0m 48s)
Iter: 200, Loss 0.001426, Num updates: 200, Wall time: 1065.30, ETA: 0m 39s (- 0m 40s)
Iter: 240, Loss 0.001428, Num updates: 240, Wall time: 1072.69, ETA: 0m 47s (- 0m 31s)
Iter: 280, Loss 0.001429, Num updates: 280, Wall time: 1080.08, ETA: 0m 54s (- 0m 23s)
Iter: 320, Loss 0.001433, Num updates: 320, Wall time: 1087.41, ETA: 1m 1s (- 0m 15s)
Iter: 360, Loss 0.001435, Num updates: 360, Wall time: 1094.78, ETA: 1m 9s (- 0m 7s)
Iter: 400, Loss 0.001434, Num updates: 400, Wall time: 1101.95, ETA: 1m 16s (- 0m 0s)
Evaluating...
epoch 16, time: 77.88
	train_loss: 0.0014, score: 24.71
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001358, Num updates: 40, Wall time: 1112.31, ETA: 0m 8s (- 1m 18s)
Iter: 80, Loss 0.001386, Num updates: 80, Wall time: 1119.59, ETA: 0m 15s (- 1m 4s)
Iter: 120, Loss 0.001397, Num updates: 120, Wall time: 1126.61, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001405, Num updates: 160, Wall time: 1133.77, ETA: 0m 29s (- 0m 45s)
Iter: 200, Loss 0.001405, Num updates: 200, Wall time: 1141.02, ETA: 0m 37s (- 0m 37s)
Iter: 240, Loss 0.001410, Num updates: 240, Wall time: 1148.06, ETA: 0m 44s (- 0m 29s)
Iter: 280, Loss 0.001407, Num updates: 280, Wall time: 1154.91, ETA: 0m 51s (- 0m 22s)
Iter: 320, Loss 0.001410, Num updates: 320, Wall time: 1162.43, ETA: 0m 58s (- 0m 14s)
Iter: 360, Loss 0.001414, Num updates: 360, Wall time: 1169.53, ETA: 1m 5s (- 0m 7s)
Iter: 400, Loss 0.001416, Num updates: 400, Wall time: 1176.86, ETA: 1m 13s (- 0m 0s)
Evaluating...
epoch 17, time: 74.29
	train_loss: 0.0014, score: 25.52
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001378, Num updates: 40, Wall time: 1187.24, ETA: 0m 8s (- 1m 22s)
Iter: 80, Loss 0.001380, Num updates: 80, Wall time: 1193.92, ETA: 0m 15s (- 1m 3s)
Iter: 120, Loss 0.001386, Num updates: 120, Wall time: 1201.38, ETA: 0m 23s (- 0m 54s)
Iter: 160, Loss 0.001393, Num updates: 160, Wall time: 1208.68, ETA: 0m 30s (- 0m 45s)
Iter: 200, Loss 0.001395, Num updates: 200, Wall time: 1215.91, ETA: 0m 37s (- 0m 37s)
Iter: 240, Loss 0.001395, Num updates: 240, Wall time: 1224.03, ETA: 0m 45s (- 0m 30s)
Iter: 280, Loss 0.001398, Num updates: 280, Wall time: 1230.43, ETA: 0m 52s (- 0m 22s)
Iter: 320, Loss 0.001396, Num updates: 320, Wall time: 1237.75, ETA: 0m 59s (- 0m 15s)
Iter: 360, Loss 0.001399, Num updates: 360, Wall time: 1244.91, ETA: 1m 6s (- 0m 7s)
Iter: 400, Loss 0.001400, Num updates: 400, Wall time: 1252.03, ETA: 1m 13s (- 0m 0s)
Evaluating...
epoch 18, time: 74.92
	train_loss: 0.0014, score: 25.55
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001342, Num updates: 40, Wall time: 1262.62, ETA: 0m 9s (- 1m 24s)
Iter: 80, Loss 0.001360, Num updates: 80, Wall time: 1269.75, ETA: 0m 16s (- 1m 6s)
Iter: 120, Loss 0.001371, Num updates: 120, Wall time: 1277.04, ETA: 0m 23s (- 0m 55s)
Iter: 160, Loss 0.001377, Num updates: 160, Wall time: 1284.08, ETA: 0m 30s (- 0m 46s)
Iter: 200, Loss 0.001377, Num updates: 200, Wall time: 1291.58, ETA: 0m 38s (- 0m 38s)
Iter: 240, Loss 0.001380, Num updates: 240, Wall time: 1298.76, ETA: 0m 45s (- 0m 30s)
Iter: 280, Loss 0.001386, Num updates: 280, Wall time: 1305.92, ETA: 0m 52s (- 0m 22s)
Iter: 320, Loss 0.001388, Num updates: 320, Wall time: 1312.66, ETA: 0m 59s (- 0m 15s)
Iter: 360, Loss 0.001390, Num updates: 360, Wall time: 1320.37, ETA: 1m 6s (- 0m 7s)
Iter: 400, Loss 0.001387, Num updates: 400, Wall time: 1327.46, ETA: 1m 13s (- 0m 0s)
Evaluating...
epoch 19, time: 75.38
	train_loss: 0.0014, score: 25.65
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001326, Num updates: 40, Wall time: 1337.78, ETA: 0m 8s (- 1m 20s)
Iter: 80, Loss 0.001351, Num updates: 80, Wall time: 1344.86, ETA: 0m 15s (- 1m 3s)
Iter: 120, Loss 0.001363, Num updates: 120, Wall time: 1352.33, ETA: 0m 23s (- 0m 54s)
Iter: 160, Loss 0.001365, Num updates: 160, Wall time: 1359.28, ETA: 0m 30s (- 0m 45s)
Iter: 200, Loss 0.001363, Num updates: 200, Wall time: 1366.62, ETA: 0m 37s (- 0m 37s)
Iter: 240, Loss 0.001366, Num updates: 240, Wall time: 1374.16, ETA: 0m 45s (- 0m 30s)
Iter: 280, Loss 0.001367, Num updates: 280, Wall time: 1381.30, ETA: 0m 52s (- 0m 22s)
Iter: 320, Loss 0.001368, Num updates: 320, Wall time: 1388.71, ETA: 0m 59s (- 0m 15s)
Iter: 360, Loss 0.001371, Num updates: 360, Wall time: 1395.84, ETA: 1m 6s (- 0m 7s)
Iter: 400, Loss 0.001371, Num updates: 400, Wall time: 1403.24, ETA: 1m 14s (- 0m 0s)
Evaluating...
epoch 20, time: 75.44
	train_loss: 0.0014, score: 25.97
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001338, Num updates: 40, Wall time: 1414.03, ETA: 0m 9s (- 1m 25s)
Iter: 80, Loss 0.001337, Num updates: 80, Wall time: 1421.32, ETA: 0m 16s (- 1m 7s)
Iter: 120, Loss 0.001337, Num updates: 120, Wall time: 1428.74, ETA: 0m 23s (- 0m 56s)
Iter: 160, Loss 0.001341, Num updates: 160, Wall time: 1436.24, ETA: 0m 31s (- 0m 47s)
Iter: 200, Loss 0.001338, Num updates: 200, Wall time: 1443.87, ETA: 0m 39s (- 0m 39s)
Iter: 240, Loss 0.001347, Num updates: 240, Wall time: 1450.66, ETA: 0m 45s (- 0m 30s)
Iter: 280, Loss 0.001353, Num updates: 280, Wall time: 1457.56, ETA: 0m 52s (- 0m 22s)
Iter: 320, Loss 0.001351, Num updates: 320, Wall time: 1464.91, ETA: 1m 0s (- 0m 15s)
Iter: 360, Loss 0.001353, Num updates: 360, Wall time: 1472.25, ETA: 1m 7s (- 0m 7s)
Iter: 400, Loss 0.001355, Num updates: 400, Wall time: 1479.40, ETA: 1m 14s (- 0m 0s)
Evaluating...
epoch 21, time: 75.92
	train_loss: 0.0014, score: 26.51
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001304, Num updates: 40, Wall time: 1490.77, ETA: 0m 9s (- 1m 24s)
Iter: 80, Loss 0.001323, Num updates: 80, Wall time: 1497.74, ETA: 0m 16s (- 1m 5s)
Iter: 120, Loss 0.001334, Num updates: 120, Wall time: 1504.64, ETA: 0m 22s (- 0m 54s)
Iter: 160, Loss 0.001332, Num updates: 160, Wall time: 1511.56, ETA: 0m 29s (- 0m 45s)
Iter: 200, Loss 0.001335, Num updates: 200, Wall time: 1518.49, ETA: 0m 36s (- 0m 37s)
Iter: 240, Loss 0.001341, Num updates: 240, Wall time: 1524.94, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001343, Num updates: 280, Wall time: 1532.21, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001339, Num updates: 320, Wall time: 1539.01, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001341, Num updates: 360, Wall time: 1545.67, ETA: 1m 3s (- 0m 7s)
Iter: 400, Loss 0.001344, Num updates: 400, Wall time: 1553.09, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 22, time: 72.57
	train_loss: 0.0013, score: 26.41
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001291, Num updates: 40, Wall time: 1563.01, ETA: 0m 8s (- 1m 18s)
Iter: 80, Loss 0.001311, Num updates: 80, Wall time: 1569.85, ETA: 0m 15s (- 1m 2s)
Iter: 120, Loss 0.001314, Num updates: 120, Wall time: 1577.44, ETA: 0m 22s (- 0m 54s)
Iter: 160, Loss 0.001314, Num updates: 160, Wall time: 1584.16, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001319, Num updates: 200, Wall time: 1591.53, ETA: 0m 37s (- 0m 37s)
Iter: 240, Loss 0.001320, Num updates: 240, Wall time: 1598.30, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001322, Num updates: 280, Wall time: 1605.45, ETA: 0m 50s (- 0m 22s)
Iter: 320, Loss 0.001327, Num updates: 320, Wall time: 1612.71, ETA: 0m 58s (- 0m 14s)
Iter: 360, Loss 0.001327, Num updates: 360, Wall time: 1619.96, ETA: 1m 5s (- 0m 7s)
Iter: 400, Loss 0.001328, Num updates: 400, Wall time: 1626.88, ETA: 1m 12s (- 0m 0s)
Evaluating...
epoch 23, time: 73.47
	train_loss: 0.0013, score: 26.92
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001241, Num updates: 40, Wall time: 1637.41, ETA: 0m 9s (- 1m 25s)
Iter: 80, Loss 0.001287, Num updates: 80, Wall time: 1644.35, ETA: 0m 16s (- 1m 5s)
Iter: 120, Loss 0.001293, Num updates: 120, Wall time: 1650.51, ETA: 0m 22s (- 0m 52s)
Iter: 160, Loss 0.001305, Num updates: 160, Wall time: 1657.18, ETA: 0m 28s (- 0m 43s)
Iter: 200, Loss 0.001304, Num updates: 200, Wall time: 1664.29, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001310, Num updates: 240, Wall time: 1671.24, ETA: 0m 43s (- 0m 28s)
Iter: 280, Loss 0.001313, Num updates: 280, Wall time: 1678.24, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001315, Num updates: 320, Wall time: 1685.37, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001319, Num updates: 360, Wall time: 1692.19, ETA: 1m 3s (- 0m 7s)
Iter: 400, Loss 0.001318, Num updates: 400, Wall time: 1699.29, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 24, time: 72.22
	train_loss: 0.0013, score: 27.16
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001244, Num updates: 40, Wall time: 1709.49, ETA: 0m 8s (- 1m 21s)
Iter: 80, Loss 0.001276, Num updates: 80, Wall time: 1716.31, ETA: 0m 15s (- 1m 3s)
Iter: 120, Loss 0.001277, Num updates: 120, Wall time: 1723.29, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001289, Num updates: 160, Wall time: 1730.16, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001295, Num updates: 200, Wall time: 1736.93, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001295, Num updates: 240, Wall time: 1743.49, ETA: 0m 42s (- 0m 28s)
Iter: 280, Loss 0.001298, Num updates: 280, Wall time: 1750.52, ETA: 0m 49s (- 0m 21s)
Iter: 320, Loss 0.001299, Num updates: 320, Wall time: 1757.80, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001303, Num updates: 360, Wall time: 1764.84, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001308, Num updates: 400, Wall time: 1772.06, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 25, time: 72.26
	train_loss: 0.0013, score: 27.00
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001259, Num updates: 40, Wall time: 1782.14, ETA: 0m 8s (- 1m 22s)
Iter: 80, Loss 0.001284, Num updates: 80, Wall time: 1789.19, ETA: 0m 16s (- 1m 5s)
Iter: 120, Loss 0.001292, Num updates: 120, Wall time: 1796.52, ETA: 0m 23s (- 0m 55s)
Iter: 160, Loss 0.001285, Num updates: 160, Wall time: 1803.44, ETA: 0m 30s (- 0m 45s)
Iter: 200, Loss 0.001291, Num updates: 200, Wall time: 1810.61, ETA: 0m 37s (- 0m 37s)
Iter: 240, Loss 0.001292, Num updates: 240, Wall time: 1817.65, ETA: 0m 44s (- 0m 29s)
Iter: 280, Loss 0.001292, Num updates: 280, Wall time: 1824.53, ETA: 0m 51s (- 0m 22s)
Iter: 320, Loss 0.001291, Num updates: 320, Wall time: 1831.23, ETA: 0m 58s (- 0m 14s)
Iter: 360, Loss 0.001292, Num updates: 360, Wall time: 1838.25, ETA: 1m 5s (- 0m 7s)
Iter: 400, Loss 0.001294, Num updates: 400, Wall time: 1845.64, ETA: 1m 12s (- 0m 0s)
Evaluating...
epoch 26, time: 73.59
	train_loss: 0.0013, score: 27.60
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001225, Num updates: 40, Wall time: 1856.05, ETA: 0m 9s (- 1m 23s)
Iter: 80, Loss 0.001252, Num updates: 80, Wall time: 1863.48, ETA: 0m 16s (- 1m 6s)
Iter: 120, Loss 0.001255, Num updates: 120, Wall time: 1869.98, ETA: 0m 22s (- 0m 54s)
Iter: 160, Loss 0.001261, Num updates: 160, Wall time: 1877.11, ETA: 0m 30s (- 0m 45s)
Iter: 200, Loss 0.001267, Num updates: 200, Wall time: 1883.77, ETA: 0m 36s (- 0m 37s)
Iter: 240, Loss 0.001277, Num updates: 240, Wall time: 1891.22, ETA: 0m 44s (- 0m 29s)
Iter: 280, Loss 0.001283, Num updates: 280, Wall time: 1898.63, ETA: 0m 51s (- 0m 22s)
Iter: 320, Loss 0.001285, Num updates: 320, Wall time: 1905.85, ETA: 0m 58s (- 0m 14s)
Iter: 360, Loss 0.001284, Num updates: 360, Wall time: 1913.01, ETA: 1m 5s (- 0m 7s)
Iter: 400, Loss 0.001286, Num updates: 400, Wall time: 1920.46, ETA: 1m 13s (- 0m 0s)
Evaluating...
epoch 27, time: 74.44
	train_loss: 0.0013, score: 27.38
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001225, Num updates: 40, Wall time: 1930.50, ETA: 0m 8s (- 1m 21s)
Iter: 80, Loss 0.001226, Num updates: 80, Wall time: 1937.81, ETA: 0m 16s (- 1m 5s)
Iter: 120, Loss 0.001243, Num updates: 120, Wall time: 1945.03, ETA: 0m 23s (- 0m 55s)
Iter: 160, Loss 0.001248, Num updates: 160, Wall time: 1952.05, ETA: 0m 30s (- 0m 46s)
Iter: 200, Loss 0.001259, Num updates: 200, Wall time: 1958.95, ETA: 0m 37s (- 0m 37s)
Iter: 240, Loss 0.001265, Num updates: 240, Wall time: 1965.94, ETA: 0m 44s (- 0m 29s)
Iter: 280, Loss 0.001263, Num updates: 280, Wall time: 1973.05, ETA: 0m 51s (- 0m 22s)
Iter: 320, Loss 0.001269, Num updates: 320, Wall time: 1979.96, ETA: 0m 58s (- 0m 14s)
Iter: 360, Loss 0.001273, Num updates: 360, Wall time: 1987.45, ETA: 1m 5s (- 0m 7s)
Iter: 400, Loss 0.001275, Num updates: 400, Wall time: 1994.80, ETA: 1m 13s (- 0m 0s)
Evaluating...
epoch 28, time: 74.38
	train_loss: 0.0013, score: 27.63
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001226, Num updates: 40, Wall time: 2005.08, ETA: 0m 8s (- 1m 20s)
Iter: 80, Loss 0.001235, Num updates: 80, Wall time: 2012.29, ETA: 0m 15s (- 1m 4s)
Iter: 120, Loss 0.001244, Num updates: 120, Wall time: 2018.97, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001254, Num updates: 160, Wall time: 2026.51, ETA: 0m 30s (- 0m 45s)
Iter: 200, Loss 0.001250, Num updates: 200, Wall time: 2034.16, ETA: 0m 37s (- 0m 38s)
Iter: 240, Loss 0.001252, Num updates: 240, Wall time: 2041.28, ETA: 0m 44s (- 0m 30s)
Iter: 280, Loss 0.001256, Num updates: 280, Wall time: 2048.27, ETA: 0m 51s (- 0m 22s)
Iter: 320, Loss 0.001256, Num updates: 320, Wall time: 2055.55, ETA: 0m 59s (- 0m 15s)
Iter: 360, Loss 0.001261, Num updates: 360, Wall time: 2061.85, ETA: 1m 5s (- 0m 7s)
Iter: 400, Loss 0.001265, Num updates: 400, Wall time: 2069.03, ETA: 1m 12s (- 0m 0s)
Evaluating...
epoch 29, time: 73.89
	train_loss: 0.0013, score: 28.41
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001198, Num updates: 40, Wall time: 2079.65, ETA: 0m 9s (- 1m 24s)
Iter: 80, Loss 0.001211, Num updates: 80, Wall time: 2086.89, ETA: 0m 16s (- 1m 6s)
Iter: 120, Loss 0.001228, Num updates: 120, Wall time: 2094.40, ETA: 0m 23s (- 0m 56s)
Iter: 160, Loss 0.001232, Num updates: 160, Wall time: 2101.73, ETA: 0m 31s (- 0m 47s)
Iter: 200, Loss 0.001237, Num updates: 200, Wall time: 2108.95, ETA: 0m 38s (- 0m 38s)
Iter: 240, Loss 0.001248, Num updates: 240, Wall time: 2116.22, ETA: 0m 45s (- 0m 30s)
Iter: 280, Loss 0.001248, Num updates: 280, Wall time: 2123.47, ETA: 0m 52s (- 0m 22s)
Iter: 320, Loss 0.001251, Num updates: 320, Wall time: 2130.64, ETA: 1m 0s (- 0m 15s)
Iter: 360, Loss 0.001252, Num updates: 360, Wall time: 2137.09, ETA: 1m 6s (- 0m 7s)
Iter: 400, Loss 0.001256, Num updates: 400, Wall time: 2144.53, ETA: 1m 14s (- 0m 0s)
Evaluating...
epoch 30, time: 75.19
	train_loss: 0.0013, score: 27.47
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001220, Num updates: 40, Wall time: 2154.70, ETA: 0m 8s (- 1m 21s)
Iter: 80, Loss 0.001236, Num updates: 80, Wall time: 2161.81, ETA: 0m 15s (- 1m 4s)
Iter: 120, Loss 0.001237, Num updates: 120, Wall time: 2169.14, ETA: 0m 23s (- 0m 54s)
Iter: 160, Loss 0.001248, Num updates: 160, Wall time: 2176.20, ETA: 0m 30s (- 0m 45s)
Iter: 200, Loss 0.001256, Num updates: 200, Wall time: 2183.48, ETA: 0m 37s (- 0m 37s)
Iter: 240, Loss 0.001257, Num updates: 240, Wall time: 2190.43, ETA: 0m 44s (- 0m 29s)
Iter: 280, Loss 0.001251, Num updates: 280, Wall time: 2197.25, ETA: 0m 51s (- 0m 22s)
Iter: 320, Loss 0.001250, Num updates: 320, Wall time: 2204.51, ETA: 0m 58s (- 0m 14s)
Iter: 360, Loss 0.001248, Num updates: 360, Wall time: 2211.74, ETA: 1m 5s (- 0m 7s)
Iter: 400, Loss 0.001250, Num updates: 400, Wall time: 2219.29, ETA: 1m 13s (- 0m 0s)
Evaluating...
epoch 31, time: 73.97
	train_loss: 0.0013, score: 27.93
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001199, Num updates: 40, Wall time: 2228.90, ETA: 0m 8s (- 1m 21s)
Iter: 80, Loss 0.001217, Num updates: 80, Wall time: 2236.26, ETA: 0m 16s (- 1m 5s)
Iter: 120, Loss 0.001224, Num updates: 120, Wall time: 2243.44, ETA: 0m 23s (- 0m 55s)
Iter: 160, Loss 0.001225, Num updates: 160, Wall time: 2250.68, ETA: 0m 30s (- 0m 46s)
Iter: 200, Loss 0.001226, Num updates: 200, Wall time: 2257.95, ETA: 0m 37s (- 0m 38s)
Iter: 240, Loss 0.001238, Num updates: 240, Wall time: 2265.15, ETA: 0m 45s (- 0m 30s)
Iter: 280, Loss 0.001239, Num updates: 280, Wall time: 2272.32, ETA: 0m 52s (- 0m 22s)
Iter: 320, Loss 0.001240, Num updates: 320, Wall time: 2279.66, ETA: 0m 59s (- 0m 15s)
Iter: 360, Loss 0.001240, Num updates: 360, Wall time: 2286.70, ETA: 1m 6s (- 0m 7s)
Iter: 400, Loss 0.001241, Num updates: 400, Wall time: 2294.14, ETA: 1m 14s (- 0m 0s)
Evaluating...
epoch 32, time: 75.32
	train_loss: 0.0012, score: 28.17
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001200, Num updates: 40, Wall time: 2304.96, ETA: 0m 8s (- 1m 22s)
Iter: 80, Loss 0.001208, Num updates: 80, Wall time: 2312.36, ETA: 0m 16s (- 1m 6s)
Iter: 120, Loss 0.001212, Num updates: 120, Wall time: 2319.39, ETA: 0m 23s (- 0m 55s)
Iter: 160, Loss 0.001214, Num updates: 160, Wall time: 2326.57, ETA: 0m 30s (- 0m 46s)
Iter: 200, Loss 0.001222, Num updates: 200, Wall time: 2333.62, ETA: 0m 37s (- 0m 37s)
Iter: 240, Loss 0.001225, Num updates: 240, Wall time: 2340.29, ETA: 0m 44s (- 0m 29s)
Iter: 280, Loss 0.001228, Num updates: 280, Wall time: 2347.60, ETA: 0m 51s (- 0m 22s)
Iter: 320, Loss 0.001230, Num updates: 320, Wall time: 2355.01, ETA: 0m 58s (- 0m 14s)
Iter: 360, Loss 0.001232, Num updates: 360, Wall time: 2362.29, ETA: 1m 6s (- 0m 7s)
Iter: 400, Loss 0.001235, Num updates: 400, Wall time: 2369.45, ETA: 1m 13s (- 0m 0s)
Evaluating...
epoch 33, time: 74.48
	train_loss: 0.0012, score: 27.77
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001210, Num updates: 40, Wall time: 2379.74, ETA: 0m 8s (- 1m 22s)
Iter: 80, Loss 0.001213, Num updates: 80, Wall time: 2386.89, ETA: 0m 16s (- 1m 5s)
Iter: 120, Loss 0.001209, Num updates: 120, Wall time: 2393.90, ETA: 0m 23s (- 0m 54s)
Iter: 160, Loss 0.001208, Num updates: 160, Wall time: 2401.07, ETA: 0m 30s (- 0m 45s)
Iter: 200, Loss 0.001210, Num updates: 200, Wall time: 2408.10, ETA: 0m 37s (- 0m 37s)
Iter: 240, Loss 0.001211, Num updates: 240, Wall time: 2415.15, ETA: 0m 44s (- 0m 29s)
Iter: 280, Loss 0.001217, Num updates: 280, Wall time: 2421.95, ETA: 0m 51s (- 0m 22s)
Iter: 320, Loss 0.001216, Num updates: 320, Wall time: 2429.27, ETA: 0m 58s (- 0m 14s)
Iter: 360, Loss 0.001222, Num updates: 360, Wall time: 2436.42, ETA: 1m 5s (- 0m 7s)
Iter: 400, Loss 0.001225, Num updates: 400, Wall time: 2443.82, ETA: 1m 13s (- 0m 0s)
Evaluating...
epoch 34, time: 74.15
	train_loss: 0.0012, score: 28.07
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001156, Num updates: 40, Wall time: 2453.57, ETA: 0m 8s (- 1m 17s)
Iter: 80, Loss 0.001183, Num updates: 80, Wall time: 2460.61, ETA: 0m 15s (- 1m 2s)
Iter: 120, Loss 0.001197, Num updates: 120, Wall time: 2467.02, ETA: 0m 21s (- 0m 51s)
Iter: 160, Loss 0.001205, Num updates: 160, Wall time: 2474.10, ETA: 0m 28s (- 0m 43s)
Iter: 200, Loss 0.001205, Num updates: 200, Wall time: 2481.56, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001208, Num updates: 240, Wall time: 2488.47, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001208, Num updates: 280, Wall time: 2495.46, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001213, Num updates: 320, Wall time: 2502.69, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001218, Num updates: 360, Wall time: 2509.64, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001219, Num updates: 400, Wall time: 2516.90, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 35, time: 72.90
	train_loss: 0.0012, score: 27.88
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001167, Num updates: 40, Wall time: 2526.68, ETA: 0m 8s (- 1m 17s)
Iter: 80, Loss 0.001187, Num updates: 80, Wall time: 2534.30, ETA: 0m 15s (- 1m 4s)
Iter: 120, Loss 0.001208, Num updates: 120, Wall time: 2541.44, ETA: 0m 23s (- 0m 54s)
Iter: 160, Loss 0.001208, Num updates: 160, Wall time: 2548.50, ETA: 0m 30s (- 0m 45s)
Iter: 200, Loss 0.001210, Num updates: 200, Wall time: 2555.57, ETA: 0m 37s (- 0m 37s)
Iter: 240, Loss 0.001213, Num updates: 240, Wall time: 2562.93, ETA: 0m 44s (- 0m 30s)
Iter: 280, Loss 0.001215, Num updates: 280, Wall time: 2569.81, ETA: 0m 51s (- 0m 22s)
Iter: 320, Loss 0.001215, Num updates: 320, Wall time: 2577.13, ETA: 0m 58s (- 0m 14s)
Iter: 360, Loss 0.001213, Num updates: 360, Wall time: 2584.23, ETA: 1m 5s (- 0m 7s)
Iter: 400, Loss 0.001214, Num updates: 400, Wall time: 2591.23, ETA: 1m 12s (- 0m 0s)
Evaluating...
epoch 36, time: 73.97
	train_loss: 0.0012, score: 28.04
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001157, Num updates: 40, Wall time: 2601.00, ETA: 0m 8s (- 1m 18s)
Iter: 80, Loss 0.001185, Num updates: 80, Wall time: 2607.86, ETA: 0m 15s (- 1m 2s)
Iter: 120, Loss 0.001187, Num updates: 120, Wall time: 2615.03, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001191, Num updates: 160, Wall time: 2622.09, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001198, Num updates: 200, Wall time: 2629.33, ETA: 0m 36s (- 0m 37s)
Iter: 240, Loss 0.001199, Num updates: 240, Wall time: 2636.42, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001204, Num updates: 280, Wall time: 2643.67, ETA: 0m 51s (- 0m 22s)
Iter: 320, Loss 0.001204, Num updates: 320, Wall time: 2650.86, ETA: 0m 58s (- 0m 14s)
Iter: 360, Loss 0.001207, Num updates: 360, Wall time: 2657.81, ETA: 1m 5s (- 0m 7s)
Iter: 400, Loss 0.001209, Num updates: 400, Wall time: 2664.87, ETA: 1m 12s (- 0m 0s)
Evaluating...
epoch 37, time: 73.35
	train_loss: 0.0012, score: 27.53
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001150, Num updates: 40, Wall time: 2674.33, ETA: 0m 8s (- 1m 15s)
Iter: 80, Loss 0.001168, Num updates: 80, Wall time: 2681.30, ETA: 0m 15s (- 1m 1s)
Iter: 120, Loss 0.001176, Num updates: 120, Wall time: 2688.49, ETA: 0m 22s (- 0m 52s)
Iter: 160, Loss 0.001181, Num updates: 160, Wall time: 2695.74, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001188, Num updates: 200, Wall time: 2702.41, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001189, Num updates: 240, Wall time: 2709.24, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001194, Num updates: 280, Wall time: 2716.49, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001194, Num updates: 320, Wall time: 2723.60, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001195, Num updates: 360, Wall time: 2730.91, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001198, Num updates: 400, Wall time: 2737.62, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 38, time: 72.76
	train_loss: 0.0012, score: 27.80
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001182, Num updates: 40, Wall time: 2747.87, ETA: 0m 8s (- 1m 20s)
Iter: 80, Loss 0.001179, Num updates: 80, Wall time: 2755.12, ETA: 0m 15s (- 1m 4s)
Iter: 120, Loss 0.001180, Num updates: 120, Wall time: 2762.24, ETA: 0m 23s (- 0m 54s)
Iter: 160, Loss 0.001182, Num updates: 160, Wall time: 2769.40, ETA: 0m 30s (- 0m 45s)
Iter: 200, Loss 0.001181, Num updates: 200, Wall time: 2776.53, ETA: 0m 37s (- 0m 37s)
Iter: 240, Loss 0.001187, Num updates: 240, Wall time: 2783.69, ETA: 0m 44s (- 0m 29s)
Iter: 280, Loss 0.001191, Num updates: 280, Wall time: 2790.83, ETA: 0m 51s (- 0m 22s)
Iter: 320, Loss 0.001192, Num updates: 320, Wall time: 2797.83, ETA: 0m 58s (- 0m 14s)
Iter: 360, Loss 0.001194, Num updates: 360, Wall time: 2804.99, ETA: 1m 5s (- 0m 7s)
Iter: 400, Loss 0.001194, Num updates: 400, Wall time: 2812.05, ETA: 1m 12s (- 0m 0s)
Evaluating...
epoch 39, time: 74.04
	train_loss: 0.0012, score: 27.55
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001146, Num updates: 40, Wall time: 2823.04, ETA: 0m 9s (- 1m 25s)
Iter: 80, Loss 0.001168, Num updates: 80, Wall time: 2829.43, ETA: 0m 15s (- 1m 3s)
Iter: 120, Loss 0.001183, Num updates: 120, Wall time: 2836.55, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001178, Num updates: 160, Wall time: 2843.58, ETA: 0m 29s (- 0m 45s)
Iter: 200, Loss 0.001178, Num updates: 200, Wall time: 2850.76, ETA: 0m 36s (- 0m 37s)
Iter: 240, Loss 0.001179, Num updates: 240, Wall time: 2857.41, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001182, Num updates: 280, Wall time: 2864.71, ETA: 0m 50s (- 0m 22s)
Iter: 320, Loss 0.001184, Num updates: 320, Wall time: 2871.69, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001188, Num updates: 360, Wall time: 2878.42, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001189, Num updates: 400, Wall time: 2885.16, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 40, time: 72.56
	train_loss: 0.0012, score: 27.78
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001138, Num updates: 40, Wall time: 2895.28, ETA: 0m 8s (- 1m 20s)
Iter: 80, Loss 0.001169, Num updates: 80, Wall time: 2902.20, ETA: 0m 15s (- 1m 3s)
Iter: 120, Loss 0.001169, Num updates: 120, Wall time: 2909.27, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001183, Num updates: 160, Wall time: 2916.29, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001185, Num updates: 200, Wall time: 2923.48, ETA: 0m 36s (- 0m 37s)
Iter: 240, Loss 0.001187, Num updates: 240, Wall time: 2930.55, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001187, Num updates: 280, Wall time: 2937.79, ETA: 0m 51s (- 0m 22s)
Iter: 320, Loss 0.001187, Num updates: 320, Wall time: 2945.19, ETA: 0m 58s (- 0m 14s)
Iter: 360, Loss 0.001186, Num updates: 360, Wall time: 2951.94, ETA: 1m 5s (- 0m 7s)
Iter: 400, Loss 0.001186, Num updates: 400, Wall time: 2958.70, ETA: 1m 12s (- 0m 0s)
Evaluating...
epoch 41, time: 73.28
	train_loss: 0.0012, score: 28.03
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001139, Num updates: 40, Wall time: 2968.54, ETA: 0m 8s (- 1m 17s)
Iter: 80, Loss 0.001157, Num updates: 80, Wall time: 2975.00, ETA: 0m 14s (- 1m 0s)
Iter: 120, Loss 0.001163, Num updates: 120, Wall time: 2982.21, ETA: 0m 22s (- 0m 52s)
Iter: 160, Loss 0.001170, Num updates: 160, Wall time: 2989.00, ETA: 0m 28s (- 0m 43s)
Iter: 200, Loss 0.001171, Num updates: 200, Wall time: 2996.24, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001174, Num updates: 240, Wall time: 3003.25, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001174, Num updates: 280, Wall time: 3010.14, ETA: 0m 49s (- 0m 21s)
Iter: 320, Loss 0.001177, Num updates: 320, Wall time: 3016.90, ETA: 0m 56s (- 0m 14s)
Iter: 360, Loss 0.001178, Num updates: 360, Wall time: 3024.23, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001180, Num updates: 400, Wall time: 3031.50, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 42, time: 72.29
	train_loss: 0.0012, score: 27.56
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001144, Num updates: 40, Wall time: 3041.29, ETA: 0m 8s (- 1m 19s)
Iter: 80, Loss 0.001155, Num updates: 80, Wall time: 3048.37, ETA: 0m 15s (- 1m 3s)
Iter: 120, Loss 0.001162, Num updates: 120, Wall time: 3055.49, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001159, Num updates: 160, Wall time: 3062.40, ETA: 0m 29s (- 0m 45s)
Iter: 200, Loss 0.001166, Num updates: 200, Wall time: 3069.86, ETA: 0m 37s (- 0m 37s)
Iter: 240, Loss 0.001168, Num updates: 240, Wall time: 3076.86, ETA: 0m 44s (- 0m 29s)
Iter: 280, Loss 0.001169, Num updates: 280, Wall time: 3083.86, ETA: 0m 51s (- 0m 22s)
Iter: 320, Loss 0.001170, Num updates: 320, Wall time: 3091.00, ETA: 0m 58s (- 0m 14s)
Iter: 360, Loss 0.001170, Num updates: 360, Wall time: 3097.68, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001172, Num updates: 400, Wall time: 3104.87, ETA: 1m 12s (- 0m 0s)
Evaluating...
epoch 43, time: 73.33
	train_loss: 0.0012, score: 26.76
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001130, Num updates: 40, Wall time: 3115.10, ETA: 0m 8s (- 1m 21s)
Iter: 80, Loss 0.001156, Num updates: 80, Wall time: 3122.41, ETA: 0m 16s (- 1m 5s)
Iter: 120, Loss 0.001142, Num updates: 120, Wall time: 3129.52, ETA: 0m 23s (- 0m 54s)
Iter: 160, Loss 0.001149, Num updates: 160, Wall time: 3136.38, ETA: 0m 30s (- 0m 45s)
Iter: 200, Loss 0.001155, Num updates: 200, Wall time: 3143.44, ETA: 0m 37s (- 0m 37s)
Iter: 240, Loss 0.001156, Num updates: 240, Wall time: 3150.73, ETA: 0m 44s (- 0m 29s)
Iter: 280, Loss 0.001159, Num updates: 280, Wall time: 3157.54, ETA: 0m 51s (- 0m 22s)
Iter: 320, Loss 0.001162, Num updates: 320, Wall time: 3164.98, ETA: 0m 58s (- 0m 14s)
Iter: 360, Loss 0.001165, Num updates: 360, Wall time: 3171.68, ETA: 1m 5s (- 0m 7s)
Iter: 400, Loss 0.001166, Num updates: 400, Wall time: 3178.71, ETA: 1m 12s (- 0m 0s)
Evaluating...
epoch 44, time: 73.18
	train_loss: 0.0012, score: 28.35
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001141, Num updates: 40, Wall time: 3187.62, ETA: 0m 7s (- 1m 13s)
Iter: 80, Loss 0.001141, Num updates: 80, Wall time: 3194.27, ETA: 0m 14s (- 0m 59s)
Iter: 120, Loss 0.001144, Num updates: 120, Wall time: 3201.81, ETA: 0m 22s (- 0m 52s)
Iter: 160, Loss 0.001155, Num updates: 160, Wall time: 3208.79, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001153, Num updates: 200, Wall time: 3215.72, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001159, Num updates: 240, Wall time: 3222.81, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001164, Num updates: 280, Wall time: 3229.95, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001161, Num updates: 320, Wall time: 3237.12, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001162, Num updates: 360, Wall time: 3244.71, ETA: 1m 5s (- 0m 7s)
Iter: 400, Loss 0.001162, Num updates: 400, Wall time: 3252.04, ETA: 1m 12s (- 0m 0s)
Evaluating...
epoch 45, time: 73.58
	train_loss: 0.0012, score: 27.71
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001136, Num updates: 40, Wall time: 3262.24, ETA: 0m 8s (- 1m 20s)
Iter: 80, Loss 0.001144, Num updates: 80, Wall time: 3269.56, ETA: 0m 16s (- 1m 5s)
Iter: 120, Loss 0.001154, Num updates: 120, Wall time: 3276.89, ETA: 0m 23s (- 0m 55s)
Iter: 160, Loss 0.001148, Num updates: 160, Wall time: 3283.87, ETA: 0m 30s (- 0m 46s)
Iter: 200, Loss 0.001152, Num updates: 200, Wall time: 3290.72, ETA: 0m 37s (- 0m 37s)
Iter: 240, Loss 0.001151, Num updates: 240, Wall time: 3298.09, ETA: 0m 44s (- 0m 30s)
Iter: 280, Loss 0.001157, Num updates: 280, Wall time: 3305.20, ETA: 0m 51s (- 0m 22s)
Iter: 320, Loss 0.001157, Num updates: 320, Wall time: 3312.38, ETA: 0m 58s (- 0m 14s)
Iter: 360, Loss 0.001158, Num updates: 360, Wall time: 3319.62, ETA: 1m 6s (- 0m 7s)
Iter: 400, Loss 0.001159, Num updates: 400, Wall time: 3326.92, ETA: 1m 13s (- 0m 0s)
Evaluating...
epoch 46, time: 74.57
	train_loss: 0.0012, score: 27.62
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001113, Num updates: 40, Wall time: 3337.56, ETA: 0m 9s (- 1m 25s)
Iter: 80, Loss 0.001137, Num updates: 80, Wall time: 3344.60, ETA: 0m 16s (- 1m 6s)
Iter: 120, Loss 0.001146, Num updates: 120, Wall time: 3351.58, ETA: 0m 23s (- 0m 54s)
Iter: 160, Loss 0.001145, Num updates: 160, Wall time: 3358.51, ETA: 0m 30s (- 0m 45s)
Iter: 200, Loss 0.001149, Num updates: 200, Wall time: 3365.80, ETA: 0m 37s (- 0m 37s)
Iter: 240, Loss 0.001152, Num updates: 240, Wall time: 3373.04, ETA: 0m 44s (- 0m 30s)
Iter: 280, Loss 0.001150, Num updates: 280, Wall time: 3379.86, ETA: 0m 51s (- 0m 22s)
Iter: 320, Loss 0.001147, Num updates: 320, Wall time: 3386.93, ETA: 0m 58s (- 0m 14s)
Iter: 360, Loss 0.001148, Num updates: 360, Wall time: 3393.47, ETA: 1m 5s (- 0m 7s)
Iter: 400, Loss 0.001149, Num updates: 400, Wall time: 3400.45, ETA: 1m 12s (- 0m 0s)
Evaluating...
epoch 47, time: 73.32
	train_loss: 0.0012, score: 27.73
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001113, Num updates: 40, Wall time: 3410.52, ETA: 0m 8s (- 1m 20s)
Iter: 80, Loss 0.001126, Num updates: 80, Wall time: 3417.71, ETA: 0m 15s (- 1m 4s)
Iter: 120, Loss 0.001141, Num updates: 120, Wall time: 3424.58, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001148, Num updates: 160, Wall time: 3431.67, ETA: 0m 29s (- 0m 45s)
Iter: 200, Loss 0.001151, Num updates: 200, Wall time: 3438.61, ETA: 0m 36s (- 0m 37s)
Iter: 240, Loss 0.001148, Num updates: 240, Wall time: 3445.47, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001143, Num updates: 280, Wall time: 3452.31, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001147, Num updates: 320, Wall time: 3459.76, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001151, Num updates: 360, Wall time: 3466.59, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001151, Num updates: 400, Wall time: 3473.32, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 48, time: 72.62
	train_loss: 0.0012, score: 27.37
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001103, Num updates: 40, Wall time: 3483.26, ETA: 0m 8s (- 1m 19s)
Iter: 80, Loss 0.001113, Num updates: 80, Wall time: 3490.54, ETA: 0m 15s (- 1m 4s)
Iter: 120, Loss 0.001125, Num updates: 120, Wall time: 3497.30, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001131, Num updates: 160, Wall time: 3504.26, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001135, Num updates: 200, Wall time: 3511.31, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001134, Num updates: 240, Wall time: 3518.45, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001140, Num updates: 280, Wall time: 3525.25, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001144, Num updates: 320, Wall time: 3532.59, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001145, Num updates: 360, Wall time: 3539.37, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001146, Num updates: 400, Wall time: 3546.04, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 49, time: 72.42
	train_loss: 0.0011, score: 27.44
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001082, Num updates: 40, Wall time: 3556.13, ETA: 0m 8s (- 1m 20s)
Iter: 80, Loss 0.001111, Num updates: 80, Wall time: 3563.36, ETA: 0m 15s (- 1m 4s)
Iter: 120, Loss 0.001125, Num updates: 120, Wall time: 3570.45, ETA: 0m 23s (- 0m 54s)
Iter: 160, Loss 0.001131, Num updates: 160, Wall time: 3577.47, ETA: 0m 30s (- 0m 45s)
Iter: 200, Loss 0.001134, Num updates: 200, Wall time: 3584.33, ETA: 0m 36s (- 0m 37s)
Iter: 240, Loss 0.001139, Num updates: 240, Wall time: 3591.09, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001137, Num updates: 280, Wall time: 3598.10, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001134, Num updates: 320, Wall time: 3604.90, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001138, Num updates: 360, Wall time: 3611.87, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001142, Num updates: 400, Wall time: 3618.85, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 50, time: 72.61
	train_loss: 0.0011, score: 27.60
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001107, Num updates: 40, Wall time: 3629.04, ETA: 0m 8s (- 1m 21s)
Iter: 80, Loss 0.001119, Num updates: 80, Wall time: 3636.05, ETA: 0m 15s (- 1m 4s)
Iter: 120, Loss 0.001119, Num updates: 120, Wall time: 3642.98, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001127, Num updates: 160, Wall time: 3650.29, ETA: 0m 30s (- 0m 45s)
Iter: 200, Loss 0.001125, Num updates: 200, Wall time: 3657.27, ETA: 0m 37s (- 0m 37s)
Iter: 240, Loss 0.001128, Num updates: 240, Wall time: 3664.07, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001130, Num updates: 280, Wall time: 3671.72, ETA: 0m 51s (- 0m 22s)
Iter: 320, Loss 0.001131, Num updates: 320, Wall time: 3678.75, ETA: 0m 58s (- 0m 14s)
Iter: 360, Loss 0.001134, Num updates: 360, Wall time: 3685.93, ETA: 1m 5s (- 0m 7s)
Iter: 400, Loss 0.001135, Num updates: 400, Wall time: 3692.88, ETA: 1m 12s (- 0m 0s)
Evaluating...
epoch 51, time: 73.66
	train_loss: 0.0011, score: 27.30
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001096, Num updates: 40, Wall time: 3703.47, ETA: 0m 9s (- 1m 26s)
Iter: 80, Loss 0.001112, Num updates: 80, Wall time: 3710.87, ETA: 0m 16s (- 1m 8s)
Iter: 120, Loss 0.001117, Num updates: 120, Wall time: 3718.19, ETA: 0m 24s (- 0m 56s)
Iter: 160, Loss 0.001117, Num updates: 160, Wall time: 3725.55, ETA: 0m 31s (- 0m 47s)
Iter: 200, Loss 0.001128, Num updates: 200, Wall time: 3732.61, ETA: 0m 38s (- 0m 38s)
Iter: 240, Loss 0.001132, Num updates: 240, Wall time: 3740.09, ETA: 0m 45s (- 0m 30s)
Iter: 280, Loss 0.001132, Num updates: 280, Wall time: 3747.47, ETA: 0m 53s (- 0m 23s)
Iter: 320, Loss 0.001133, Num updates: 320, Wall time: 3754.73, ETA: 1m 0s (- 0m 15s)
Iter: 360, Loss 0.001133, Num updates: 360, Wall time: 3762.15, ETA: 1m 8s (- 0m 7s)
Iter: 400, Loss 0.001132, Num updates: 400, Wall time: 3769.15, ETA: 1m 15s (- 0m 0s)
Evaluating...
epoch 52, time: 76.21
	train_loss: 0.0011, score: 27.59
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001094, Num updates: 40, Wall time: 3779.08, ETA: 0m 8s (- 1m 18s)
Iter: 80, Loss 0.001109, Num updates: 80, Wall time: 3785.90, ETA: 0m 15s (- 1m 2s)
Iter: 120, Loss 0.001116, Num updates: 120, Wall time: 3792.75, ETA: 0m 22s (- 0m 52s)
Traceback (most recent call last):
  File "main.py", line 214, in <module>
    train(args, model, train_loader, eval_loader, args.epochs, args.output, optim, epoch, qc_model)
  File "/home/coder/projects/VQAMix-main/train.py", line 93, in train
    loss, batch_score = trainer.train_step(sample)
  File "/home/coder/projects/VQAMix-main/trainer.py", line 181, in train_step
    loss.backward()
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/autograd/__init__.py", line 145, in backward
    Variable._execution_engine.run_backward(
  File "/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 1448077) is killed by signal: Killed. 
saved_model_Med2019/BAN_MEVF
Namespace(RAD_dir='/home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019', activation='relu', ae_alpha=0.001, ae_model_path='pretrained_ae.pth', alpha=1.0, autoencoder=True, batch_size=32, clip_norm=0.25, dropout=0.5, epochs=80, eps_cnn=1e-05, feat_dim=32, five_fold=False, gamma=2, gpu=0, input=None, lr=0.03, maml=True, maml_model_path='pretrained_maml.weights', model='BAN', momentum_cnn=0.05, num_hid=1024, num_stacks=2, op='c', output='saved_model_Med2019/BAN_MEVF', pow=2, print_interval=40, qc_model_path='./saved_models/QC/rad_best.pth', question_len=12, record_id=1, rescale_factor=1.5, rnn='LSTM', seed=3, tfidf=True, update_freq='1', use_RAD=True, use_ablation=False, use_ablation_q=False, use_ablation_v=False, use_counter=False, use_grad_cam=False, use_kl_mix=False, use_mix=True, use_mix_all=False, use_mix_cond=True, use_mix_cond_q=True, use_mix_cond_v=False, use_mix_cond_vq_in=False, use_mix_cond_vq_union=False, use_partial_label=False, use_rescale=False, use_sep_mix=False)
loading dictionary from /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/dictionary.pkl
loading MAML image data from file: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/images84x84.pkl
loading DAE image data from file: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/images128x128.pkl
loading MAML image data from file: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/images84x84.pkl
loading DAE image data from file: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/images128x128.pkl
load initial weights MAML from: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/pretrained_maml.weights
load initial weights DAE from: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/pretrained_ae.pth
loading dictionary from /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/dictionary.pkl
Loading embedding tfidf and weights from file
Load embedding tfidf and weights from file successfully
Namespace(RAD_dir='/home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019', activation='relu', ae_alpha=0.001, ae_model_path='pretrained_ae.pth', alpha=1.0, autoencoder=True, batch_size=32, clip_norm=0.25, device=device(type='cuda', index=0), dropout=0.5, epochs=80, eps_cnn=1e-05, feat_dim=64, five_fold=False, gamma=2, gpu=0, input=None, lr=0.03, maml=True, maml_model_path='pretrained_maml.weights', model='BAN', momentum_cnn=0.05, num_hid=1024, num_stacks=2, op='c', output='saved_model_Med2019/BAN_MEVF', pow=2, print_interval=40, qc_model_path='./saved_models/QC/rad_best.pth', question_len=12, record_id=1, rescale_factor=1.5, rnn='LSTM', seed=3, tfidf=True, update_freq='1', use_RAD=True, use_ablation=False, use_ablation_q=False, use_ablation_v=False, use_counter=False, use_grad_cam=False, use_kl_mix=False, use_mix=True, use_mix_all=False, use_mix_cond=True, use_mix_cond_q=True, use_mix_cond_v=False, use_mix_cond_vq_in=False, use_mix_cond_vq_union=False, use_partial_label=False, use_rescale=False, use_sep_mix=False)
nParams=	21342541
optim: adamax lr=0.0300, decay_step=3, decay_rate=0.75, grad_clip=0.25
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'language_model.WordEmbedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Iter: 40, Loss 0.021839, Num updates: 40, Wall time: 10.98, ETA: 0m 9s (- 1m 31s)
Iter: 80, Loss 0.012096, Num updates: 80, Wall time: 18.03, ETA: 0m 16s (- 1m 8s)
Iter: 120, Loss 0.008773, Num updates: 120, Wall time: 25.21, ETA: 0m 24s (- 0m 56s)
Iter: 160, Loss 0.007119, Num updates: 160, Wall time: 32.43, ETA: 0m 31s (- 0m 47s)
Iter: 200, Loss 0.006112, Num updates: 200, Wall time: 39.74, ETA: 0m 38s (- 0m 38s)
Iter: 240, Loss 0.005429, Num updates: 240, Wall time: 46.29, ETA: 0m 45s (- 0m 30s)
Iter: 280, Loss 0.004942, Num updates: 280, Wall time: 53.09, ETA: 0m 51s (- 0m 22s)
Iter: 320, Loss 0.004570, Num updates: 320, Wall time: 60.21, ETA: 0m 59s (- 0m 15s)
Iter: 360, Loss 0.004274, Num updates: 360, Wall time: 67.68, ETA: 1m 6s (- 0m 7s)
Iter: 400, Loss 0.004034, Num updates: 400, Wall time: 75.45, ETA: 1m 14s (- 0m 0s)
Evaluating...
epoch 0, time: 75.54
	train_loss: 0.0040, score: 14.34
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001794, Num updates: 40, Wall time: 85.07, ETA: 0m 8s (- 1m 15s)
Iter: 80, Loss 0.001808, Num updates: 80, Wall time: 91.92, ETA: 0m 14s (- 1m 0s)
Iter: 120, Loss 0.001799, Num updates: 120, Wall time: 98.91, ETA: 0m 21s (- 0m 51s)
Iter: 160, Loss 0.001797, Num updates: 160, Wall time: 105.71, ETA: 0m 28s (- 0m 43s)
Iter: 200, Loss 0.001800, Num updates: 200, Wall time: 112.33, ETA: 0m 35s (- 0m 35s)
Iter: 240, Loss 0.001795, Num updates: 240, Wall time: 119.23, ETA: 0m 42s (- 0m 28s)
Iter: 280, Loss 0.001798, Num updates: 280, Wall time: 125.61, ETA: 0m 48s (- 0m 21s)
Iter: 320, Loss 0.001798, Num updates: 320, Wall time: 132.73, ETA: 0m 55s (- 0m 14s)
Iter: 360, Loss 0.001794, Num updates: 360, Wall time: 139.78, ETA: 1m 2s (- 0m 7s)
Iter: 400, Loss 0.001787, Num updates: 400, Wall time: 146.74, ETA: 1m 9s (- 0m 0s)
Evaluating...
epoch 1, time: 70.90
	train_loss: 0.0018, score: 20.09
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001690, Num updates: 40, Wall time: 156.65, ETA: 0m 8s (- 1m 19s)
Iter: 80, Loss 0.001715, Num updates: 80, Wall time: 163.57, ETA: 0m 15s (- 1m 2s)
Iter: 120, Loss 0.001731, Num updates: 120, Wall time: 170.66, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001721, Num updates: 160, Wall time: 177.16, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001713, Num updates: 200, Wall time: 184.34, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001711, Num updates: 240, Wall time: 191.50, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001712, Num updates: 280, Wall time: 198.21, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001713, Num updates: 320, Wall time: 205.32, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001714, Num updates: 360, Wall time: 212.23, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001713, Num updates: 400, Wall time: 219.45, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 2, time: 72.40
	train_loss: 0.0017, score: 21.08
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001611, Num updates: 40, Wall time: 228.73, ETA: 0m 7s (- 1m 13s)
Iter: 80, Loss 0.001642, Num updates: 80, Wall time: 236.15, ETA: 0m 15s (- 1m 2s)
Iter: 120, Loss 0.001644, Num updates: 120, Wall time: 243.23, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001654, Num updates: 160, Wall time: 250.29, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001662, Num updates: 200, Wall time: 256.91, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001665, Num updates: 240, Wall time: 264.17, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001665, Num updates: 280, Wall time: 271.05, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001667, Num updates: 320, Wall time: 277.91, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001667, Num updates: 360, Wall time: 285.00, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001669, Num updates: 400, Wall time: 291.78, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 3, time: 72.10
	train_loss: 0.0017, score: 21.84
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001632, Num updates: 40, Wall time: 301.67, ETA: 0m 8s (- 1m 18s)
Iter: 80, Loss 0.001626, Num updates: 80, Wall time: 308.85, ETA: 0m 15s (- 1m 3s)
Iter: 120, Loss 0.001649, Num updates: 120, Wall time: 315.97, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001655, Num updates: 160, Wall time: 323.14, ETA: 0m 29s (- 0m 45s)
Iter: 200, Loss 0.001654, Num updates: 200, Wall time: 330.24, ETA: 0m 37s (- 0m 37s)
Iter: 240, Loss 0.001649, Num updates: 240, Wall time: 337.39, ETA: 0m 44s (- 0m 29s)
Iter: 280, Loss 0.001647, Num updates: 280, Wall time: 344.14, ETA: 0m 50s (- 0m 22s)
Iter: 320, Loss 0.001647, Num updates: 320, Wall time: 351.14, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001645, Num updates: 360, Wall time: 358.33, ETA: 1m 5s (- 0m 7s)
Iter: 400, Loss 0.001645, Num updates: 400, Wall time: 364.76, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 4, time: 72.63
	train_loss: 0.0016, score: 21.92
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001638, Num updates: 40, Wall time: 374.22, ETA: 0m 8s (- 1m 15s)
Iter: 80, Loss 0.001626, Num updates: 80, Wall time: 381.26, ETA: 0m 15s (- 1m 1s)
Iter: 120, Loss 0.001616, Num updates: 120, Wall time: 388.60, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001618, Num updates: 160, Wall time: 395.75, ETA: 0m 29s (- 0m 45s)
Iter: 200, Loss 0.001620, Num updates: 200, Wall time: 402.81, ETA: 0m 36s (- 0m 37s)
Iter: 240, Loss 0.001614, Num updates: 240, Wall time: 409.86, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001615, Num updates: 280, Wall time: 416.98, ETA: 0m 50s (- 0m 22s)
Iter: 320, Loss 0.001618, Num updates: 320, Wall time: 423.87, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001623, Num updates: 360, Wall time: 431.11, ETA: 1m 5s (- 0m 7s)
Iter: 400, Loss 0.001623, Num updates: 400, Wall time: 438.09, ETA: 1m 12s (- 0m 0s)
Evaluating...
epoch 5, time: 73.05
	train_loss: 0.0016, score: 22.49
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001519, Num updates: 40, Wall time: 447.89, ETA: 0m 8s (- 1m 18s)
Iter: 80, Loss 0.001582, Num updates: 80, Wall time: 454.87, ETA: 0m 15s (- 1m 2s)
Iter: 120, Loss 0.001610, Num updates: 120, Wall time: 461.92, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001607, Num updates: 160, Wall time: 468.66, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001609, Num updates: 200, Wall time: 475.59, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001601, Num updates: 240, Wall time: 482.81, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001607, Num updates: 280, Wall time: 489.61, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001608, Num updates: 320, Wall time: 496.54, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001609, Num updates: 360, Wall time: 503.41, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001605, Num updates: 400, Wall time: 510.38, ETA: 1m 10s (- 0m 0s)
Evaluating...
epoch 6, time: 72.13
	train_loss: 0.0016, score: 23.40
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001554, Num updates: 40, Wall time: 520.27, ETA: 0m 8s (- 1m 18s)
Iter: 80, Loss 0.001576, Num updates: 80, Wall time: 527.31, ETA: 0m 15s (- 1m 2s)
Iter: 120, Loss 0.001586, Num updates: 120, Wall time: 534.18, ETA: 0m 22s (- 0m 52s)
Iter: 160, Loss 0.001585, Num updates: 160, Wall time: 541.64, ETA: 0m 29s (- 0m 45s)
Iter: 200, Loss 0.001583, Num updates: 200, Wall time: 548.83, ETA: 0m 37s (- 0m 37s)
Iter: 240, Loss 0.001586, Num updates: 240, Wall time: 556.23, ETA: 0m 44s (- 0m 29s)
Iter: 280, Loss 0.001582, Num updates: 280, Wall time: 563.06, ETA: 0m 51s (- 0m 22s)
Iter: 320, Loss 0.001589, Num updates: 320, Wall time: 570.10, ETA: 0m 58s (- 0m 14s)
Iter: 360, Loss 0.001587, Num updates: 360, Wall time: 576.84, ETA: 1m 5s (- 0m 7s)
Iter: 400, Loss 0.001587, Num updates: 400, Wall time: 583.88, ETA: 1m 12s (- 0m 0s)
Evaluating...
epoch 7, time: 73.22
	train_loss: 0.0016, score: 23.75
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001523, Num updates: 40, Wall time: 593.88, ETA: 0m 8s (- 1m 19s)
Iter: 80, Loss 0.001556, Num updates: 80, Wall time: 600.74, ETA: 0m 15s (- 1m 2s)
Iter: 120, Loss 0.001562, Num updates: 120, Wall time: 607.68, ETA: 0m 22s (- 0m 52s)
Iter: 160, Loss 0.001565, Num updates: 160, Wall time: 614.64, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001569, Num updates: 200, Wall time: 621.36, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001573, Num updates: 240, Wall time: 628.48, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001572, Num updates: 280, Wall time: 635.56, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001572, Num updates: 320, Wall time: 642.77, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001573, Num updates: 360, Wall time: 649.71, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001571, Num updates: 400, Wall time: 656.85, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 8, time: 72.50
	train_loss: 0.0016, score: 23.75
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001486, Num updates: 40, Wall time: 666.43, ETA: 0m 8s (- 1m 17s)
Iter: 80, Loss 0.001508, Num updates: 80, Wall time: 673.20, ETA: 0m 15s (- 1m 1s)
Iter: 120, Loss 0.001521, Num updates: 120, Wall time: 680.18, ETA: 0m 22s (- 0m 52s)
Iter: 160, Loss 0.001538, Num updates: 160, Wall time: 686.80, ETA: 0m 28s (- 0m 43s)
Iter: 200, Loss 0.001546, Num updates: 200, Wall time: 693.97, ETA: 0m 35s (- 0m 36s)
Iter: 240, Loss 0.001550, Num updates: 240, Wall time: 700.85, ETA: 0m 42s (- 0m 28s)
Iter: 280, Loss 0.001557, Num updates: 280, Wall time: 708.02, ETA: 0m 49s (- 0m 21s)
Iter: 320, Loss 0.001558, Num updates: 320, Wall time: 715.18, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001558, Num updates: 360, Wall time: 722.24, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001555, Num updates: 400, Wall time: 729.40, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 9, time: 72.22
	train_loss: 0.0016, score: 24.04
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001480, Num updates: 40, Wall time: 738.81, ETA: 0m 8s (- 1m 16s)
Iter: 80, Loss 0.001516, Num updates: 80, Wall time: 745.61, ETA: 0m 15s (- 1m 1s)
Iter: 120, Loss 0.001516, Num updates: 120, Wall time: 752.59, ETA: 0m 22s (- 0m 51s)
Iter: 160, Loss 0.001523, Num updates: 160, Wall time: 759.67, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001538, Num updates: 200, Wall time: 766.94, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001534, Num updates: 240, Wall time: 773.81, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001537, Num updates: 280, Wall time: 780.36, ETA: 0m 49s (- 0m 21s)
Iter: 320, Loss 0.001539, Num updates: 320, Wall time: 787.42, ETA: 0m 56s (- 0m 14s)
Iter: 360, Loss 0.001535, Num updates: 360, Wall time: 794.36, ETA: 1m 3s (- 0m 7s)
Iter: 400, Loss 0.001538, Num updates: 400, Wall time: 801.25, ETA: 1m 10s (- 0m 0s)
Evaluating...
epoch 10, time: 72.07
	train_loss: 0.0015, score: 24.27
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001509, Num updates: 40, Wall time: 811.13, ETA: 0m 8s (- 1m 16s)
Iter: 80, Loss 0.001520, Num updates: 80, Wall time: 818.16, ETA: 0m 15s (- 1m 1s)
Iter: 120, Loss 0.001526, Num updates: 120, Wall time: 824.94, ETA: 0m 22s (- 0m 52s)
Iter: 160, Loss 0.001518, Num updates: 160, Wall time: 831.70, ETA: 0m 28s (- 0m 43s)
Iter: 200, Loss 0.001515, Num updates: 200, Wall time: 838.58, ETA: 0m 35s (- 0m 36s)
Iter: 240, Loss 0.001520, Num updates: 240, Wall time: 845.88, ETA: 0m 42s (- 0m 28s)
Iter: 280, Loss 0.001522, Num updates: 280, Wall time: 852.28, ETA: 0m 49s (- 0m 21s)
Iter: 320, Loss 0.001516, Num updates: 320, Wall time: 859.31, ETA: 0m 56s (- 0m 14s)
Iter: 360, Loss 0.001517, Num updates: 360, Wall time: 866.23, ETA: 1m 3s (- 0m 7s)
Iter: 400, Loss 0.001520, Num updates: 400, Wall time: 873.44, ETA: 1m 10s (- 0m 0s)
Evaluating...
epoch 11, time: 71.70
	train_loss: 0.0015, score: 24.10
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001475, Num updates: 40, Wall time: 883.60, ETA: 0m 8s (- 1m 20s)
Iter: 80, Loss 0.001484, Num updates: 80, Wall time: 890.51, ETA: 0m 15s (- 1m 3s)
Iter: 120, Loss 0.001484, Num updates: 120, Wall time: 897.41, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001480, Num updates: 160, Wall time: 904.55, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001488, Num updates: 200, Wall time: 911.82, ETA: 0m 36s (- 0m 37s)
Iter: 240, Loss 0.001490, Num updates: 240, Wall time: 918.83, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001496, Num updates: 280, Wall time: 925.23, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001499, Num updates: 320, Wall time: 932.10, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001502, Num updates: 360, Wall time: 939.02, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001505, Num updates: 400, Wall time: 946.26, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 12, time: 72.58
	train_loss: 0.0015, score: 24.40
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001434, Num updates: 40, Wall time: 955.92, ETA: 0m 8s (- 1m 15s)
Iter: 80, Loss 0.001443, Num updates: 80, Wall time: 962.74, ETA: 0m 15s (- 1m 0s)
Iter: 120, Loss 0.001461, Num updates: 120, Wall time: 969.82, ETA: 0m 22s (- 0m 52s)
Iter: 160, Loss 0.001470, Num updates: 160, Wall time: 976.76, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001480, Num updates: 200, Wall time: 983.93, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001477, Num updates: 240, Wall time: 991.17, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001480, Num updates: 280, Wall time: 998.00, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001483, Num updates: 320, Wall time: 1005.20, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001482, Num updates: 360, Wall time: 1012.02, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001488, Num updates: 400, Wall time: 1019.50, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 13, time: 72.89
	train_loss: 0.0015, score: 24.49
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001466, Num updates: 40, Wall time: 1029.38, ETA: 0m 8s (- 1m 18s)
Iter: 80, Loss 0.001449, Num updates: 80, Wall time: 1036.56, ETA: 0m 15s (- 1m 3s)
Iter: 120, Loss 0.001447, Num updates: 120, Wall time: 1043.54, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001448, Num updates: 160, Wall time: 1050.30, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001453, Num updates: 200, Wall time: 1056.77, ETA: 0m 35s (- 0m 36s)
Iter: 240, Loss 0.001455, Num updates: 240, Wall time: 1063.41, ETA: 0m 42s (- 0m 28s)
Iter: 280, Loss 0.001464, Num updates: 280, Wall time: 1070.42, ETA: 0m 49s (- 0m 21s)
Iter: 320, Loss 0.001463, Num updates: 320, Wall time: 1077.56, ETA: 0m 56s (- 0m 14s)
Iter: 360, Loss 0.001467, Num updates: 360, Wall time: 1084.37, ETA: 1m 3s (- 0m 7s)
Iter: 400, Loss 0.001466, Num updates: 400, Wall time: 1091.49, ETA: 1m 10s (- 0m 0s)
Evaluating...
epoch 14, time: 71.84
	train_loss: 0.0015, score: 25.29
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001479, Num updates: 40, Wall time: 1101.44, ETA: 0m 8s (- 1m 18s)
Iter: 80, Loss 0.001459, Num updates: 80, Wall time: 1108.10, ETA: 0m 15s (- 1m 1s)
Iter: 120, Loss 0.001454, Num updates: 120, Wall time: 1115.35, ETA: 0m 22s (- 0m 52s)
Iter: 160, Loss 0.001457, Num updates: 160, Wall time: 1122.23, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001459, Num updates: 200, Wall time: 1129.26, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001464, Num updates: 240, Wall time: 1136.20, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001464, Num updates: 280, Wall time: 1143.02, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001459, Num updates: 320, Wall time: 1150.12, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001455, Num updates: 360, Wall time: 1157.28, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001454, Num updates: 400, Wall time: 1164.51, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 15, time: 72.75
	train_loss: 0.0015, score: 24.74
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001393, Num updates: 40, Wall time: 1174.55, ETA: 0m 8s (- 1m 19s)
Iter: 80, Loss 0.001406, Num updates: 80, Wall time: 1181.14, ETA: 0m 15s (- 1m 1s)
Iter: 120, Loss 0.001409, Num updates: 120, Wall time: 1187.78, ETA: 0m 21s (- 0m 51s)
Iter: 160, Loss 0.001420, Num updates: 160, Wall time: 1194.53, ETA: 0m 28s (- 0m 43s)
Iter: 200, Loss 0.001426, Num updates: 200, Wall time: 1201.75, ETA: 0m 35s (- 0m 36s)
Iter: 240, Loss 0.001429, Num updates: 240, Wall time: 1208.82, ETA: 0m 42s (- 0m 28s)
Iter: 280, Loss 0.001430, Num updates: 280, Wall time: 1216.02, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001434, Num updates: 320, Wall time: 1223.19, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001437, Num updates: 360, Wall time: 1229.90, ETA: 1m 3s (- 0m 7s)
Iter: 400, Loss 0.001435, Num updates: 400, Wall time: 1236.41, ETA: 1m 10s (- 0m 0s)
Evaluating...
epoch 16, time: 71.50
	train_loss: 0.0014, score: 25.04
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001358, Num updates: 40, Wall time: 1245.86, ETA: 0m 8s (- 1m 14s)
Iter: 80, Loss 0.001384, Num updates: 80, Wall time: 1252.38, ETA: 0m 14s (- 0m 59s)
Iter: 120, Loss 0.001397, Num updates: 120, Wall time: 1259.07, ETA: 0m 21s (- 0m 50s)
Iter: 160, Loss 0.001406, Num updates: 160, Wall time: 1265.93, ETA: 0m 28s (- 0m 42s)
Iter: 200, Loss 0.001406, Num updates: 200, Wall time: 1273.20, ETA: 0m 35s (- 0m 35s)
Iter: 240, Loss 0.001409, Num updates: 240, Wall time: 1279.92, ETA: 0m 42s (- 0m 28s)
Iter: 280, Loss 0.001407, Num updates: 280, Wall time: 1287.10, ETA: 0m 49s (- 0m 21s)
Iter: 320, Loss 0.001409, Num updates: 320, Wall time: 1294.09, ETA: 0m 56s (- 0m 14s)
Iter: 360, Loss 0.001414, Num updates: 360, Wall time: 1301.29, ETA: 1m 3s (- 0m 7s)
Iter: 400, Loss 0.001415, Num updates: 400, Wall time: 1308.13, ETA: 1m 10s (- 0m 0s)
Evaluating...
epoch 17, time: 71.25
	train_loss: 0.0014, score: 25.84
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001374, Num updates: 40, Wall time: 1317.51, ETA: 0m 8s (- 1m 15s)
Iter: 80, Loss 0.001380, Num updates: 80, Wall time: 1324.55, ETA: 0m 15s (- 1m 1s)
Iter: 120, Loss 0.001387, Num updates: 120, Wall time: 1331.28, ETA: 0m 21s (- 0m 51s)
Iter: 160, Loss 0.001393, Num updates: 160, Wall time: 1338.47, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001394, Num updates: 200, Wall time: 1345.69, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001395, Num updates: 240, Wall time: 1352.77, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001398, Num updates: 280, Wall time: 1359.95, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001396, Num updates: 320, Wall time: 1366.50, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001399, Num updates: 360, Wall time: 1373.71, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001401, Num updates: 400, Wall time: 1380.93, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 18, time: 72.71
	train_loss: 0.0014, score: 25.91
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001344, Num updates: 40, Wall time: 1390.19, ETA: 0m 7s (- 1m 12s)
Iter: 80, Loss 0.001360, Num updates: 80, Wall time: 1396.97, ETA: 0m 14s (- 0m 59s)
Iter: 120, Loss 0.001370, Num updates: 120, Wall time: 1403.97, ETA: 0m 21s (- 0m 51s)
Iter: 160, Loss 0.001377, Num updates: 160, Wall time: 1410.75, ETA: 0m 28s (- 0m 43s)
Iter: 200, Loss 0.001377, Num updates: 200, Wall time: 1417.48, ETA: 0m 35s (- 0m 35s)
Iter: 240, Loss 0.001380, Num updates: 240, Wall time: 1424.62, ETA: 0m 42s (- 0m 28s)
Iter: 280, Loss 0.001385, Num updates: 280, Wall time: 1432.39, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001387, Num updates: 320, Wall time: 1439.53, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001389, Num updates: 360, Wall time: 1446.65, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001387, Num updates: 400, Wall time: 1453.86, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 19, time: 72.72
	train_loss: 0.0014, score: 25.73
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001321, Num updates: 40, Wall time: 1464.34, ETA: 0m 8s (- 1m 20s)
Iter: 80, Loss 0.001347, Num updates: 80, Wall time: 1471.32, ETA: 0m 15s (- 1m 3s)
Iter: 120, Loss 0.001361, Num updates: 120, Wall time: 1479.23, ETA: 0m 23s (- 0m 55s)
Iter: 160, Loss 0.001362, Num updates: 160, Wall time: 1487.00, ETA: 0m 31s (- 0m 47s)
Iter: 200, Loss 0.001361, Num updates: 200, Wall time: 1495.01, ETA: 0m 39s (- 0m 39s)
Iter: 240, Loss 0.001365, Num updates: 240, Wall time: 1503.40, ETA: 0m 47s (- 0m 32s)
Iter: 280, Loss 0.001366, Num updates: 280, Wall time: 1511.24, ETA: 0m 55s (- 0m 24s)
Iter: 320, Loss 0.001367, Num updates: 320, Wall time: 1518.17, ETA: 1m 2s (- 0m 15s)
Iter: 360, Loss 0.001371, Num updates: 360, Wall time: 1525.17, ETA: 1m 9s (- 0m 7s)
Iter: 400, Loss 0.001370, Num updates: 400, Wall time: 1532.21, ETA: 1m 16s (- 0m 0s)
Evaluating...
epoch 20, time: 77.51
	train_loss: 0.0014, score: 26.52
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001339, Num updates: 40, Wall time: 1542.45, ETA: 0m 8s (- 1m 20s)
Iter: 80, Loss 0.001337, Num updates: 80, Wall time: 1549.24, ETA: 0m 15s (- 1m 2s)
Iter: 120, Loss 0.001338, Num updates: 120, Wall time: 1556.13, ETA: 0m 22s (- 0m 52s)
Iter: 160, Loss 0.001339, Num updates: 160, Wall time: 1563.10, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001337, Num updates: 200, Wall time: 1570.25, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001347, Num updates: 240, Wall time: 1577.31, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001353, Num updates: 280, Wall time: 1583.80, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001350, Num updates: 320, Wall time: 1590.79, ETA: 0m 56s (- 0m 14s)
Iter: 360, Loss 0.001353, Num updates: 360, Wall time: 1597.45, ETA: 1m 3s (- 0m 7s)
Iter: 400, Loss 0.001355, Num updates: 400, Wall time: 1604.19, ETA: 1m 10s (- 0m 0s)
Evaluating...
epoch 21, time: 71.58
	train_loss: 0.0014, score: 26.53
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001302, Num updates: 40, Wall time: 1614.31, ETA: 0m 8s (- 1m 20s)
Iter: 80, Loss 0.001322, Num updates: 80, Wall time: 1621.07, ETA: 0m 15s (- 1m 2s)
Iter: 120, Loss 0.001332, Num updates: 120, Wall time: 1628.11, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001330, Num updates: 160, Wall time: 1635.05, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001334, Num updates: 200, Wall time: 1642.02, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001339, Num updates: 240, Wall time: 1649.06, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001343, Num updates: 280, Wall time: 1656.17, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001339, Num updates: 320, Wall time: 1663.05, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001340, Num updates: 360, Wall time: 1669.63, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001343, Num updates: 400, Wall time: 1676.67, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 22, time: 72.25
	train_loss: 0.0013, score: 27.02
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001297, Num updates: 40, Wall time: 1686.05, ETA: 0m 7s (- 1m 13s)
Iter: 80, Loss 0.001316, Num updates: 80, Wall time: 1692.20, ETA: 0m 14s (- 0m 57s)
Iter: 120, Loss 0.001317, Num updates: 120, Wall time: 1699.11, ETA: 0m 20s (- 0m 49s)
Iter: 160, Loss 0.001315, Num updates: 160, Wall time: 1706.20, ETA: 0m 28s (- 0m 42s)
Iter: 200, Loss 0.001320, Num updates: 200, Wall time: 1713.50, ETA: 0m 35s (- 0m 35s)
Iter: 240, Loss 0.001320, Num updates: 240, Wall time: 1720.73, ETA: 0m 42s (- 0m 28s)
Iter: 280, Loss 0.001323, Num updates: 280, Wall time: 1727.98, ETA: 0m 49s (- 0m 21s)
Iter: 320, Loss 0.001328, Num updates: 320, Wall time: 1735.10, ETA: 0m 56s (- 0m 14s)
Iter: 360, Loss 0.001328, Num updates: 360, Wall time: 1742.30, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001330, Num updates: 400, Wall time: 1749.31, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 23, time: 72.20
	train_loss: 0.0013, score: 27.12
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001243, Num updates: 40, Wall time: 1758.73, ETA: 0m 8s (- 1m 14s)
Iter: 80, Loss 0.001290, Num updates: 80, Wall time: 1765.91, ETA: 0m 15s (- 1m 2s)
Iter: 120, Loss 0.001296, Num updates: 120, Wall time: 1772.28, ETA: 0m 21s (- 0m 51s)
Iter: 160, Loss 0.001306, Num updates: 160, Wall time: 1779.03, ETA: 0m 28s (- 0m 43s)
Iter: 200, Loss 0.001305, Num updates: 200, Wall time: 1786.36, ETA: 0m 35s (- 0m 36s)
Iter: 240, Loss 0.001309, Num updates: 240, Wall time: 1793.40, ETA: 0m 42s (- 0m 28s)
Iter: 280, Loss 0.001313, Num updates: 280, Wall time: 1800.24, ETA: 0m 49s (- 0m 21s)
Iter: 320, Loss 0.001314, Num updates: 320, Wall time: 1806.78, ETA: 0m 56s (- 0m 14s)
Iter: 360, Loss 0.001319, Num updates: 360, Wall time: 1814.09, ETA: 1m 3s (- 0m 7s)
Iter: 400, Loss 0.001318, Num updates: 400, Wall time: 1820.92, ETA: 1m 10s (- 0m 0s)
Evaluating...
epoch 24, time: 71.17
	train_loss: 0.0013, score: 27.38
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001244, Num updates: 40, Wall time: 1830.47, ETA: 0m 8s (- 1m 17s)
Iter: 80, Loss 0.001276, Num updates: 80, Wall time: 1836.98, ETA: 0m 14s (- 1m 0s)
Iter: 120, Loss 0.001277, Num updates: 120, Wall time: 1844.56, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001290, Num updates: 160, Wall time: 1851.50, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001295, Num updates: 200, Wall time: 1858.31, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001294, Num updates: 240, Wall time: 1865.03, ETA: 0m 42s (- 0m 28s)
Iter: 280, Loss 0.001297, Num updates: 280, Wall time: 1872.10, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001299, Num updates: 320, Wall time: 1878.77, ETA: 0m 56s (- 0m 14s)
Iter: 360, Loss 0.001302, Num updates: 360, Wall time: 1885.55, ETA: 1m 3s (- 0m 7s)
Iter: 400, Loss 0.001308, Num updates: 400, Wall time: 1892.07, ETA: 1m 10s (- 0m 0s)
Evaluating...
epoch 25, time: 71.13
	train_loss: 0.0013, score: 27.12
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001258, Num updates: 40, Wall time: 1901.69, ETA: 0m 8s (- 1m 15s)
Iter: 80, Loss 0.001284, Num updates: 80, Wall time: 1908.52, ETA: 0m 15s (- 1m 1s)
Iter: 120, Loss 0.001294, Num updates: 120, Wall time: 1915.39, ETA: 0m 21s (- 0m 51s)
Iter: 160, Loss 0.001287, Num updates: 160, Wall time: 1922.36, ETA: 0m 28s (- 0m 43s)
Iter: 200, Loss 0.001292, Num updates: 200, Wall time: 1929.40, ETA: 0m 35s (- 0m 36s)
Iter: 240, Loss 0.001292, Num updates: 240, Wall time: 1936.54, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001293, Num updates: 280, Wall time: 1943.74, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001291, Num updates: 320, Wall time: 1950.45, ETA: 0m 56s (- 0m 14s)
Iter: 360, Loss 0.001292, Num updates: 360, Wall time: 1957.56, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001294, Num updates: 400, Wall time: 1964.40, ETA: 1m 10s (- 0m 0s)
Evaluating...
epoch 26, time: 72.02
	train_loss: 0.0013, score: 27.73
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001223, Num updates: 40, Wall time: 1973.20, ETA: 0m 7s (- 1m 8s)
Iter: 80, Loss 0.001255, Num updates: 80, Wall time: 1980.29, ETA: 0m 14s (- 0m 58s)
Iter: 120, Loss 0.001256, Num updates: 120, Wall time: 1987.57, ETA: 0m 21s (- 0m 51s)
Iter: 160, Loss 0.001262, Num updates: 160, Wall time: 1993.73, ETA: 0m 27s (- 0m 42s)
Iter: 200, Loss 0.001269, Num updates: 200, Wall time: 2000.69, ETA: 0m 34s (- 0m 35s)
Iter: 240, Loss 0.001278, Num updates: 240, Wall time: 2007.44, ETA: 0m 41s (- 0m 28s)
Iter: 280, Loss 0.001284, Num updates: 280, Wall time: 2014.28, ETA: 0m 48s (- 0m 21s)
Iter: 320, Loss 0.001287, Num updates: 320, Wall time: 2021.02, ETA: 0m 55s (- 0m 14s)
Iter: 360, Loss 0.001286, Num updates: 360, Wall time: 2027.79, ETA: 1m 1s (- 0m 7s)
Iter: 400, Loss 0.001287, Num updates: 400, Wall time: 2034.96, ETA: 1m 9s (- 0m 0s)
Evaluating...
epoch 27, time: 70.35
	train_loss: 0.0013, score: 26.85
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001224, Num updates: 40, Wall time: 2044.19, ETA: 0m 7s (- 1m 11s)
Iter: 80, Loss 0.001227, Num updates: 80, Wall time: 2050.44, ETA: 0m 14s (- 0m 56s)
Iter: 120, Loss 0.001244, Num updates: 120, Wall time: 2056.21, ETA: 0m 19s (- 0m 46s)
Iter: 160, Loss 0.001249, Num updates: 160, Wall time: 2062.08, ETA: 0m 25s (- 0m 38s)
Iter: 200, Loss 0.001260, Num updates: 200, Wall time: 2068.14, ETA: 0m 31s (- 0m 32s)
Iter: 240, Loss 0.001266, Num updates: 240, Wall time: 2074.07, ETA: 0m 37s (- 0m 25s)
Iter: 280, Loss 0.001265, Num updates: 280, Wall time: 2080.39, ETA: 0m 43s (- 0m 19s)
Iter: 320, Loss 0.001270, Num updates: 320, Wall time: 2086.01, ETA: 0m 49s (- 0m 12s)
Iter: 360, Loss 0.001273, Num updates: 360, Wall time: 2092.15, ETA: 0m 55s (- 0m 6s)
Iter: 400, Loss 0.001276, Num updates: 400, Wall time: 2098.47, ETA: 1m 2s (- 0m 0s)
Evaluating...
epoch 28, time: 63.29
	train_loss: 0.0013, score: 27.79
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001230, Num updates: 40, Wall time: 2107.95, ETA: 0m 7s (- 1m 13s)
Iter: 80, Loss 0.001239, Num updates: 80, Wall time: 2115.00, ETA: 0m 15s (- 1m 1s)
Iter: 120, Loss 0.001247, Num updates: 120, Wall time: 2121.89, ETA: 0m 21s (- 0m 51s)
Iter: 160, Loss 0.001258, Num updates: 160, Wall time: 2128.74, ETA: 0m 28s (- 0m 43s)
Iter: 200, Loss 0.001253, Num updates: 200, Wall time: 2135.54, ETA: 0m 35s (- 0m 35s)
Iter: 240, Loss 0.001255, Num updates: 240, Wall time: 2142.74, ETA: 0m 42s (- 0m 28s)
Iter: 280, Loss 0.001260, Num updates: 280, Wall time: 2149.86, ETA: 0m 49s (- 0m 21s)
Iter: 320, Loss 0.001260, Num updates: 320, Wall time: 2156.82, ETA: 0m 56s (- 0m 14s)
Iter: 360, Loss 0.001265, Num updates: 360, Wall time: 2163.54, ETA: 1m 3s (- 0m 7s)
Iter: 400, Loss 0.001268, Num updates: 400, Wall time: 2170.59, ETA: 1m 10s (- 0m 0s)
Evaluating...
epoch 29, time: 71.78
	train_loss: 0.0013, score: 28.06
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001201, Num updates: 40, Wall time: 2180.18, ETA: 0m 8s (- 1m 15s)
Iter: 80, Loss 0.001217, Num updates: 80, Wall time: 2187.20, ETA: 0m 15s (- 1m 1s)
Iter: 120, Loss 0.001232, Num updates: 120, Wall time: 2194.41, ETA: 0m 22s (- 0m 52s)
Iter: 160, Loss 0.001237, Num updates: 160, Wall time: 2201.27, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001242, Num updates: 200, Wall time: 2208.41, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001253, Num updates: 240, Wall time: 2215.52, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001252, Num updates: 280, Wall time: 2222.51, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001255, Num updates: 320, Wall time: 2229.29, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001255, Num updates: 360, Wall time: 2236.65, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001260, Num updates: 400, Wall time: 2243.45, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 30, time: 72.30
	train_loss: 0.0013, score: 27.20
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001222, Num updates: 40, Wall time: 2254.13, ETA: 0m 8s (- 1m 21s)
Iter: 80, Loss 0.001237, Num updates: 80, Wall time: 2260.56, ETA: 0m 15s (- 1m 1s)
Iter: 120, Loss 0.001238, Num updates: 120, Wall time: 2267.64, ETA: 0m 22s (- 0m 52s)
Iter: 160, Loss 0.001248, Num updates: 160, Wall time: 2274.61, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001256, Num updates: 200, Wall time: 2281.85, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001258, Num updates: 240, Wall time: 2288.55, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001253, Num updates: 280, Wall time: 2295.46, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001253, Num updates: 320, Wall time: 2302.46, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001251, Num updates: 360, Wall time: 2308.92, ETA: 1m 3s (- 0m 7s)
Iter: 400, Loss 0.001253, Num updates: 400, Wall time: 2316.06, ETA: 1m 10s (- 0m 0s)
Evaluating...
epoch 31, time: 71.86
	train_loss: 0.0013, score: 27.56
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001194, Num updates: 40, Wall time: 2325.97, ETA: 0m 8s (- 1m 18s)
Iter: 80, Loss 0.001213, Num updates: 80, Wall time: 2333.02, ETA: 0m 15s (- 1m 3s)
Iter: 120, Loss 0.001220, Num updates: 120, Wall time: 2340.55, ETA: 0m 23s (- 0m 54s)
Iter: 160, Loss 0.001224, Num updates: 160, Wall time: 2347.51, ETA: 0m 30s (- 0m 45s)
Iter: 200, Loss 0.001227, Num updates: 200, Wall time: 2354.24, ETA: 0m 36s (- 0m 37s)
Iter: 240, Loss 0.001239, Num updates: 240, Wall time: 2360.99, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001242, Num updates: 280, Wall time: 2367.39, ETA: 0m 49s (- 0m 21s)
Iter: 320, Loss 0.001241, Num updates: 320, Wall time: 2374.61, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001241, Num updates: 360, Wall time: 2381.64, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001243, Num updates: 400, Wall time: 2387.89, ETA: 1m 10s (- 0m 0s)
Evaluating...
epoch 32, time: 71.44
	train_loss: 0.0012, score: 28.34
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001200, Num updates: 40, Wall time: 2397.57, ETA: 0m 8s (- 1m 17s)
Iter: 80, Loss 0.001210, Num updates: 80, Wall time: 2404.58, ETA: 0m 15s (- 1m 2s)
Iter: 120, Loss 0.001216, Num updates: 120, Wall time: 2411.33, ETA: 0m 22s (- 0m 52s)
Iter: 160, Loss 0.001217, Num updates: 160, Wall time: 2418.31, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001224, Num updates: 200, Wall time: 2425.63, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001227, Num updates: 240, Wall time: 2432.90, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001230, Num updates: 280, Wall time: 2439.68, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001232, Num updates: 320, Wall time: 2446.95, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001234, Num updates: 360, Wall time: 2453.77, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001236, Num updates: 400, Wall time: 2460.30, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 33, time: 72.21
	train_loss: 0.0012, score: 27.66
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001215, Num updates: 40, Wall time: 2470.14, ETA: 0m 8s (- 1m 18s)
Iter: 80, Loss 0.001214, Num updates: 80, Wall time: 2477.16, ETA: 0m 15s (- 1m 3s)
Iter: 120, Loss 0.001210, Num updates: 120, Wall time: 2484.04, ETA: 0m 22s (- 0m 52s)
Iter: 160, Loss 0.001209, Num updates: 160, Wall time: 2490.79, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001211, Num updates: 200, Wall time: 2497.23, ETA: 0m 35s (- 0m 35s)
Iter: 240, Loss 0.001211, Num updates: 240, Wall time: 2504.51, ETA: 0m 42s (- 0m 28s)
Iter: 280, Loss 0.001217, Num updates: 280, Wall time: 2511.79, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001217, Num updates: 320, Wall time: 2518.86, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001223, Num updates: 360, Wall time: 2525.94, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001225, Num updates: 400, Wall time: 2533.21, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 34, time: 72.70
	train_loss: 0.0012, score: 27.65
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001155, Num updates: 40, Wall time: 2543.58, ETA: 0m 8s (- 1m 22s)
Iter: 80, Loss 0.001184, Num updates: 80, Wall time: 2550.65, ETA: 0m 16s (- 1m 5s)
Iter: 120, Loss 0.001197, Num updates: 120, Wall time: 2557.43, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001205, Num updates: 160, Wall time: 2563.58, ETA: 0m 28s (- 0m 43s)
Iter: 200, Loss 0.001205, Num updates: 200, Wall time: 2570.52, ETA: 0m 35s (- 0m 36s)
Iter: 240, Loss 0.001208, Num updates: 240, Wall time: 2577.32, ETA: 0m 42s (- 0m 28s)
Iter: 280, Loss 0.001208, Num updates: 280, Wall time: 2584.59, ETA: 0m 49s (- 0m 21s)
Iter: 320, Loss 0.001213, Num updates: 320, Wall time: 2591.60, ETA: 0m 56s (- 0m 14s)
Iter: 360, Loss 0.001218, Num updates: 360, Wall time: 2598.65, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001218, Num updates: 400, Wall time: 2605.69, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 35, time: 72.28
	train_loss: 0.0012, score: 28.17
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001164, Num updates: 40, Wall time: 2615.36, ETA: 0m 8s (- 1m 15s)
Iter: 80, Loss 0.001184, Num updates: 80, Wall time: 2622.44, ETA: 0m 15s (- 1m 1s)
Iter: 120, Loss 0.001205, Num updates: 120, Wall time: 2629.63, ETA: 0m 22s (- 0m 52s)
Iter: 160, Loss 0.001204, Num updates: 160, Wall time: 2636.91, ETA: 0m 29s (- 0m 45s)
Iter: 200, Loss 0.001207, Num updates: 200, Wall time: 2643.52, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001213, Num updates: 240, Wall time: 2650.42, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001215, Num updates: 280, Wall time: 2657.32, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001215, Num updates: 320, Wall time: 2664.05, ETA: 0m 56s (- 0m 14s)
Iter: 360, Loss 0.001213, Num updates: 360, Wall time: 2671.11, ETA: 1m 3s (- 0m 7s)
Iter: 400, Loss 0.001214, Num updates: 400, Wall time: 2678.03, ETA: 1m 10s (- 0m 0s)
Evaluating...
epoch 36, time: 71.89
	train_loss: 0.0012, score: 28.05
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001157, Num updates: 40, Wall time: 2687.86, ETA: 0m 8s (- 1m 18s)
Iter: 80, Loss 0.001186, Num updates: 80, Wall time: 2694.90, ETA: 0m 15s (- 1m 3s)
Iter: 120, Loss 0.001189, Num updates: 120, Wall time: 2701.96, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001191, Num updates: 160, Wall time: 2709.34, ETA: 0m 29s (- 0m 45s)
Iter: 200, Loss 0.001199, Num updates: 200, Wall time: 2716.23, ETA: 0m 36s (- 0m 37s)
Iter: 240, Loss 0.001200, Num updates: 240, Wall time: 2723.16, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001206, Num updates: 280, Wall time: 2730.21, ETA: 0m 50s (- 0m 22s)
Iter: 320, Loss 0.001205, Num updates: 320, Wall time: 2737.27, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001208, Num updates: 360, Wall time: 2744.36, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001209, Num updates: 400, Wall time: 2751.11, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 37, time: 72.77
	train_loss: 0.0012, score: 27.48
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001151, Num updates: 40, Wall time: 2760.85, ETA: 0m 8s (- 1m 18s)
Iter: 80, Loss 0.001169, Num updates: 80, Wall time: 2767.98, ETA: 0m 15s (- 1m 3s)
Iter: 120, Loss 0.001179, Num updates: 120, Wall time: 2774.91, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001182, Num updates: 160, Wall time: 2781.75, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001190, Num updates: 200, Wall time: 2788.65, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001192, Num updates: 240, Wall time: 2795.78, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001196, Num updates: 280, Wall time: 2802.47, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001195, Num updates: 320, Wall time: 2809.62, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001197, Num updates: 360, Wall time: 2816.05, ETA: 1m 3s (- 0m 7s)
Iter: 400, Loss 0.001199, Num updates: 400, Wall time: 2822.94, ETA: 1m 10s (- 0m 0s)
Evaluating...
epoch 38, time: 71.61
	train_loss: 0.0012, score: 27.80
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001185, Num updates: 40, Wall time: 2833.17, ETA: 0m 8s (- 1m 22s)
Iter: 80, Loss 0.001180, Num updates: 80, Wall time: 2840.03, ETA: 0m 15s (- 1m 3s)
Iter: 120, Loss 0.001180, Num updates: 120, Wall time: 2846.82, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001184, Num updates: 160, Wall time: 2853.94, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001183, Num updates: 200, Wall time: 2861.08, ETA: 0m 36s (- 0m 37s)
Iter: 240, Loss 0.001189, Num updates: 240, Wall time: 2867.82, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001194, Num updates: 280, Wall time: 2874.90, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001196, Num updates: 320, Wall time: 2882.10, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001197, Num updates: 360, Wall time: 2888.94, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001198, Num updates: 400, Wall time: 2895.85, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 39, time: 72.72
	train_loss: 0.0012, score: 27.83
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001149, Num updates: 40, Wall time: 2906.17, ETA: 0m 8s (- 1m 18s)
Iter: 80, Loss 0.001170, Num updates: 80, Wall time: 2913.46, ETA: 0m 15s (- 1m 4s)
Iter: 120, Loss 0.001185, Num updates: 120, Wall time: 2920.43, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001181, Num updates: 160, Wall time: 2927.88, ETA: 0m 30s (- 0m 45s)
Iter: 200, Loss 0.001181, Num updates: 200, Wall time: 2934.28, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001182, Num updates: 240, Wall time: 2941.19, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001185, Num updates: 280, Wall time: 2948.02, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001187, Num updates: 320, Wall time: 2955.06, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001191, Num updates: 360, Wall time: 2961.79, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001192, Num updates: 400, Wall time: 2968.67, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 40, time: 71.99
	train_loss: 0.0012, score: 28.01
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001137, Num updates: 40, Wall time: 2978.45, ETA: 0m 8s (- 1m 18s)
Iter: 80, Loss 0.001170, Num updates: 80, Wall time: 2985.27, ETA: 0m 15s (- 1m 2s)
Iter: 120, Loss 0.001171, Num updates: 120, Wall time: 2992.73, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001183, Num updates: 160, Wall time: 2999.66, ETA: 0m 29s (- 0m 45s)
Iter: 200, Loss 0.001185, Num updates: 200, Wall time: 3005.94, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001185, Num updates: 240, Wall time: 3012.74, ETA: 0m 42s (- 0m 28s)
Iter: 280, Loss 0.001187, Num updates: 280, Wall time: 3019.79, ETA: 0m 49s (- 0m 21s)
Iter: 320, Loss 0.001187, Num updates: 320, Wall time: 3027.07, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001187, Num updates: 360, Wall time: 3033.99, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001187, Num updates: 400, Wall time: 3040.88, ETA: 1m 10s (- 0m 0s)
Evaluating...
epoch 41, time: 72.10
	train_loss: 0.0012, score: 28.47
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001146, Num updates: 40, Wall time: 3050.82, ETA: 0m 8s (- 1m 18s)
Iter: 80, Loss 0.001162, Num updates: 80, Wall time: 3057.69, ETA: 0m 15s (- 1m 2s)
Iter: 120, Loss 0.001165, Num updates: 120, Wall time: 3064.68, ETA: 0m 22s (- 0m 52s)
Iter: 160, Loss 0.001170, Num updates: 160, Wall time: 3071.78, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001172, Num updates: 200, Wall time: 3078.45, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001175, Num updates: 240, Wall time: 3085.41, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001176, Num updates: 280, Wall time: 3092.70, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001178, Num updates: 320, Wall time: 3099.73, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001179, Num updates: 360, Wall time: 3106.68, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001181, Num updates: 400, Wall time: 3113.81, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 42, time: 72.12
	train_loss: 0.0012, score: 27.41
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001144, Num updates: 40, Wall time: 3123.57, ETA: 0m 8s (- 1m 21s)
Iter: 80, Loss 0.001157, Num updates: 80, Wall time: 3130.61, ETA: 0m 15s (- 1m 4s)
Iter: 120, Loss 0.001162, Num updates: 120, Wall time: 3137.85, ETA: 0m 23s (- 0m 54s)
Iter: 160, Loss 0.001160, Num updates: 160, Wall time: 3145.12, ETA: 0m 30s (- 0m 46s)
Iter: 200, Loss 0.001168, Num updates: 200, Wall time: 3151.90, ETA: 0m 37s (- 0m 37s)
Iter: 240, Loss 0.001170, Num updates: 240, Wall time: 3158.68, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001170, Num updates: 280, Wall time: 3165.98, ETA: 0m 51s (- 0m 22s)
Iter: 320, Loss 0.001171, Num updates: 320, Wall time: 3172.75, ETA: 0m 58s (- 0m 14s)
Iter: 360, Loss 0.001172, Num updates: 360, Wall time: 3179.57, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001174, Num updates: 400, Wall time: 3186.52, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 43, time: 72.88
	train_loss: 0.0012, score: 27.63
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001128, Num updates: 40, Wall time: 3196.35, ETA: 0m 8s (- 1m 18s)
Iter: 80, Loss 0.001157, Num updates: 80, Wall time: 3203.27, ETA: 0m 15s (- 1m 2s)
Iter: 120, Loss 0.001144, Num updates: 120, Wall time: 3210.05, ETA: 0m 22s (- 0m 52s)
Iter: 160, Loss 0.001152, Num updates: 160, Wall time: 3217.46, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001156, Num updates: 200, Wall time: 3224.50, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001158, Num updates: 240, Wall time: 3231.60, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001162, Num updates: 280, Wall time: 3238.42, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001165, Num updates: 320, Wall time: 3244.98, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001167, Num updates: 360, Wall time: 3251.97, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001169, Num updates: 400, Wall time: 3258.71, ETA: 1m 10s (- 0m 0s)
Evaluating...
epoch 44, time: 71.73
	train_loss: 0.0012, score: 28.25
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001147, Num updates: 40, Wall time: 3268.44, ETA: 0m 8s (- 1m 19s)
Iter: 80, Loss 0.001148, Num updates: 80, Wall time: 3275.42, ETA: 0m 15s (- 1m 3s)
Iter: 120, Loss 0.001149, Num updates: 120, Wall time: 3282.30, ETA: 0m 22s (- 0m 52s)
Iter: 160, Loss 0.001159, Num updates: 160, Wall time: 3289.25, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001156, Num updates: 200, Wall time: 3296.22, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001161, Num updates: 240, Wall time: 3303.32, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001166, Num updates: 280, Wall time: 3310.06, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001164, Num updates: 320, Wall time: 3317.06, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001164, Num updates: 360, Wall time: 3324.03, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001164, Num updates: 400, Wall time: 3331.08, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 45, time: 72.27
	train_loss: 0.0012, score: 28.09
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001147, Num updates: 40, Wall time: 3340.53, ETA: 0m 8s (- 1m 14s)
Iter: 80, Loss 0.001154, Num updates: 80, Wall time: 3347.41, ETA: 0m 14s (- 1m 0s)
Iter: 120, Loss 0.001161, Num updates: 120, Wall time: 3354.76, ETA: 0m 22s (- 0m 52s)
Iter: 160, Loss 0.001154, Num updates: 160, Wall time: 3361.78, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001155, Num updates: 200, Wall time: 3368.71, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001154, Num updates: 240, Wall time: 3375.88, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001159, Num updates: 280, Wall time: 3383.06, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001160, Num updates: 320, Wall time: 3390.14, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001160, Num updates: 360, Wall time: 3397.29, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001162, Num updates: 400, Wall time: 3404.09, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 46, time: 72.70
	train_loss: 0.0012, score: 27.40
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001109, Num updates: 40, Wall time: 3414.00, ETA: 0m 8s (- 1m 19s)
Iter: 80, Loss 0.001137, Num updates: 80, Wall time: 3421.20, ETA: 0m 15s (- 1m 4s)
Iter: 120, Loss 0.001145, Num updates: 120, Wall time: 3428.09, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001145, Num updates: 160, Wall time: 3434.90, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001151, Num updates: 200, Wall time: 3442.00, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001153, Num updates: 240, Wall time: 3449.08, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001151, Num updates: 280, Wall time: 3456.35, ETA: 0m 50s (- 0m 22s)
Iter: 320, Loss 0.001150, Num updates: 320, Wall time: 3463.15, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001151, Num updates: 360, Wall time: 3470.13, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001152, Num updates: 400, Wall time: 3477.27, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 47, time: 73.06
	train_loss: 0.0012, score: 28.02
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001112, Num updates: 40, Wall time: 3486.57, ETA: 0m 7s (- 1m 12s)
Iter: 80, Loss 0.001126, Num updates: 80, Wall time: 3493.53, ETA: 0m 14s (- 0m 59s)
Iter: 120, Loss 0.001142, Num updates: 120, Wall time: 3499.79, ETA: 0m 21s (- 0m 49s)
Iter: 160, Loss 0.001149, Num updates: 160, Wall time: 3506.88, ETA: 0m 28s (- 0m 42s)
Iter: 200, Loss 0.001151, Num updates: 200, Wall time: 3514.12, ETA: 0m 35s (- 0m 35s)
Iter: 240, Loss 0.001148, Num updates: 240, Wall time: 3521.01, ETA: 0m 42s (- 0m 28s)
Iter: 280, Loss 0.001143, Num updates: 280, Wall time: 3528.01, ETA: 0m 49s (- 0m 21s)
Iter: 320, Loss 0.001148, Num updates: 320, Wall time: 3534.65, ETA: 0m 55s (- 0m 14s)
Iter: 360, Loss 0.001151, Num updates: 360, Wall time: 3541.78, ETA: 1m 3s (- 0m 7s)
Iter: 400, Loss 0.001151, Num updates: 400, Wall time: 3549.12, ETA: 1m 10s (- 0m 0s)
Evaluating...
epoch 48, time: 71.37
	train_loss: 0.0012, score: 27.27
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001098, Num updates: 40, Wall time: 3558.77, ETA: 0m 8s (- 1m 17s)
Iter: 80, Loss 0.001111, Num updates: 80, Wall time: 3565.81, ETA: 0m 15s (- 1m 2s)
Iter: 120, Loss 0.001125, Num updates: 120, Wall time: 3572.49, ETA: 0m 22s (- 0m 52s)
Iter: 160, Loss 0.001131, Num updates: 160, Wall time: 3579.50, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001134, Num updates: 200, Wall time: 3586.68, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001134, Num updates: 240, Wall time: 3594.15, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001140, Num updates: 280, Wall time: 3600.92, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001145, Num updates: 320, Wall time: 3608.10, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001145, Num updates: 360, Wall time: 3615.26, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001147, Num updates: 400, Wall time: 3622.26, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 49, time: 73.06
	train_loss: 0.0011, score: 27.48
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001078, Num updates: 40, Wall time: 3632.02, ETA: 0m 8s (- 1m 16s)
Iter: 80, Loss 0.001111, Num updates: 80, Wall time: 3638.91, ETA: 0m 15s (- 1m 1s)
Iter: 120, Loss 0.001125, Num updates: 120, Wall time: 3646.18, ETA: 0m 22s (- 0m 52s)
Iter: 160, Loss 0.001132, Num updates: 160, Wall time: 3653.37, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001132, Num updates: 200, Wall time: 3660.18, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001138, Num updates: 240, Wall time: 3667.20, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001137, Num updates: 280, Wall time: 3673.80, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001133, Num updates: 320, Wall time: 3680.60, ETA: 0m 56s (- 0m 14s)
Iter: 360, Loss 0.001138, Num updates: 360, Wall time: 3687.50, ETA: 1m 3s (- 0m 7s)
Iter: 400, Loss 0.001142, Num updates: 400, Wall time: 3693.81, ETA: 1m 10s (- 0m 0s)
Evaluating...
epoch 50, time: 71.23
	train_loss: 0.0011, score: 27.48
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001113, Num updates: 40, Wall time: 3703.59, ETA: 0m 8s (- 1m 16s)
Iter: 80, Loss 0.001123, Num updates: 80, Wall time: 3710.75, ETA: 0m 15s (- 1m 2s)
Iter: 120, Loss 0.001122, Num updates: 120, Wall time: 3717.84, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001129, Num updates: 160, Wall time: 3724.69, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001128, Num updates: 200, Wall time: 3731.66, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001131, Num updates: 240, Wall time: 3738.63, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001132, Num updates: 280, Wall time: 3745.83, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001133, Num updates: 320, Wall time: 3752.67, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001136, Num updates: 360, Wall time: 3760.00, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001137, Num updates: 400, Wall time: 3767.11, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 51, time: 72.83
	train_loss: 0.0011, score: 27.24
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001093, Num updates: 40, Wall time: 3776.83, ETA: 0m 8s (- 1m 17s)
Iter: 80, Loss 0.001111, Num updates: 80, Wall time: 3783.80, ETA: 0m 15s (- 1m 2s)
Iter: 120, Loss 0.001116, Num updates: 120, Wall time: 3790.75, ETA: 0m 22s (- 0m 52s)
Iter: 160, Loss 0.001118, Num updates: 160, Wall time: 3797.95, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001129, Num updates: 200, Wall time: 3804.47, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001133, Num updates: 240, Wall time: 3811.31, ETA: 0m 42s (- 0m 28s)
Iter: 280, Loss 0.001133, Num updates: 280, Wall time: 3818.11, ETA: 0m 49s (- 0m 21s)
Iter: 320, Loss 0.001135, Num updates: 320, Wall time: 3825.40, ETA: 0m 56s (- 0m 14s)
Iter: 360, Loss 0.001135, Num updates: 360, Wall time: 3832.56, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001134, Num updates: 400, Wall time: 3839.80, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 52, time: 72.55
	train_loss: 0.0011, score: 27.73
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001102, Num updates: 40, Wall time: 3849.89, ETA: 0m 8s (- 1m 20s)
Iter: 80, Loss 0.001113, Num updates: 80, Wall time: 3857.01, ETA: 0m 15s (- 1m 4s)
Iter: 120, Loss 0.001120, Num updates: 120, Wall time: 3864.20, ETA: 0m 22s (- 0m 54s)
Iter: 160, Loss 0.001121, Num updates: 160, Wall time: 3870.71, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001121, Num updates: 200, Wall time: 3877.54, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001122, Num updates: 240, Wall time: 3884.82, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001127, Num updates: 280, Wall time: 3891.82, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001129, Num updates: 320, Wall time: 3898.68, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001130, Num updates: 360, Wall time: 3905.95, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001131, Num updates: 400, Wall time: 3913.23, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 53, time: 72.97
	train_loss: 0.0011, score: 28.00
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001073, Num updates: 40, Wall time: 3923.37, ETA: 0m 8s (- 1m 22s)
Iter: 80, Loss 0.001090, Num updates: 80, Wall time: 3930.25, ETA: 0m 15s (- 1m 3s)
Iter: 120, Loss 0.001091, Num updates: 120, Wall time: 3937.37, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001098, Num updates: 160, Wall time: 3944.46, ETA: 0m 29s (- 0m 45s)
Iter: 200, Loss 0.001107, Num updates: 200, Wall time: 3951.82, ETA: 0m 37s (- 0m 37s)
Iter: 240, Loss 0.001109, Num updates: 240, Wall time: 3958.65, ETA: 0m 44s (- 0m 29s)
Iter: 280, Loss 0.001115, Num updates: 280, Wall time: 3965.67, ETA: 0m 51s (- 0m 22s)
Iter: 320, Loss 0.001119, Num updates: 320, Wall time: 3972.84, ETA: 0m 58s (- 0m 14s)
Iter: 360, Loss 0.001121, Num updates: 360, Wall time: 3979.84, ETA: 1m 5s (- 0m 7s)
Iter: 400, Loss 0.001124, Num updates: 400, Wall time: 3986.53, ETA: 1m 12s (- 0m 0s)
Evaluating...
epoch 54, time: 73.16
	train_loss: 0.0011, score: 27.77
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001091, Num updates: 40, Wall time: 3996.98, ETA: 0m 9s (- 1m 23s)
Iter: 80, Loss 0.001114, Num updates: 80, Wall time: 4003.97, ETA: 0m 16s (- 1m 5s)
Iter: 120, Loss 0.001114, Num updates: 120, Wall time: 4011.15, ETA: 0m 23s (- 0m 54s)
Iter: 160, Loss 0.001116, Num updates: 160, Wall time: 4018.40, ETA: 0m 30s (- 0m 46s)
Iter: 200, Loss 0.001112, Num updates: 200, Wall time: 4025.66, ETA: 0m 37s (- 0m 38s)
Iter: 240, Loss 0.001113, Num updates: 240, Wall time: 4032.87, ETA: 0m 44s (- 0m 30s)
Iter: 280, Loss 0.001115, Num updates: 280, Wall time: 4039.68, ETA: 0m 51s (- 0m 22s)
Iter: 320, Loss 0.001117, Num updates: 320, Wall time: 4046.86, ETA: 0m 58s (- 0m 14s)
Iter: 360, Loss 0.001118, Num updates: 360, Wall time: 4054.07, ETA: 1m 6s (- 0m 7s)
Iter: 400, Loss 0.001121, Num updates: 400, Wall time: 4060.88, ETA: 1m 12s (- 0m 0s)
Evaluating...
epoch 55, time: 74.08
	train_loss: 0.0011, score: 27.60
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001091, Num updates: 40, Wall time: 4071.11, ETA: 0m 8s (- 1m 21s)
Iter: 80, Loss 0.001094, Num updates: 80, Wall time: 4077.99, ETA: 0m 15s (- 1m 3s)
Iter: 120, Loss 0.001100, Num updates: 120, Wall time: 4085.20, ETA: 0m 22s (- 0m 54s)
Iter: 160, Loss 0.001111, Num updates: 160, Wall time: 4092.37, ETA: 0m 30s (- 0m 45s)
Iter: 200, Loss 0.001112, Num updates: 200, Wall time: 4099.21, ETA: 0m 36s (- 0m 37s)
Iter: 240, Loss 0.001115, Num updates: 240, Wall time: 4106.52, ETA: 0m 44s (- 0m 29s)
Iter: 280, Loss 0.001119, Num updates: 280, Wall time: 4113.84, ETA: 0m 51s (- 0m 22s)
Iter: 320, Loss 0.001117, Num updates: 320, Wall time: 4120.77, ETA: 0m 58s (- 0m 14s)
Iter: 360, Loss 0.001114, Num updates: 360, Wall time: 4127.79, ETA: 1m 5s (- 0m 7s)
Iter: 400, Loss 0.001116, Num updates: 400, Wall time: 4134.79, ETA: 1m 12s (- 0m 0s)
Evaluating...
epoch 56, time: 73.59
	train_loss: 0.0011, score: 27.20
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001096, Num updates: 40, Wall time: 4144.79, ETA: 0m 8s (- 1m 19s)
Iter: 80, Loss 0.001107, Num updates: 80, Wall time: 4152.09, ETA: 0m 15s (- 1m 4s)
Iter: 120, Loss 0.001109, Num updates: 120, Wall time: 4159.33, ETA: 0m 23s (- 0m 54s)
Iter: 160, Loss 0.001111, Num updates: 160, Wall time: 4166.48, ETA: 0m 30s (- 0m 45s)
Iter: 200, Loss 0.001114, Num updates: 200, Wall time: 4172.94, ETA: 0m 36s (- 0m 37s)
Iter: 240, Loss 0.001114, Num updates: 240, Wall time: 4180.13, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001115, Num updates: 280, Wall time: 4186.84, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001116, Num updates: 320, Wall time: 4193.75, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001114, Num updates: 360, Wall time: 4200.94, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001115, Num updates: 400, Wall time: 4208.20, ETA: 1m 12s (- 0m 0s)
Evaluating...
epoch 57, time: 73.10
	train_loss: 0.0011, score: 26.81
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001066, Num updates: 40, Wall time: 4218.29, ETA: 0m 8s (- 1m 20s)
Iter: 80, Loss 0.001082, Num updates: 80, Wall time: 4224.73, ETA: 0m 15s (- 1m 1s)
Iter: 120, Loss 0.001089, Num updates: 120, Wall time: 4231.91, ETA: 0m 22s (- 0m 52s)
Iter: 160, Loss 0.001094, Num updates: 160, Wall time: 4239.16, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001100, Num updates: 200, Wall time: 4246.48, ETA: 0m 36s (- 0m 37s)
Iter: 240, Loss 0.001103, Num updates: 240, Wall time: 4253.29, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001105, Num updates: 280, Wall time: 4260.25, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001109, Num updates: 320, Wall time: 4266.83, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001107, Num updates: 360, Wall time: 4273.78, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001109, Num updates: 400, Wall time: 4280.49, ETA: 1m 10s (- 0m 0s)
Evaluating...
epoch 58, time: 72.08
	train_loss: 0.0011, score: 27.67
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001083, Num updates: 40, Wall time: 4290.21, ETA: 0m 8s (- 1m 16s)
Iter: 80, Loss 0.001090, Num updates: 80, Wall time: 4297.75, ETA: 0m 15s (- 1m 4s)
Iter: 120, Loss 0.001086, Num updates: 120, Wall time: 4304.81, ETA: 0m 22s (- 0m 54s)
Iter: 160, Loss 0.001091, Num updates: 160, Wall time: 4311.71, ETA: 0m 29s (- 0m 45s)
Iter: 200, Loss 0.001095, Num updates: 200, Wall time: 4318.47, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001102, Num updates: 240, Wall time: 4325.30, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001104, Num updates: 280, Wall time: 4332.07, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001107, Num updates: 320, Wall time: 4339.00, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001109, Num updates: 360, Wall time: 4346.03, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001109, Num updates: 400, Wall time: 4352.93, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 59, time: 72.08
	train_loss: 0.0011, score: 27.17
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001051, Num updates: 40, Wall time: 4362.57, ETA: 0m 8s (- 1m 16s)
Iter: 80, Loss 0.001077, Num updates: 80, Wall time: 4369.61, ETA: 0m 15s (- 1m 2s)
Iter: 120, Loss 0.001089, Num updates: 120, Wall time: 4376.89, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001088, Num updates: 160, Wall time: 4383.34, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001091, Num updates: 200, Wall time: 4390.45, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001097, Num updates: 240, Wall time: 4397.56, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001100, Num updates: 280, Wall time: 4404.72, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001103, Num updates: 320, Wall time: 4411.90, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001102, Num updates: 360, Wall time: 4418.78, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001103, Num updates: 400, Wall time: 4425.63, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 60, time: 72.49
	train_loss: 0.0011, score: 27.50
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001067, Num updates: 40, Wall time: 4435.59, ETA: 0m 8s (- 1m 19s)
Iter: 80, Loss 0.001083, Num updates: 80, Wall time: 4442.78, ETA: 0m 15s (- 1m 3s)
Iter: 120, Loss 0.001083, Num updates: 120, Wall time: 4449.96, ETA: 0m 22s (- 0m 54s)
Iter: 160, Loss 0.001091, Num updates: 160, Wall time: 4456.71, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001092, Num updates: 200, Wall time: 4463.60, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001095, Num updates: 240, Wall time: 4470.50, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001097, Num updates: 280, Wall time: 4477.21, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001099, Num updates: 320, Wall time: 4484.18, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001100, Num updates: 360, Wall time: 4490.98, ETA: 1m 3s (- 0m 7s)
Iter: 400, Loss 0.001102, Num updates: 400, Wall time: 4497.73, ETA: 1m 10s (- 0m 0s)
Evaluating...
epoch 61, time: 71.85
	train_loss: 0.0011, score: 26.91
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001074, Num updates: 40, Wall time: 4507.26, ETA: 0m 8s (- 1m 15s)
Iter: 80, Loss 0.001077, Num updates: 80, Wall time: 4514.37, ETA: 0m 15s (- 1m 1s)
Iter: 120, Loss 0.001092, Num updates: 120, Wall time: 4521.13, ETA: 0m 21s (- 0m 51s)
Iter: 160, Loss 0.001091, Num updates: 160, Wall time: 4528.28, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001087, Num updates: 200, Wall time: 4535.67, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001094, Num updates: 240, Wall time: 4542.76, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001096, Num updates: 280, Wall time: 4549.67, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001096, Num updates: 320, Wall time: 4556.28, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001096, Num updates: 360, Wall time: 4563.13, ETA: 1m 3s (- 0m 7s)
Iter: 400, Loss 0.001096, Num updates: 400, Wall time: 4569.81, ETA: 1m 10s (- 0m 0s)
Evaluating...
epoch 62, time: 71.67
	train_loss: 0.0011, score: 27.05
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001052, Num updates: 40, Wall time: 4578.91, ETA: 0m 7s (- 1m 12s)
Iter: 80, Loss 0.001074, Num updates: 80, Wall time: 4585.84, ETA: 0m 14s (- 0m 59s)
Iter: 120, Loss 0.001072, Num updates: 120, Wall time: 4593.05, ETA: 0m 21s (- 0m 51s)
Iter: 160, Loss 0.001077, Num updates: 160, Wall time: 4600.36, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001078, Num updates: 200, Wall time: 4607.72, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001085, Num updates: 240, Wall time: 4614.83, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001087, Num updates: 280, Wall time: 4621.87, ETA: 0m 50s (- 0m 22s)
Iter: 320, Loss 0.001090, Num updates: 320, Wall time: 4628.77, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001091, Num updates: 360, Wall time: 4636.03, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001094, Num updates: 400, Wall time: 4642.68, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 63, time: 72.77
	train_loss: 0.0011, score: 27.28
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001064, Num updates: 40, Wall time: 4652.55, ETA: 0m 8s (- 1m 17s)
Iter: 80, Loss 0.001074, Num updates: 80, Wall time: 4659.80, ETA: 0m 15s (- 1m 3s)
Iter: 120, Loss 0.001079, Num updates: 120, Wall time: 4666.94, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001082, Num updates: 160, Wall time: 4673.78, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001088, Num updates: 200, Wall time: 4680.72, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001089, Num updates: 240, Wall time: 4687.99, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001093, Num updates: 280, Wall time: 4695.18, ETA: 0m 51s (- 0m 22s)
Iter: 320, Loss 0.001092, Num updates: 320, Wall time: 4702.02, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001093, Num updates: 360, Wall time: 4709.41, ETA: 1m 5s (- 0m 7s)
Iter: 400, Loss 0.001092, Num updates: 400, Wall time: 4716.20, ETA: 1m 12s (- 0m 0s)
Evaluating...
epoch 64, time: 72.85
	train_loss: 0.0011, score: 26.97
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001054, Num updates: 40, Wall time: 4726.00, ETA: 0m 8s (- 1m 20s)
Iter: 80, Loss 0.001078, Num updates: 80, Wall time: 4732.93, ETA: 0m 15s (- 1m 3s)
Iter: 120, Loss 0.001082, Num updates: 120, Wall time: 4739.73, ETA: 0m 22s (- 0m 52s)
Iter: 160, Loss 0.001081, Num updates: 160, Wall time: 4746.83, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001084, Num updates: 200, Wall time: 4753.80, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001083, Num updates: 240, Wall time: 4761.10, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001086, Num updates: 280, Wall time: 4767.99, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001087, Num updates: 320, Wall time: 4775.33, ETA: 0m 58s (- 0m 14s)
Iter: 360, Loss 0.001089, Num updates: 360, Wall time: 4782.55, ETA: 1m 5s (- 0m 7s)
Iter: 400, Loss 0.001090, Num updates: 400, Wall time: 4789.48, ETA: 1m 12s (- 0m 0s)
Evaluating...
epoch 65, time: 73.33
	train_loss: 0.0011, score: 27.39
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001045, Num updates: 40, Wall time: 4800.02, ETA: 0m 9s (- 1m 24s)
Iter: 80, Loss 0.001061, Num updates: 80, Wall time: 4807.19, ETA: 0m 16s (- 1m 6s)
Iter: 120, Loss 0.001074, Num updates: 120, Wall time: 4814.11, ETA: 0m 23s (- 0m 54s)
Iter: 160, Loss 0.001081, Num updates: 160, Wall time: 4821.06, ETA: 0m 30s (- 0m 45s)
Iter: 200, Loss 0.001080, Num updates: 200, Wall time: 4828.40, ETA: 0m 37s (- 0m 37s)
Iter: 240, Loss 0.001078, Num updates: 240, Wall time: 4835.35, ETA: 0m 44s (- 0m 29s)
Iter: 280, Loss 0.001082, Num updates: 280, Wall time: 4842.51, ETA: 0m 51s (- 0m 22s)
Iter: 320, Loss 0.001082, Num updates: 320, Wall time: 4849.88, ETA: 0m 58s (- 0m 14s)
Iter: 360, Loss 0.001085, Num updates: 360, Wall time: 4856.71, ETA: 1m 5s (- 0m 7s)
Iter: 400, Loss 0.001085, Num updates: 400, Wall time: 4863.68, ETA: 1m 12s (- 0m 0s)
Evaluating...
epoch 66, time: 73.87
	train_loss: 0.0011, score: 27.19
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001052, Num updates: 40, Wall time: 4873.75, ETA: 0m 8s (- 1m 20s)
Iter: 80, Loss 0.001061, Num updates: 80, Wall time: 4880.74, ETA: 0m 15s (- 1m 3s)
Iter: 120, Loss 0.001068, Num updates: 120, Wall time: 4887.43, ETA: 0m 22s (- 0m 52s)
Iter: 160, Loss 0.001071, Num updates: 160, Wall time: 4894.45, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001079, Num updates: 200, Wall time: 4901.62, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001082, Num updates: 240, Wall time: 4908.66, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001085, Num updates: 280, Wall time: 4915.93, ETA: 0m 50s (- 0m 22s)
Iter: 320, Loss 0.001085, Num updates: 320, Wall time: 4923.30, ETA: 0m 58s (- 0m 14s)
Iter: 360, Loss 0.001085, Num updates: 360, Wall time: 4930.46, ETA: 1m 5s (- 0m 7s)
Iter: 400, Loss 0.001087, Num updates: 400, Wall time: 4937.42, ETA: 1m 12s (- 0m 0s)
Evaluating...
epoch 67, time: 73.26
	train_loss: 0.0011, score: 26.91
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001055, Num updates: 40, Wall time: 4947.09, ETA: 0m 8s (- 1m 18s)
Iter: 80, Loss 0.001064, Num updates: 80, Wall time: 4954.36, ETA: 0m 15s (- 1m 4s)
Iter: 120, Loss 0.001073, Num updates: 120, Wall time: 4961.92, ETA: 0m 23s (- 0m 55s)
Iter: 160, Loss 0.001074, Num updates: 160, Wall time: 4969.24, ETA: 0m 30s (- 0m 46s)
Iter: 200, Loss 0.001076, Num updates: 200, Wall time: 4976.31, ETA: 0m 37s (- 0m 38s)
Iter: 240, Loss 0.001077, Num updates: 240, Wall time: 4983.46, ETA: 0m 44s (- 0m 30s)
Iter: 280, Loss 0.001078, Num updates: 280, Wall time: 4990.49, ETA: 0m 51s (- 0m 22s)
Iter: 320, Loss 0.001079, Num updates: 320, Wall time: 4997.01, ETA: 0m 58s (- 0m 14s)
Iter: 360, Loss 0.001078, Num updates: 360, Wall time: 5003.91, ETA: 1m 5s (- 0m 7s)
Iter: 400, Loss 0.001081, Num updates: 400, Wall time: 5010.87, ETA: 1m 12s (- 0m 0s)
Evaluating...
epoch 68, time: 73.31
	train_loss: 0.0011, score: 26.86
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001046, Num updates: 40, Wall time: 5020.94, ETA: 0m 8s (- 1m 21s)
Iter: 80, Loss 0.001055, Num updates: 80, Wall time: 5027.87, ETA: 0m 15s (- 1m 3s)
Iter: 120, Loss 0.001053, Num updates: 120, Wall time: 5034.65, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001062, Num updates: 160, Wall time: 5041.82, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001069, Num updates: 200, Wall time: 5049.15, ETA: 0m 36s (- 0m 37s)
Iter: 240, Loss 0.001071, Num updates: 240, Wall time: 5056.33, ETA: 0m 44s (- 0m 29s)
Iter: 280, Loss 0.001075, Num updates: 280, Wall time: 5063.54, ETA: 0m 51s (- 0m 22s)
Iter: 320, Loss 0.001077, Num updates: 320, Wall time: 5070.15, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001076, Num updates: 360, Wall time: 5076.87, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001074, Num updates: 400, Wall time: 5084.04, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 69, time: 72.90
	train_loss: 0.0011, score: 27.19
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001042, Num updates: 40, Wall time: 5094.26, ETA: 0m 8s (- 1m 22s)
Iter: 80, Loss 0.001055, Num updates: 80, Wall time: 5101.02, ETA: 0m 15s (- 1m 3s)
Iter: 120, Loss 0.001060, Num updates: 120, Wall time: 5108.00, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001066, Num updates: 160, Wall time: 5115.06, ETA: 0m 29s (- 0m 45s)
Iter: 200, Loss 0.001066, Num updates: 200, Wall time: 5122.16, ETA: 0m 36s (- 0m 37s)
Iter: 240, Loss 0.001071, Num updates: 240, Wall time: 5129.16, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001071, Num updates: 280, Wall time: 5135.89, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001072, Num updates: 320, Wall time: 5142.85, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001076, Num updates: 360, Wall time: 5149.85, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001074, Num updates: 400, Wall time: 5156.54, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 70, time: 72.26
	train_loss: 0.0011, score: 26.94
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001013, Num updates: 40, Wall time: 5166.08, ETA: 0m 8s (- 1m 15s)
Iter: 80, Loss 0.001039, Num updates: 80, Wall time: 5172.72, ETA: 0m 14s (- 1m 0s)
Iter: 120, Loss 0.001046, Num updates: 120, Wall time: 5179.79, ETA: 0m 21s (- 0m 51s)
Iter: 160, Loss 0.001054, Num updates: 160, Wall time: 5186.62, ETA: 0m 28s (- 0m 43s)
Iter: 200, Loss 0.001057, Num updates: 200, Wall time: 5193.84, ETA: 0m 35s (- 0m 36s)
Iter: 240, Loss 0.001060, Num updates: 240, Wall time: 5200.59, ETA: 0m 42s (- 0m 28s)
Iter: 280, Loss 0.001066, Num updates: 280, Wall time: 5207.97, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001067, Num updates: 320, Wall time: 5215.19, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001071, Num updates: 360, Wall time: 5222.17, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001073, Num updates: 400, Wall time: 5228.75, ETA: 1m 10s (- 0m 0s)
Evaluating...
epoch 71, time: 71.98
	train_loss: 0.0011, score: 26.98
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001028, Num updates: 40, Wall time: 5239.02, ETA: 0m 8s (- 1m 22s)
Iter: 80, Loss 0.001044, Num updates: 80, Wall time: 5246.15, ETA: 0m 16s (- 1m 5s)
Iter: 120, Loss 0.001046, Num updates: 120, Wall time: 5253.39, ETA: 0m 23s (- 0m 54s)
Iter: 160, Loss 0.001058, Num updates: 160, Wall time: 5260.68, ETA: 0m 30s (- 0m 46s)
Iter: 200, Loss 0.001062, Num updates: 200, Wall time: 5268.08, ETA: 0m 37s (- 0m 38s)
Iter: 240, Loss 0.001062, Num updates: 240, Wall time: 5274.63, ETA: 0m 44s (- 0m 29s)
Iter: 280, Loss 0.001062, Num updates: 280, Wall time: 5281.57, ETA: 0m 51s (- 0m 22s)
Iter: 320, Loss 0.001061, Num updates: 320, Wall time: 5288.46, ETA: 0m 58s (- 0m 14s)
Iter: 360, Loss 0.001067, Num updates: 360, Wall time: 5295.60, ETA: 1m 5s (- 0m 7s)
Iter: 400, Loss 0.001069, Num updates: 400, Wall time: 5302.20, ETA: 1m 12s (- 0m 0s)
Evaluating...
epoch 72, time: 73.03
	train_loss: 0.0011, score: 27.05
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001042, Num updates: 40, Wall time: 5311.65, ETA: 0m 8s (- 1m 15s)
Iter: 80, Loss 0.001057, Num updates: 80, Wall time: 5318.71, ETA: 0m 15s (- 1m 2s)
Iter: 120, Loss 0.001057, Num updates: 120, Wall time: 5326.14, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001060, Num updates: 160, Wall time: 5333.17, ETA: 0m 29s (- 0m 45s)
Iter: 200, Loss 0.001059, Num updates: 200, Wall time: 5340.14, ETA: 0m 36s (- 0m 37s)
Iter: 240, Loss 0.001065, Num updates: 240, Wall time: 5346.97, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001068, Num updates: 280, Wall time: 5354.07, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001068, Num updates: 320, Wall time: 5360.70, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001070, Num updates: 360, Wall time: 5367.69, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001068, Num updates: 400, Wall time: 5375.07, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 73, time: 72.76
	train_loss: 0.0011, score: 26.97
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001044, Num updates: 40, Wall time: 5385.01, ETA: 0m 8s (- 1m 18s)
Iter: 80, Loss 0.001047, Num updates: 80, Wall time: 5392.17, ETA: 0m 15s (- 1m 3s)
Iter: 120, Loss 0.001054, Num updates: 120, Wall time: 5398.75, ETA: 0m 22s (- 0m 52s)
Iter: 160, Loss 0.001055, Num updates: 160, Wall time: 5405.92, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001058, Num updates: 200, Wall time: 5412.85, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001065, Num updates: 240, Wall time: 5419.25, ETA: 0m 42s (- 0m 28s)
Iter: 280, Loss 0.001064, Num updates: 280, Wall time: 5425.94, ETA: 0m 49s (- 0m 21s)
Iter: 320, Loss 0.001063, Num updates: 320, Wall time: 5432.37, ETA: 0m 55s (- 0m 14s)
Iter: 360, Loss 0.001066, Num updates: 360, Wall time: 5439.47, ETA: 1m 2s (- 0m 7s)
Iter: 400, Loss 0.001066, Num updates: 400, Wall time: 5446.63, ETA: 1m 10s (- 0m 0s)
Evaluating...
epoch 74, time: 71.34
	train_loss: 0.0011, score: 26.92
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001044, Num updates: 40, Wall time: 5456.70, ETA: 0m 8s (- 1m 19s)
Iter: 80, Loss 0.001052, Num updates: 80, Wall time: 5463.47, ETA: 0m 15s (- 1m 2s)
Iter: 120, Loss 0.001050, Num updates: 120, Wall time: 5470.63, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001055, Num updates: 160, Wall time: 5477.59, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001059, Num updates: 200, Wall time: 5484.16, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001062, Num updates: 240, Wall time: 5491.27, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001062, Num updates: 280, Wall time: 5497.91, ETA: 0m 49s (- 0m 21s)
Iter: 320, Loss 0.001061, Num updates: 320, Wall time: 5504.84, ETA: 0m 56s (- 0m 14s)
Iter: 360, Loss 0.001063, Num updates: 360, Wall time: 5511.40, ETA: 1m 3s (- 0m 7s)
Iter: 400, Loss 0.001064, Num updates: 400, Wall time: 5518.54, ETA: 1m 10s (- 0m 0s)
Evaluating...
epoch 75, time: 71.43
	train_loss: 0.0011, score: 26.68
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001018, Num updates: 40, Wall time: 5528.07, ETA: 0m 8s (- 1m 16s)
Iter: 80, Loss 0.001043, Num updates: 80, Wall time: 5535.00, ETA: 0m 15s (- 1m 1s)
Iter: 120, Loss 0.001044, Num updates: 120, Wall time: 5542.00, ETA: 0m 22s (- 0m 52s)
Iter: 160, Loss 0.001050, Num updates: 160, Wall time: 5548.79, ETA: 0m 28s (- 0m 43s)
Iter: 200, Loss 0.001048, Num updates: 200, Wall time: 5556.00, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001052, Num updates: 240, Wall time: 5562.97, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001051, Num updates: 280, Wall time: 5570.17, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001057, Num updates: 320, Wall time: 5577.01, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001060, Num updates: 360, Wall time: 5583.96, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001061, Num updates: 400, Wall time: 5590.98, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 76, time: 72.23
	train_loss: 0.0011, score: 26.98
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001032, Num updates: 40, Wall time: 5600.68, ETA: 0m 8s (- 1m 17s)
Iter: 80, Loss 0.001047, Num updates: 80, Wall time: 5607.81, ETA: 0m 15s (- 1m 2s)
Iter: 120, Loss 0.001050, Num updates: 120, Wall time: 5614.79, ETA: 0m 22s (- 0m 53s)
Iter: 160, Loss 0.001055, Num updates: 160, Wall time: 5621.55, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001052, Num updates: 200, Wall time: 5628.69, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001052, Num updates: 240, Wall time: 5635.64, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001052, Num updates: 280, Wall time: 5642.62, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001053, Num updates: 320, Wall time: 5649.53, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001058, Num updates: 360, Wall time: 5656.53, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001059, Num updates: 400, Wall time: 5663.32, ETA: 1m 10s (- 0m 0s)
Evaluating...
epoch 77, time: 72.25
	train_loss: 0.0011, score: 26.58
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001037, Num updates: 40, Wall time: 5673.25, ETA: 0m 8s (- 1m 14s)
Iter: 80, Loss 0.001038, Num updates: 80, Wall time: 5680.27, ETA: 0m 15s (- 1m 1s)
Iter: 120, Loss 0.001045, Num updates: 120, Wall time: 5687.32, ETA: 0m 22s (- 0m 52s)
Iter: 160, Loss 0.001044, Num updates: 160, Wall time: 5694.31, ETA: 0m 29s (- 0m 44s)
Iter: 200, Loss 0.001045, Num updates: 200, Wall time: 5701.32, ETA: 0m 36s (- 0m 36s)
Iter: 240, Loss 0.001049, Num updates: 240, Wall time: 5708.49, ETA: 0m 43s (- 0m 29s)
Iter: 280, Loss 0.001055, Num updates: 280, Wall time: 5715.23, ETA: 0m 50s (- 0m 21s)
Iter: 320, Loss 0.001054, Num updates: 320, Wall time: 5722.63, ETA: 0m 57s (- 0m 14s)
Iter: 360, Loss 0.001055, Num updates: 360, Wall time: 5729.55, ETA: 1m 4s (- 0m 7s)
Iter: 400, Loss 0.001057, Num updates: 400, Wall time: 5736.51, ETA: 1m 11s (- 0m 0s)
Evaluating...
epoch 78, time: 72.52
	train_loss: 0.0011, score: 27.08
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001020, Num updates: 40, Wall time: 5746.15, ETA: 0m 8s (- 1m 15s)
Iter: 80, Loss 0.001045, Num updates: 80, Wall time: 5752.85, ETA: 0m 14s (- 1m 0s)
Iter: 120, Loss 0.001054, Num updates: 120, Wall time: 5759.46, ETA: 0m 21s (- 0m 50s)
Iter: 160, Loss 0.001056, Num updates: 160, Wall time: 5766.50, ETA: 0m 28s (- 0m 43s)
Iter: 200, Loss 0.001058, Num updates: 200, Wall time: 5773.55, ETA: 0m 35s (- 0m 35s)
Iter: 240, Loss 0.001060, Num updates: 240, Wall time: 5780.20, ETA: 0m 42s (- 0m 28s)
Iter: 280, Loss 0.001057, Num updates: 280, Wall time: 5787.19, ETA: 0m 49s (- 0m 21s)
Iter: 320, Loss 0.001055, Num updates: 320, Wall time: 5794.49, ETA: 0m 56s (- 0m 14s)
Iter: 360, Loss 0.001057, Num updates: 360, Wall time: 5801.37, ETA: 1m 3s (- 0m 7s)
Iter: 400, Loss 0.001056, Num updates: 400, Wall time: 5808.49, ETA: 1m 10s (- 0m 0s)
Evaluating...
epoch 79, time: 71.62
	train_loss: 0.0011, score: 26.08
	eval score: 0.00 (0.00)
0.00404,0.00179,0.00172,0.00167,0.00165,0.00163,0.00161,0.00159,0.00158,0.00156,0.00154,0.00152,0.00151,0.00149,0.00147,0.00146,0.00144,0.00142,0.0014,0.00139,0.00137,0.00136,0.00135,0.00133,0.00132,0.00131,0.0013,0.00129,0.00128,0.00127,0.00126,0.00126,0.00125,0.00124,0.00123,0.00122,0.00122,0.00121,0.0012,0.0012,0.0012,0.00119,0.00118,0.00118,0.00117,0.00117,0.00117,0.00115,0.00115,0.00115,0.00114,0.00114,0.00114,0.00113,0.00113,0.00112,0.00112,0.00112,0.00111,0.00111,0.00111,0.0011,0.0011,0.0011,0.00109,0.00109,0.00109,0.00109,0.00108,0.00108,0.00108,0.00108,0.00107,0.00107,0.00107,0.00107,0.00106,0.00106,0.00106,0.00106
0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
saved_model_Med2019/BAN_MEVF
Namespace(RAD_dir='/home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019', activation='relu', ae_alpha=0.001, ae_model_path='pretrained_ae.pth', alpha=1.0, autoencoder=True, batch_size=32, clip_norm=0.25, dropout=0.5, epochs=100, eps_cnn=1e-05, feat_dim=32, five_fold=False, gamma=2, gpu=0, input=None, lr=0.03, maml=True, maml_model_path='pretrained_maml.weights', model='BAN', momentum_cnn=0.05, num_hid=1024, num_stacks=2, op='c', output='saved_model_Med2019/BAN_MEVF', pow=2, print_interval=40, qc_model_path='./saved_models/QC/rad_best.pth', question_len=12, record_id=1, rescale_factor=1.5, rnn='LSTM', seed=3, tfidf=True, update_freq='1', use_RAD=True, use_ablation=False, use_ablation_q=False, use_ablation_v=False, use_counter=False, use_grad_cam=False, use_kl_mix=False, use_mix=True, use_mix_all=False, use_mix_cond=True, use_mix_cond_q=True, use_mix_cond_v=False, use_mix_cond_vq_in=False, use_mix_cond_vq_union=False, use_partial_label=False, use_rescale=False, use_sep_mix=False)
loading dictionary from /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/dictionary.pkl
loading MAML image data from file: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/images84x84.pkl
loading DAE image data from file: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/images128x128.pkl
loading MAML image data from file: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/images84x84.pkl
loading DAE image data from file: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/images128x128.pkl
load initial weights MAML from: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/pretrained_maml.weights
load initial weights DAE from: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/pretrained_ae.pth
loading dictionary from /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/dictionary.pkl
Loading embedding tfidf and weights from file
Load embedding tfidf and weights from file successfully
Namespace(RAD_dir='/home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019', activation='relu', ae_alpha=0.001, ae_model_path='pretrained_ae.pth', alpha=1.0, autoencoder=True, batch_size=32, clip_norm=0.25, device=device(type='cuda', index=0), dropout=0.5, epochs=100, eps_cnn=1e-05, feat_dim=64, five_fold=False, gamma=2, gpu=0, input=None, lr=0.03, maml=True, maml_model_path='pretrained_maml.weights', model='BAN', momentum_cnn=0.05, num_hid=1024, num_stacks=2, op='c', output='saved_model_Med2019/BAN_MEVF', pow=2, print_interval=40, qc_model_path='./saved_models/QC/rad_best.pth', question_len=12, record_id=1, rescale_factor=1.5, rnn='LSTM', seed=3, tfidf=True, update_freq='1', use_RAD=True, use_ablation=False, use_ablation_q=False, use_ablation_v=False, use_counter=False, use_grad_cam=False, use_kl_mix=False, use_mix=True, use_mix_all=False, use_mix_cond=True, use_mix_cond_q=True, use_mix_cond_v=False, use_mix_cond_vq_in=False, use_mix_cond_vq_union=False, use_partial_label=False, use_rescale=False, use_sep_mix=False)
nParams=	21342541
optim: adamax lr=0.0300, decay_step=3, decay_rate=0.75, grad_clip=0.25
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'language_model.WordEmbedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Iter: 40, Loss 0.021834, Num updates: 40, Wall time: 8.68, ETA: 0m 8s (- 1m 14s)
Iter: 80, Loss 0.012092, Num updates: 80, Wall time: 13.97, ETA: 0m 13s (- 0m 54s)
Iter: 120, Loss 0.008770, Num updates: 120, Wall time: 19.33, ETA: 0m 18s (- 0m 44s)
Iter: 160, Loss 0.007116, Num updates: 160, Wall time: 24.42, ETA: 0m 23s (- 0m 36s)
Iter: 200, Loss 0.006109, Num updates: 200, Wall time: 29.45, ETA: 0m 28s (- 0m 29s)
Iter: 240, Loss 0.005428, Num updates: 240, Wall time: 34.74, ETA: 0m 34s (- 0m 22s)
Iter: 280, Loss 0.004941, Num updates: 280, Wall time: 40.02, ETA: 0m 39s (- 0m 17s)
Iter: 320, Loss 0.004571, Num updates: 320, Wall time: 45.37, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.004274, Num updates: 360, Wall time: 50.79, ETA: 0m 50s (- 0m 5s)
Iter: 400, Loss 0.004034, Num updates: 400, Wall time: 56.54, ETA: 0m 55s (- 0m 0s)
Evaluating...
epoch 0, time: 56.80
	train_loss: 0.0040, score: 14.35
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001794, Num updates: 40, Wall time: 64.28, ETA: 0m 6s (- 1m 0s)
Iter: 80, Loss 0.001808, Num updates: 80, Wall time: 69.27, ETA: 0m 11s (- 0m 46s)
Iter: 120, Loss 0.001797, Num updates: 120, Wall time: 74.78, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001795, Num updates: 160, Wall time: 79.91, ETA: 0m 22s (- 0m 33s)
Iter: 200, Loss 0.001799, Num updates: 200, Wall time: 84.90, ETA: 0m 27s (- 0m 27s)
Iter: 240, Loss 0.001794, Num updates: 240, Wall time: 90.15, ETA: 0m 32s (- 0m 21s)
Iter: 280, Loss 0.001797, Num updates: 280, Wall time: 95.61, ETA: 0m 37s (- 0m 16s)
Iter: 320, Loss 0.001798, Num updates: 320, Wall time: 101.14, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001793, Num updates: 360, Wall time: 106.71, ETA: 0m 48s (- 0m 5s)
Iter: 400, Loss 0.001787, Num updates: 400, Wall time: 112.32, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 1, time: 55.63
	train_loss: 0.0018, score: 20.20
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001689, Num updates: 40, Wall time: 120.00, ETA: 0m 6s (- 0m 58s)
Iter: 80, Loss 0.001715, Num updates: 80, Wall time: 125.57, ETA: 0m 11s (- 0m 48s)
Iter: 120, Loss 0.001732, Num updates: 120, Wall time: 131.47, ETA: 0m 17s (- 0m 42s)
Iter: 160, Loss 0.001723, Num updates: 160, Wall time: 136.91, ETA: 0m 23s (- 0m 35s)
Iter: 200, Loss 0.001713, Num updates: 200, Wall time: 142.56, ETA: 0m 28s (- 0m 29s)
Iter: 240, Loss 0.001711, Num updates: 240, Wall time: 147.98, ETA: 0m 34s (- 0m 23s)
Iter: 280, Loss 0.001713, Num updates: 280, Wall time: 153.52, ETA: 0m 39s (- 0m 17s)
Iter: 320, Loss 0.001714, Num updates: 320, Wall time: 158.77, ETA: 0m 45s (- 0m 11s)
Iter: 360, Loss 0.001715, Num updates: 360, Wall time: 164.17, ETA: 0m 50s (- 0m 5s)
Iter: 400, Loss 0.001714, Num updates: 400, Wall time: 169.40, ETA: 0m 55s (- 0m 0s)
Evaluating...
epoch 2, time: 56.69
	train_loss: 0.0017, score: 21.16
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001614, Num updates: 40, Wall time: 177.22, ETA: 0m 6s (- 1m 1s)
Iter: 80, Loss 0.001646, Num updates: 80, Wall time: 182.63, ETA: 0m 12s (- 0m 48s)
Iter: 120, Loss 0.001646, Num updates: 120, Wall time: 188.01, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001656, Num updates: 160, Wall time: 193.30, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001665, Num updates: 200, Wall time: 199.15, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001667, Num updates: 240, Wall time: 204.54, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001666, Num updates: 280, Wall time: 210.03, ETA: 0m 39s (- 0m 17s)
Iter: 320, Loss 0.001668, Num updates: 320, Wall time: 215.60, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001668, Num updates: 360, Wall time: 220.96, ETA: 0m 50s (- 0m 5s)
Iter: 400, Loss 0.001670, Num updates: 400, Wall time: 226.31, ETA: 0m 55s (- 0m 0s)
Evaluating...
epoch 3, time: 56.71
	train_loss: 0.0017, score: 22.11
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001639, Num updates: 40, Wall time: 234.48, ETA: 0m 6s (- 1m 3s)
Iter: 80, Loss 0.001631, Num updates: 80, Wall time: 240.11, ETA: 0m 12s (- 0m 50s)
Iter: 120, Loss 0.001653, Num updates: 120, Wall time: 245.74, ETA: 0m 18s (- 0m 42s)
Iter: 160, Loss 0.001658, Num updates: 160, Wall time: 251.16, ETA: 0m 23s (- 0m 35s)
Iter: 200, Loss 0.001658, Num updates: 200, Wall time: 256.83, ETA: 0m 29s (- 0m 29s)
Iter: 240, Loss 0.001652, Num updates: 240, Wall time: 262.41, ETA: 0m 34s (- 0m 23s)
Iter: 280, Loss 0.001649, Num updates: 280, Wall time: 267.89, ETA: 0m 40s (- 0m 17s)
Iter: 320, Loss 0.001648, Num updates: 320, Wall time: 273.41, ETA: 0m 45s (- 0m 11s)
Iter: 360, Loss 0.001646, Num updates: 360, Wall time: 278.81, ETA: 0m 51s (- 0m 5s)
Iter: 400, Loss 0.001645, Num updates: 400, Wall time: 284.27, ETA: 0m 56s (- 0m 0s)
Evaluating...
epoch 4, time: 57.59
	train_loss: 0.0016, score: 21.62
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001634, Num updates: 40, Wall time: 292.01, ETA: 0m 6s (- 1m 1s)
Iter: 80, Loss 0.001625, Num updates: 80, Wall time: 297.15, ETA: 0m 11s (- 0m 47s)
Iter: 120, Loss 0.001615, Num updates: 120, Wall time: 302.62, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001617, Num updates: 160, Wall time: 308.13, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001619, Num updates: 200, Wall time: 313.38, ETA: 0m 27s (- 0m 28s)
Iter: 240, Loss 0.001613, Num updates: 240, Wall time: 318.95, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001614, Num updates: 280, Wall time: 324.19, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001617, Num updates: 320, Wall time: 329.56, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001622, Num updates: 360, Wall time: 334.75, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001622, Num updates: 400, Wall time: 340.03, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 5, time: 55.47
	train_loss: 0.0016, score: 22.78
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001521, Num updates: 40, Wall time: 347.93, ETA: 0m 6s (- 1m 2s)
Iter: 80, Loss 0.001582, Num updates: 80, Wall time: 353.19, ETA: 0m 12s (- 0m 48s)
Iter: 120, Loss 0.001607, Num updates: 120, Wall time: 358.55, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001604, Num updates: 160, Wall time: 363.77, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001607, Num updates: 200, Wall time: 369.02, ETA: 0m 27s (- 0m 28s)
Iter: 240, Loss 0.001600, Num updates: 240, Wall time: 374.51, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001606, Num updates: 280, Wall time: 379.92, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001607, Num updates: 320, Wall time: 385.02, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001608, Num updates: 360, Wall time: 390.73, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001604, Num updates: 400, Wall time: 396.12, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 6, time: 56.01
	train_loss: 0.0016, score: 23.29
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001553, Num updates: 40, Wall time: 403.83, ETA: 0m 6s (- 0m 59s)
Iter: 80, Loss 0.001577, Num updates: 80, Wall time: 409.08, ETA: 0m 11s (- 0m 47s)
Iter: 120, Loss 0.001587, Num updates: 120, Wall time: 414.70, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001587, Num updates: 160, Wall time: 420.13, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001585, Num updates: 200, Wall time: 425.55, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001587, Num updates: 240, Wall time: 430.98, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001584, Num updates: 280, Wall time: 436.35, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001590, Num updates: 320, Wall time: 441.57, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001589, Num updates: 360, Wall time: 446.96, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001588, Num updates: 400, Wall time: 452.27, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 7, time: 55.94
	train_loss: 0.0016, score: 23.62
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001523, Num updates: 40, Wall time: 460.27, ETA: 0m 6s (- 1m 1s)
Iter: 80, Loss 0.001555, Num updates: 80, Wall time: 465.56, ETA: 0m 11s (- 0m 48s)
Iter: 120, Loss 0.001563, Num updates: 120, Wall time: 470.70, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001565, Num updates: 160, Wall time: 476.18, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001569, Num updates: 200, Wall time: 481.47, ETA: 0m 27s (- 0m 28s)
Iter: 240, Loss 0.001573, Num updates: 240, Wall time: 487.05, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001572, Num updates: 280, Wall time: 492.58, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001572, Num updates: 320, Wall time: 498.21, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001573, Num updates: 360, Wall time: 503.48, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001571, Num updates: 400, Wall time: 508.77, ETA: 0m 55s (- 0m 0s)
Evaluating...
epoch 8, time: 56.09
	train_loss: 0.0016, score: 23.67
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001488, Num updates: 40, Wall time: 517.17, ETA: 0m 7s (- 1m 6s)
Iter: 80, Loss 0.001509, Num updates: 80, Wall time: 522.50, ETA: 0m 12s (- 0m 50s)
Iter: 120, Loss 0.001522, Num updates: 120, Wall time: 528.07, ETA: 0m 18s (- 0m 42s)
Iter: 160, Loss 0.001539, Num updates: 160, Wall time: 533.51, ETA: 0m 23s (- 0m 35s)
Iter: 200, Loss 0.001547, Num updates: 200, Wall time: 539.02, ETA: 0m 29s (- 0m 29s)
Iter: 240, Loss 0.001551, Num updates: 240, Wall time: 544.29, ETA: 0m 34s (- 0m 23s)
Iter: 280, Loss 0.001558, Num updates: 280, Wall time: 549.71, ETA: 0m 39s (- 0m 17s)
Iter: 320, Loss 0.001558, Num updates: 320, Wall time: 554.89, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001559, Num updates: 360, Wall time: 560.59, ETA: 0m 50s (- 0m 5s)
Iter: 400, Loss 0.001555, Num updates: 400, Wall time: 565.73, ETA: 0m 55s (- 0m 0s)
Evaluating...
epoch 9, time: 56.67
	train_loss: 0.0016, score: 23.77
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001476, Num updates: 40, Wall time: 572.66, ETA: 0m 5s (- 0m 53s)
Iter: 80, Loss 0.001513, Num updates: 80, Wall time: 577.97, ETA: 0m 11s (- 0m 45s)
Iter: 120, Loss 0.001517, Num updates: 120, Wall time: 582.68, ETA: 0m 15s (- 0m 37s)
Iter: 160, Loss 0.001524, Num updates: 160, Wall time: 587.96, ETA: 0m 21s (- 0m 31s)
Iter: 200, Loss 0.001538, Num updates: 200, Wall time: 593.34, ETA: 0m 26s (- 0m 26s)
Iter: 240, Loss 0.001534, Num updates: 240, Wall time: 598.66, ETA: 0m 31s (- 0m 21s)
Iter: 280, Loss 0.001536, Num updates: 280, Wall time: 604.05, ETA: 0m 37s (- 0m 16s)
Iter: 320, Loss 0.001538, Num updates: 320, Wall time: 609.57, ETA: 0m 42s (- 0m 10s)
Iter: 360, Loss 0.001534, Num updates: 360, Wall time: 614.06, ETA: 0m 47s (- 0m 5s)
Iter: 400, Loss 0.001538, Num updates: 400, Wall time: 619.45, ETA: 0m 52s (- 0m 0s)
Evaluating...
epoch 10, time: 53.61
	train_loss: 0.0015, score: 23.93
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001507, Num updates: 40, Wall time: 627.30, ETA: 0m 6s (- 1m 0s)
Iter: 80, Loss 0.001524, Num updates: 80, Wall time: 632.78, ETA: 0m 12s (- 0m 48s)
Iter: 120, Loss 0.001530, Num updates: 120, Wall time: 637.80, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001520, Num updates: 160, Wall time: 643.49, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001516, Num updates: 200, Wall time: 649.06, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001520, Num updates: 240, Wall time: 654.47, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001522, Num updates: 280, Wall time: 659.82, ETA: 0m 39s (- 0m 16s)
Iter: 320, Loss 0.001516, Num updates: 320, Wall time: 665.18, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001518, Num updates: 360, Wall time: 670.48, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001521, Num updates: 400, Wall time: 675.73, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 11, time: 56.00
	train_loss: 0.0015, score: 23.59
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001476, Num updates: 40, Wall time: 683.12, ETA: 0m 6s (- 0m 56s)
Iter: 80, Loss 0.001487, Num updates: 80, Wall time: 688.35, ETA: 0m 11s (- 0m 46s)
Iter: 120, Loss 0.001488, Num updates: 120, Wall time: 693.86, ETA: 0m 16s (- 0m 39s)
Iter: 160, Loss 0.001483, Num updates: 160, Wall time: 699.36, ETA: 0m 22s (- 0m 33s)
Iter: 200, Loss 0.001491, Num updates: 200, Wall time: 704.73, ETA: 0m 27s (- 0m 28s)
Iter: 240, Loss 0.001493, Num updates: 240, Wall time: 709.67, ETA: 0m 32s (- 0m 22s)
Iter: 280, Loss 0.001499, Num updates: 280, Wall time: 715.10, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001501, Num updates: 320, Wall time: 720.74, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001503, Num updates: 360, Wall time: 726.40, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001506, Num updates: 400, Wall time: 731.34, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 12, time: 55.15
	train_loss: 0.0015, score: 24.37
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001432, Num updates: 40, Wall time: 738.79, ETA: 0m 6s (- 0m 59s)
Iter: 80, Loss 0.001444, Num updates: 80, Wall time: 744.07, ETA: 0m 11s (- 0m 47s)
Iter: 120, Loss 0.001461, Num updates: 120, Wall time: 749.15, ETA: 0m 16s (- 0m 39s)
Iter: 160, Loss 0.001469, Num updates: 160, Wall time: 754.20, ETA: 0m 21s (- 0m 33s)
Iter: 200, Loss 0.001479, Num updates: 200, Wall time: 759.50, ETA: 0m 27s (- 0m 27s)
Iter: 240, Loss 0.001479, Num updates: 240, Wall time: 764.61, ETA: 0m 32s (- 0m 21s)
Iter: 280, Loss 0.001480, Num updates: 280, Wall time: 769.82, ETA: 0m 37s (- 0m 16s)
Iter: 320, Loss 0.001483, Num updates: 320, Wall time: 775.43, ETA: 0m 43s (- 0m 10s)
Iter: 360, Loss 0.001483, Num updates: 360, Wall time: 780.66, ETA: 0m 48s (- 0m 5s)
Iter: 400, Loss 0.001489, Num updates: 400, Wall time: 786.18, ETA: 0m 53s (- 0m 0s)
Evaluating...
epoch 13, time: 54.78
	train_loss: 0.0015, score: 24.43
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001466, Num updates: 40, Wall time: 794.45, ETA: 0m 6s (- 1m 4s)
Iter: 80, Loss 0.001450, Num updates: 80, Wall time: 800.03, ETA: 0m 12s (- 0m 51s)
Iter: 120, Loss 0.001449, Num updates: 120, Wall time: 805.73, ETA: 0m 18s (- 0m 43s)
Iter: 160, Loss 0.001450, Num updates: 160, Wall time: 811.00, ETA: 0m 23s (- 0m 35s)
Iter: 200, Loss 0.001455, Num updates: 200, Wall time: 816.53, ETA: 0m 29s (- 0m 29s)
Iter: 240, Loss 0.001457, Num updates: 240, Wall time: 821.97, ETA: 0m 34s (- 0m 23s)
Iter: 280, Loss 0.001467, Num updates: 280, Wall time: 827.27, ETA: 0m 39s (- 0m 17s)
Iter: 320, Loss 0.001464, Num updates: 320, Wall time: 832.50, ETA: 0m 45s (- 0m 11s)
Iter: 360, Loss 0.001469, Num updates: 360, Wall time: 837.62, ETA: 0m 50s (- 0m 5s)
Iter: 400, Loss 0.001468, Num updates: 400, Wall time: 842.72, ETA: 0m 55s (- 0m 0s)
Evaluating...
epoch 14, time: 56.27
	train_loss: 0.0015, score: 25.27
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001476, Num updates: 40, Wall time: 850.44, ETA: 0m 6s (- 0m 59s)
Iter: 80, Loss 0.001456, Num updates: 80, Wall time: 855.42, ETA: 0m 11s (- 0m 46s)
Iter: 120, Loss 0.001454, Num updates: 120, Wall time: 860.54, ETA: 0m 16s (- 0m 39s)
Iter: 160, Loss 0.001456, Num updates: 160, Wall time: 865.56, ETA: 0m 21s (- 0m 32s)
Iter: 200, Loss 0.001459, Num updates: 200, Wall time: 870.54, ETA: 0m 26s (- 0m 26s)
Iter: 240, Loss 0.001463, Num updates: 240, Wall time: 875.86, ETA: 0m 31s (- 0m 21s)
Iter: 280, Loss 0.001463, Num updates: 280, Wall time: 881.53, ETA: 0m 37s (- 0m 16s)
Iter: 320, Loss 0.001458, Num updates: 320, Wall time: 886.99, ETA: 0m 42s (- 0m 10s)
Iter: 360, Loss 0.001455, Num updates: 360, Wall time: 892.55, ETA: 0m 48s (- 0m 5s)
Iter: 400, Loss 0.001453, Num updates: 400, Wall time: 898.15, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 15, time: 55.18
	train_loss: 0.0015, score: 24.73
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001388, Num updates: 40, Wall time: 905.87, ETA: 0m 6s (- 0m 59s)
Iter: 80, Loss 0.001408, Num updates: 80, Wall time: 911.20, ETA: 0m 11s (- 0m 47s)
Iter: 120, Loss 0.001412, Num updates: 120, Wall time: 916.80, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001421, Num updates: 160, Wall time: 921.92, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001427, Num updates: 200, Wall time: 927.53, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001429, Num updates: 240, Wall time: 933.11, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001431, Num updates: 280, Wall time: 938.65, ETA: 0m 39s (- 0m 17s)
Iter: 320, Loss 0.001435, Num updates: 320, Wall time: 944.15, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001438, Num updates: 360, Wall time: 949.02, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001436, Num updates: 400, Wall time: 953.82, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 16, time: 55.44
	train_loss: 0.0014, score: 24.63
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001358, Num updates: 40, Wall time: 961.86, ETA: 0m 6s (- 1m 2s)
Iter: 80, Loss 0.001384, Num updates: 80, Wall time: 967.16, ETA: 0m 12s (- 0m 48s)
Iter: 120, Loss 0.001397, Num updates: 120, Wall time: 972.40, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001406, Num updates: 160, Wall time: 978.01, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001405, Num updates: 200, Wall time: 983.47, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001410, Num updates: 240, Wall time: 988.75, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001407, Num updates: 280, Wall time: 994.12, ETA: 0m 39s (- 0m 16s)
Iter: 320, Loss 0.001410, Num updates: 320, Wall time: 999.65, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001414, Num updates: 360, Wall time: 1005.01, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001416, Num updates: 400, Wall time: 1009.86, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 17, time: 55.80
	train_loss: 0.0014, score: 25.58
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001381, Num updates: 40, Wall time: 1017.70, ETA: 0m 6s (- 1m 0s)
Iter: 80, Loss 0.001383, Num updates: 80, Wall time: 1022.93, ETA: 0m 11s (- 0m 47s)
Iter: 120, Loss 0.001390, Num updates: 120, Wall time: 1028.15, ETA: 0m 16s (- 0m 40s)
Iter: 160, Loss 0.001394, Num updates: 160, Wall time: 1033.37, ETA: 0m 22s (- 0m 33s)
Iter: 200, Loss 0.001396, Num updates: 200, Wall time: 1038.64, ETA: 0m 27s (- 0m 27s)
Iter: 240, Loss 0.001396, Num updates: 240, Wall time: 1043.81, ETA: 0m 32s (- 0m 21s)
Iter: 280, Loss 0.001400, Num updates: 280, Wall time: 1048.88, ETA: 0m 37s (- 0m 16s)
Iter: 320, Loss 0.001398, Num updates: 320, Wall time: 1053.91, ETA: 0m 42s (- 0m 10s)
Iter: 360, Loss 0.001402, Num updates: 360, Wall time: 1059.02, ETA: 0m 47s (- 0m 5s)
Iter: 400, Loss 0.001403, Num updates: 400, Wall time: 1064.04, ETA: 0m 52s (- 0m 0s)
Evaluating...
epoch 18, time: 53.64
	train_loss: 0.0014, score: 25.40
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001343, Num updates: 40, Wall time: 1071.67, ETA: 0m 6s (- 1m 1s)
Iter: 80, Loss 0.001360, Num updates: 80, Wall time: 1077.25, ETA: 0m 12s (- 0m 49s)
Iter: 120, Loss 0.001372, Num updates: 120, Wall time: 1082.69, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001378, Num updates: 160, Wall time: 1088.17, ETA: 0m 23s (- 0m 35s)
Iter: 200, Loss 0.001378, Num updates: 200, Wall time: 1093.14, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001381, Num updates: 240, Wall time: 1098.52, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001386, Num updates: 280, Wall time: 1103.90, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001388, Num updates: 320, Wall time: 1109.06, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001390, Num updates: 360, Wall time: 1114.47, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001388, Num updates: 400, Wall time: 1119.49, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 19, time: 55.42
	train_loss: 0.0014, score: 25.39
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001321, Num updates: 40, Wall time: 1127.23, ETA: 0m 6s (- 1m 0s)
Iter: 80, Loss 0.001349, Num updates: 80, Wall time: 1132.71, ETA: 0m 12s (- 0m 48s)
Iter: 120, Loss 0.001362, Num updates: 120, Wall time: 1137.98, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001364, Num updates: 160, Wall time: 1143.51, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001363, Num updates: 200, Wall time: 1148.71, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001367, Num updates: 240, Wall time: 1153.90, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001368, Num updates: 280, Wall time: 1159.35, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001369, Num updates: 320, Wall time: 1164.63, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001372, Num updates: 360, Wall time: 1170.03, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001372, Num updates: 400, Wall time: 1175.47, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 20, time: 55.62
	train_loss: 0.0014, score: 25.80
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001342, Num updates: 40, Wall time: 1182.62, ETA: 0m 6s (- 0m 55s)
Iter: 80, Loss 0.001342, Num updates: 80, Wall time: 1187.84, ETA: 0m 11s (- 0m 45s)
Iter: 120, Loss 0.001341, Num updates: 120, Wall time: 1193.12, ETA: 0m 16s (- 0m 39s)
Iter: 160, Loss 0.001343, Num updates: 160, Wall time: 1198.58, ETA: 0m 21s (- 0m 33s)
Iter: 200, Loss 0.001341, Num updates: 200, Wall time: 1203.74, ETA: 0m 27s (- 0m 27s)
Iter: 240, Loss 0.001351, Num updates: 240, Wall time: 1208.84, ETA: 0m 32s (- 0m 21s)
Iter: 280, Loss 0.001357, Num updates: 280, Wall time: 1214.29, ETA: 0m 37s (- 0m 16s)
Iter: 320, Loss 0.001354, Num updates: 320, Wall time: 1219.27, ETA: 0m 42s (- 0m 10s)
Iter: 360, Loss 0.001356, Num updates: 360, Wall time: 1224.41, ETA: 0m 47s (- 0m 5s)
Iter: 400, Loss 0.001358, Num updates: 400, Wall time: 1229.54, ETA: 0m 52s (- 0m 0s)
Evaluating...
epoch 21, time: 53.85
	train_loss: 0.0014, score: 26.00
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001301, Num updates: 40, Wall time: 1237.16, ETA: 0m 6s (- 0m 59s)
Iter: 80, Loss 0.001325, Num updates: 80, Wall time: 1242.58, ETA: 0m 11s (- 0m 48s)
Iter: 120, Loss 0.001335, Num updates: 120, Wall time: 1247.97, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001334, Num updates: 160, Wall time: 1253.39, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001338, Num updates: 200, Wall time: 1258.72, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001343, Num updates: 240, Wall time: 1264.20, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001346, Num updates: 280, Wall time: 1269.33, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001342, Num updates: 320, Wall time: 1274.67, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001343, Num updates: 360, Wall time: 1279.93, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001346, Num updates: 400, Wall time: 1285.16, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 22, time: 55.51
	train_loss: 0.0013, score: 26.68
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001297, Num updates: 40, Wall time: 1292.78, ETA: 0m 6s (- 0m 58s)
Iter: 80, Loss 0.001316, Num updates: 80, Wall time: 1298.06, ETA: 0m 11s (- 0m 47s)
Iter: 120, Loss 0.001318, Num updates: 120, Wall time: 1303.34, ETA: 0m 16s (- 0m 39s)
Iter: 160, Loss 0.001317, Num updates: 160, Wall time: 1308.68, ETA: 0m 22s (- 0m 33s)
Iter: 200, Loss 0.001321, Num updates: 200, Wall time: 1314.20, ETA: 0m 27s (- 0m 28s)
Iter: 240, Loss 0.001321, Num updates: 240, Wall time: 1319.49, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001324, Num updates: 280, Wall time: 1324.78, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001329, Num updates: 320, Wall time: 1330.52, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001330, Num updates: 360, Wall time: 1335.97, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001331, Num updates: 400, Wall time: 1341.23, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 23, time: 55.69
	train_loss: 0.0013, score: 26.29
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001247, Num updates: 40, Wall time: 1349.33, ETA: 0m 6s (- 1m 3s)
Iter: 80, Loss 0.001293, Num updates: 80, Wall time: 1354.66, ETA: 0m 12s (- 0m 49s)
Iter: 120, Loss 0.001299, Num updates: 120, Wall time: 1359.95, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001309, Num updates: 160, Wall time: 1365.10, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001308, Num updates: 200, Wall time: 1370.68, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001313, Num updates: 240, Wall time: 1376.04, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001317, Num updates: 280, Wall time: 1381.28, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001319, Num updates: 320, Wall time: 1386.92, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001323, Num updates: 360, Wall time: 1392.27, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001322, Num updates: 400, Wall time: 1397.75, ETA: 0m 55s (- 0m 0s)
Evaluating...
epoch 24, time: 56.26
	train_loss: 0.0013, score: 27.05
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001242, Num updates: 40, Wall time: 1405.83, ETA: 0m 6s (- 1m 3s)
Iter: 80, Loss 0.001278, Num updates: 80, Wall time: 1411.01, ETA: 0m 12s (- 0m 48s)
Iter: 120, Loss 0.001280, Num updates: 120, Wall time: 1416.10, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001293, Num updates: 160, Wall time: 1421.54, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001298, Num updates: 200, Wall time: 1426.67, ETA: 0m 27s (- 0m 27s)
Iter: 240, Loss 0.001297, Num updates: 240, Wall time: 1431.98, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001300, Num updates: 280, Wall time: 1436.80, ETA: 0m 37s (- 0m 16s)
Iter: 320, Loss 0.001301, Num updates: 320, Wall time: 1442.13, ETA: 0m 43s (- 0m 10s)
Iter: 360, Loss 0.001305, Num updates: 360, Wall time: 1447.42, ETA: 0m 48s (- 0m 5s)
Iter: 400, Loss 0.001310, Num updates: 400, Wall time: 1452.43, ETA: 0m 53s (- 0m 0s)
Evaluating...
epoch 25, time: 54.43
	train_loss: 0.0013, score: 26.59
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001263, Num updates: 40, Wall time: 1460.24, ETA: 0m 6s (- 1m 0s)
Iter: 80, Loss 0.001290, Num updates: 80, Wall time: 1465.45, ETA: 0m 11s (- 0m 47s)
Iter: 120, Loss 0.001295, Num updates: 120, Wall time: 1470.84, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001288, Num updates: 160, Wall time: 1476.29, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001292, Num updates: 200, Wall time: 1481.54, ETA: 0m 27s (- 0m 28s)
Iter: 240, Loss 0.001293, Num updates: 240, Wall time: 1487.11, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001295, Num updates: 280, Wall time: 1492.20, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001293, Num updates: 320, Wall time: 1497.73, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001295, Num updates: 360, Wall time: 1503.09, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001297, Num updates: 400, Wall time: 1508.50, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 26, time: 55.84
	train_loss: 0.0013, score: 27.14
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001227, Num updates: 40, Wall time: 1516.64, ETA: 0m 6s (- 1m 3s)
Iter: 80, Loss 0.001254, Num updates: 80, Wall time: 1521.78, ETA: 0m 12s (- 0m 48s)
Iter: 120, Loss 0.001255, Num updates: 120, Wall time: 1526.96, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001262, Num updates: 160, Wall time: 1532.49, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001268, Num updates: 200, Wall time: 1537.68, ETA: 0m 27s (- 0m 28s)
Iter: 240, Loss 0.001278, Num updates: 240, Wall time: 1542.86, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001284, Num updates: 280, Wall time: 1548.44, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001287, Num updates: 320, Wall time: 1553.74, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001286, Num updates: 360, Wall time: 1558.97, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001288, Num updates: 400, Wall time: 1564.51, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 27, time: 55.69
	train_loss: 0.0013, score: 26.84
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001223, Num updates: 40, Wall time: 1572.23, ETA: 0m 6s (- 1m 0s)
Iter: 80, Loss 0.001225, Num updates: 80, Wall time: 1577.73, ETA: 0m 12s (- 0m 48s)
Iter: 120, Loss 0.001242, Num updates: 120, Wall time: 1583.24, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001248, Num updates: 160, Wall time: 1588.54, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001262, Num updates: 200, Wall time: 1593.76, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001267, Num updates: 240, Wall time: 1599.22, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001266, Num updates: 280, Wall time: 1604.32, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001272, Num updates: 320, Wall time: 1609.83, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001275, Num updates: 360, Wall time: 1615.20, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001278, Num updates: 400, Wall time: 1620.56, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 28, time: 55.82
	train_loss: 0.0013, score: 27.40
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001227, Num updates: 40, Wall time: 1628.62, ETA: 0m 6s (- 1m 3s)
Iter: 80, Loss 0.001236, Num updates: 80, Wall time: 1634.13, ETA: 0m 12s (- 0m 50s)
Iter: 120, Loss 0.001245, Num updates: 120, Wall time: 1639.51, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001256, Num updates: 160, Wall time: 1644.76, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001252, Num updates: 200, Wall time: 1650.18, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001253, Num updates: 240, Wall time: 1655.57, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001258, Num updates: 280, Wall time: 1660.82, ETA: 0m 39s (- 0m 16s)
Iter: 320, Loss 0.001258, Num updates: 320, Wall time: 1665.71, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001263, Num updates: 360, Wall time: 1670.98, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001267, Num updates: 400, Wall time: 1675.86, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 29, time: 55.05
	train_loss: 0.0013, score: 27.44
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001203, Num updates: 40, Wall time: 1683.34, ETA: 0m 6s (- 0m 58s)
Iter: 80, Loss 0.001217, Num updates: 80, Wall time: 1688.79, ETA: 0m 11s (- 0m 47s)
Iter: 120, Loss 0.001231, Num updates: 120, Wall time: 1694.07, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001235, Num updates: 160, Wall time: 1699.39, ETA: 0m 22s (- 0m 33s)
Iter: 200, Loss 0.001241, Num updates: 200, Wall time: 1704.38, ETA: 0m 27s (- 0m 27s)
Iter: 240, Loss 0.001252, Num updates: 240, Wall time: 1709.62, ETA: 0m 32s (- 0m 21s)
Iter: 280, Loss 0.001252, Num updates: 280, Wall time: 1714.92, ETA: 0m 37s (- 0m 16s)
Iter: 320, Loss 0.001255, Num updates: 320, Wall time: 1720.39, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001256, Num updates: 360, Wall time: 1725.78, ETA: 0m 48s (- 0m 5s)
Iter: 400, Loss 0.001261, Num updates: 400, Wall time: 1730.92, ETA: 0m 53s (- 0m 0s)
Evaluating...
epoch 30, time: 54.91
	train_loss: 0.0013, score: 26.93
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001217, Num updates: 40, Wall time: 1738.50, ETA: 0m 6s (- 0m 58s)
Iter: 80, Loss 0.001235, Num updates: 80, Wall time: 1743.78, ETA: 0m 11s (- 0m 46s)
Iter: 120, Loss 0.001237, Num updates: 120, Wall time: 1749.26, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001248, Num updates: 160, Wall time: 1754.77, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001256, Num updates: 200, Wall time: 1760.31, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001258, Num updates: 240, Wall time: 1765.60, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001252, Num updates: 280, Wall time: 1770.88, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001253, Num updates: 320, Wall time: 1775.97, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001251, Num updates: 360, Wall time: 1781.05, ETA: 0m 48s (- 0m 5s)
Iter: 400, Loss 0.001253, Num updates: 400, Wall time: 1786.06, ETA: 0m 53s (- 0m 0s)
Evaluating...
epoch 31, time: 54.66
	train_loss: 0.0013, score: 27.78
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001203, Num updates: 40, Wall time: 1793.77, ETA: 0m 6s (- 1m 1s)
Iter: 80, Loss 0.001219, Num updates: 80, Wall time: 1799.06, ETA: 0m 11s (- 0m 48s)
Iter: 120, Loss 0.001226, Num updates: 120, Wall time: 1804.45, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001229, Num updates: 160, Wall time: 1809.87, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001231, Num updates: 200, Wall time: 1815.29, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001242, Num updates: 240, Wall time: 1820.62, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001242, Num updates: 280, Wall time: 1825.93, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001243, Num updates: 320, Wall time: 1831.23, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001243, Num updates: 360, Wall time: 1836.76, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001245, Num updates: 400, Wall time: 1842.09, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 32, time: 55.93
	train_loss: 0.0012, score: 27.76
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001204, Num updates: 40, Wall time: 1849.68, ETA: 0m 6s (- 0m 58s)
Iter: 80, Loss 0.001213, Num updates: 80, Wall time: 1855.07, ETA: 0m 11s (- 0m 47s)
Iter: 120, Loss 0.001216, Num updates: 120, Wall time: 1860.40, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001217, Num updates: 160, Wall time: 1865.67, ETA: 0m 22s (- 0m 33s)
Iter: 200, Loss 0.001225, Num updates: 200, Wall time: 1870.73, ETA: 0m 27s (- 0m 27s)
Iter: 240, Loss 0.001229, Num updates: 240, Wall time: 1876.03, ETA: 0m 32s (- 0m 22s)
Iter: 280, Loss 0.001233, Num updates: 280, Wall time: 1881.18, ETA: 0m 37s (- 0m 16s)
Iter: 320, Loss 0.001234, Num updates: 320, Wall time: 1886.79, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001235, Num updates: 360, Wall time: 1891.62, ETA: 0m 48s (- 0m 5s)
Iter: 400, Loss 0.001238, Num updates: 400, Wall time: 1896.80, ETA: 0m 53s (- 0m 0s)
Evaluating...
epoch 33, time: 54.33
	train_loss: 0.0012, score: 27.42
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001214, Num updates: 40, Wall time: 1904.81, ETA: 0m 6s (- 1m 3s)
Iter: 80, Loss 0.001213, Num updates: 80, Wall time: 1910.15, ETA: 0m 12s (- 0m 49s)
Iter: 120, Loss 0.001209, Num updates: 120, Wall time: 1915.29, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001208, Num updates: 160, Wall time: 1920.39, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001211, Num updates: 200, Wall time: 1925.44, ETA: 0m 27s (- 0m 27s)
Iter: 240, Loss 0.001212, Num updates: 240, Wall time: 1930.52, ETA: 0m 32s (- 0m 21s)
Iter: 280, Loss 0.001219, Num updates: 280, Wall time: 1936.10, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001219, Num updates: 320, Wall time: 1941.56, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001224, Num updates: 360, Wall time: 1946.82, ETA: 0m 48s (- 0m 5s)
Iter: 400, Loss 0.001227, Num updates: 400, Wall time: 1952.22, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 34, time: 55.31
	train_loss: 0.0012, score: 27.51
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001156, Num updates: 40, Wall time: 1959.82, ETA: 0m 6s (- 0m 58s)
Iter: 80, Loss 0.001185, Num updates: 80, Wall time: 1965.00, ETA: 0m 11s (- 0m 46s)
Iter: 120, Loss 0.001200, Num updates: 120, Wall time: 1970.17, ETA: 0m 16s (- 0m 39s)
Iter: 160, Loss 0.001207, Num updates: 160, Wall time: 1975.70, ETA: 0m 22s (- 0m 33s)
Iter: 200, Loss 0.001208, Num updates: 200, Wall time: 1981.04, ETA: 0m 27s (- 0m 27s)
Iter: 240, Loss 0.001211, Num updates: 240, Wall time: 1986.50, ETA: 0m 32s (- 0m 22s)
Iter: 280, Loss 0.001211, Num updates: 280, Wall time: 1991.92, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001217, Num updates: 320, Wall time: 1997.43, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001220, Num updates: 360, Wall time: 2002.96, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001221, Num updates: 400, Wall time: 2008.33, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 35, time: 55.89
	train_loss: 0.0012, score: 27.77
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001165, Num updates: 40, Wall time: 2015.57, ETA: 0m 5s (- 0m 54s)
Iter: 80, Loss 0.001188, Num updates: 80, Wall time: 2021.34, ETA: 0m 11s (- 0m 47s)
Iter: 120, Loss 0.001207, Num updates: 120, Wall time: 2026.83, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001208, Num updates: 160, Wall time: 2032.13, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001211, Num updates: 200, Wall time: 2037.11, ETA: 0m 27s (- 0m 27s)
Iter: 240, Loss 0.001216, Num updates: 240, Wall time: 2042.30, ETA: 0m 32s (- 0m 21s)
Iter: 280, Loss 0.001218, Num updates: 280, Wall time: 2047.63, ETA: 0m 37s (- 0m 16s)
Iter: 320, Loss 0.001218, Num updates: 320, Wall time: 2053.21, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001215, Num updates: 360, Wall time: 2058.71, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001217, Num updates: 400, Wall time: 2064.21, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 36, time: 55.56
	train_loss: 0.0012, score: 27.68
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001162, Num updates: 40, Wall time: 2071.98, ETA: 0m 6s (- 1m 0s)
Iter: 80, Loss 0.001191, Num updates: 80, Wall time: 2077.35, ETA: 0m 11s (- 0m 48s)
Iter: 120, Loss 0.001193, Num updates: 120, Wall time: 2082.99, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001196, Num updates: 160, Wall time: 2087.84, ETA: 0m 22s (- 0m 33s)
Iter: 200, Loss 0.001204, Num updates: 200, Wall time: 2092.95, ETA: 0m 27s (- 0m 27s)
Iter: 240, Loss 0.001205, Num updates: 240, Wall time: 2098.22, ETA: 0m 32s (- 0m 22s)
Iter: 280, Loss 0.001210, Num updates: 280, Wall time: 2103.34, ETA: 0m 37s (- 0m 16s)
Iter: 320, Loss 0.001208, Num updates: 320, Wall time: 2108.64, ETA: 0m 43s (- 0m 10s)
Iter: 360, Loss 0.001212, Num updates: 360, Wall time: 2114.15, ETA: 0m 48s (- 0m 5s)
Iter: 400, Loss 0.001213, Num updates: 400, Wall time: 2119.45, ETA: 0m 53s (- 0m 0s)
Evaluating...
epoch 37, time: 54.93
	train_loss: 0.0012, score: 27.48
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001154, Num updates: 40, Wall time: 2127.36, ETA: 0m 6s (- 1m 2s)
Iter: 80, Loss 0.001175, Num updates: 80, Wall time: 2132.88, ETA: 0m 12s (- 0m 49s)
Iter: 120, Loss 0.001183, Num updates: 120, Wall time: 2138.44, ETA: 0m 17s (- 0m 42s)
Iter: 160, Loss 0.001185, Num updates: 160, Wall time: 2143.64, ETA: 0m 23s (- 0m 34s)
Iter: 200, Loss 0.001192, Num updates: 200, Wall time: 2148.93, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001193, Num updates: 240, Wall time: 2154.23, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001197, Num updates: 280, Wall time: 2159.50, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001197, Num updates: 320, Wall time: 2165.03, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001198, Num updates: 360, Wall time: 2170.51, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001200, Num updates: 400, Wall time: 2175.99, ETA: 0m 55s (- 0m 0s)
Evaluating...
epoch 38, time: 56.39
	train_loss: 0.0012, score: 27.76
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001184, Num updates: 40, Wall time: 2183.84, ETA: 0m 6s (- 1m 0s)
Iter: 80, Loss 0.001179, Num updates: 80, Wall time: 2189.30, ETA: 0m 12s (- 0m 48s)
Iter: 120, Loss 0.001181, Num updates: 120, Wall time: 2194.53, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001184, Num updates: 160, Wall time: 2199.68, ETA: 0m 22s (- 0m 33s)
Iter: 200, Loss 0.001184, Num updates: 200, Wall time: 2205.29, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001189, Num updates: 240, Wall time: 2210.70, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001194, Num updates: 280, Wall time: 2215.92, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001195, Num updates: 320, Wall time: 2221.33, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001197, Num updates: 360, Wall time: 2226.72, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001197, Num updates: 400, Wall time: 2232.16, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 39, time: 55.89
	train_loss: 0.0012, score: 27.16
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001146, Num updates: 40, Wall time: 2240.27, ETA: 0m 6s (- 1m 3s)
Iter: 80, Loss 0.001171, Num updates: 80, Wall time: 2245.39, ETA: 0m 11s (- 0m 48s)
Iter: 120, Loss 0.001186, Num updates: 120, Wall time: 2250.54, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001181, Num updates: 160, Wall time: 2255.16, ETA: 0m 21s (- 0m 32s)
Iter: 200, Loss 0.001181, Num updates: 200, Wall time: 2260.30, ETA: 0m 26s (- 0m 27s)
Iter: 240, Loss 0.001183, Num updates: 240, Wall time: 2265.40, ETA: 0m 31s (- 0m 21s)
Iter: 280, Loss 0.001186, Num updates: 280, Wall time: 2271.08, ETA: 0m 37s (- 0m 16s)
Iter: 320, Loss 0.001189, Num updates: 320, Wall time: 2276.37, ETA: 0m 42s (- 0m 10s)
Iter: 360, Loss 0.001192, Num updates: 360, Wall time: 2281.74, ETA: 0m 48s (- 0m 5s)
Iter: 400, Loss 0.001193, Num updates: 400, Wall time: 2287.05, ETA: 0m 53s (- 0m 0s)
Evaluating...
epoch 40, time: 54.66
	train_loss: 0.0012, score: 27.56
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001140, Num updates: 40, Wall time: 2294.90, ETA: 0m 6s (- 1m 0s)
Iter: 80, Loss 0.001172, Num updates: 80, Wall time: 2300.40, ETA: 0m 12s (- 0m 49s)
Iter: 120, Loss 0.001173, Num updates: 120, Wall time: 2305.72, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001185, Num updates: 160, Wall time: 2310.99, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001187, Num updates: 200, Wall time: 2316.13, ETA: 0m 27s (- 0m 28s)
Iter: 240, Loss 0.001188, Num updates: 240, Wall time: 2321.55, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001188, Num updates: 280, Wall time: 2326.84, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001188, Num updates: 320, Wall time: 2332.34, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001188, Num updates: 360, Wall time: 2337.48, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001188, Num updates: 400, Wall time: 2342.56, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 41, time: 55.23
	train_loss: 0.0012, score: 27.91
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001142, Num updates: 40, Wall time: 2350.41, ETA: 0m 6s (- 1m 1s)
Iter: 80, Loss 0.001162, Num updates: 80, Wall time: 2355.83, ETA: 0m 12s (- 0m 48s)
Iter: 120, Loss 0.001165, Num updates: 120, Wall time: 2361.07, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001171, Num updates: 160, Wall time: 2366.47, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001175, Num updates: 200, Wall time: 2371.75, ETA: 0m 27s (- 0m 28s)
Iter: 240, Loss 0.001177, Num updates: 240, Wall time: 2377.30, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001178, Num updates: 280, Wall time: 2382.57, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001180, Num updates: 320, Wall time: 2387.73, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001180, Num updates: 360, Wall time: 2392.96, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001183, Num updates: 400, Wall time: 2398.36, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 42, time: 55.59
	train_loss: 0.0012, score: 27.40
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001147, Num updates: 40, Wall time: 2406.23, ETA: 0m 6s (- 1m 1s)
Iter: 80, Loss 0.001158, Num updates: 80, Wall time: 2411.73, ETA: 0m 12s (- 0m 49s)
Iter: 120, Loss 0.001164, Num updates: 120, Wall time: 2416.93, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001160, Num updates: 160, Wall time: 2422.00, ETA: 0m 22s (- 0m 33s)
Iter: 200, Loss 0.001168, Num updates: 200, Wall time: 2427.48, ETA: 0m 27s (- 0m 28s)
Iter: 240, Loss 0.001170, Num updates: 240, Wall time: 2432.64, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001171, Num updates: 280, Wall time: 2438.05, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001173, Num updates: 320, Wall time: 2443.52, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001173, Num updates: 360, Wall time: 2448.88, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001175, Num updates: 400, Wall time: 2454.47, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 43, time: 55.72
	train_loss: 0.0012, score: 27.16
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001130, Num updates: 40, Wall time: 2461.63, ETA: 0m 6s (- 0m 56s)
Iter: 80, Loss 0.001160, Num updates: 80, Wall time: 2466.78, ETA: 0m 11s (- 0m 45s)
Iter: 120, Loss 0.001147, Num updates: 120, Wall time: 2471.82, ETA: 0m 16s (- 0m 38s)
Iter: 160, Loss 0.001154, Num updates: 160, Wall time: 2476.91, ETA: 0m 21s (- 0m 32s)
Iter: 200, Loss 0.001158, Num updates: 200, Wall time: 2482.18, ETA: 0m 26s (- 0m 26s)
Iter: 240, Loss 0.001161, Num updates: 240, Wall time: 2487.67, ETA: 0m 32s (- 0m 21s)
Iter: 280, Loss 0.001164, Num updates: 280, Wall time: 2493.07, ETA: 0m 37s (- 0m 16s)
Iter: 320, Loss 0.001167, Num updates: 320, Wall time: 2498.48, ETA: 0m 42s (- 0m 10s)
Iter: 360, Loss 0.001170, Num updates: 360, Wall time: 2504.11, ETA: 0m 48s (- 0m 5s)
Iter: 400, Loss 0.001171, Num updates: 400, Wall time: 2509.22, ETA: 0m 53s (- 0m 0s)
Evaluating...
epoch 44, time: 54.77
	train_loss: 0.0012, score: 28.25
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001148, Num updates: 40, Wall time: 2516.85, ETA: 0m 6s (- 0m 58s)
Iter: 80, Loss 0.001149, Num updates: 80, Wall time: 2522.16, ETA: 0m 11s (- 0m 47s)
Iter: 120, Loss 0.001150, Num updates: 120, Wall time: 2527.81, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001159, Num updates: 160, Wall time: 2533.03, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001158, Num updates: 200, Wall time: 2538.53, ETA: 0m 27s (- 0m 28s)
Iter: 240, Loss 0.001162, Num updates: 240, Wall time: 2544.18, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001167, Num updates: 280, Wall time: 2549.11, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001164, Num updates: 320, Wall time: 2554.19, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001164, Num updates: 360, Wall time: 2559.61, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001164, Num updates: 400, Wall time: 2565.18, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 45, time: 55.63
	train_loss: 0.0012, score: 27.92
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001146, Num updates: 40, Wall time: 2573.26, ETA: 0m 6s (- 1m 3s)
Iter: 80, Loss 0.001154, Num updates: 80, Wall time: 2578.89, ETA: 0m 12s (- 0m 50s)
Iter: 120, Loss 0.001159, Num updates: 120, Wall time: 2584.40, ETA: 0m 17s (- 0m 42s)
Iter: 160, Loss 0.001153, Num updates: 160, Wall time: 2589.82, ETA: 0m 23s (- 0m 35s)
Iter: 200, Loss 0.001156, Num updates: 200, Wall time: 2594.89, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001156, Num updates: 240, Wall time: 2600.38, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001162, Num updates: 280, Wall time: 2605.87, ETA: 0m 39s (- 0m 17s)
Iter: 320, Loss 0.001162, Num updates: 320, Wall time: 2611.25, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001163, Num updates: 360, Wall time: 2616.50, ETA: 0m 50s (- 0m 5s)
Iter: 400, Loss 0.001164, Num updates: 400, Wall time: 2622.16, ETA: 0m 55s (- 0m 0s)
Evaluating...
epoch 46, time: 56.75
	train_loss: 0.0012, score: 27.57
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001111, Num updates: 40, Wall time: 2630.28, ETA: 0m 6s (- 1m 2s)
Iter: 80, Loss 0.001137, Num updates: 80, Wall time: 2635.40, ETA: 0m 11s (- 0m 48s)
Iter: 120, Loss 0.001146, Num updates: 120, Wall time: 2640.95, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001146, Num updates: 160, Wall time: 2646.40, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001152, Num updates: 200, Wall time: 2651.92, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001156, Num updates: 240, Wall time: 2657.18, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001154, Num updates: 280, Wall time: 2662.58, ETA: 0m 39s (- 0m 16s)
Iter: 320, Loss 0.001151, Num updates: 320, Wall time: 2667.98, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001153, Num updates: 360, Wall time: 2673.49, ETA: 0m 50s (- 0m 5s)
Iter: 400, Loss 0.001153, Num updates: 400, Wall time: 2678.77, ETA: 0m 55s (- 0m 0s)
Evaluating...
epoch 47, time: 56.11
	train_loss: 0.0012, score: 27.68
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001108, Num updates: 40, Wall time: 2686.50, ETA: 0m 6s (- 1m 2s)
Iter: 80, Loss 0.001124, Num updates: 80, Wall time: 2691.88, ETA: 0m 12s (- 0m 49s)
Iter: 120, Loss 0.001142, Num updates: 120, Wall time: 2697.65, ETA: 0m 17s (- 0m 42s)
Iter: 160, Loss 0.001150, Num updates: 160, Wall time: 2703.19, ETA: 0m 23s (- 0m 35s)
Iter: 200, Loss 0.001152, Num updates: 200, Wall time: 2708.75, ETA: 0m 28s (- 0m 29s)
Iter: 240, Loss 0.001148, Num updates: 240, Wall time: 2713.83, ETA: 0m 34s (- 0m 22s)
Iter: 280, Loss 0.001144, Num updates: 280, Wall time: 2719.12, ETA: 0m 39s (- 0m 17s)
Iter: 320, Loss 0.001149, Num updates: 320, Wall time: 2724.33, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001152, Num updates: 360, Wall time: 2729.82, ETA: 0m 50s (- 0m 5s)
Iter: 400, Loss 0.001152, Num updates: 400, Wall time: 2734.93, ETA: 0m 55s (- 0m 0s)
Evaluating...
epoch 48, time: 56.21
	train_loss: 0.0012, score: 27.48
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001104, Num updates: 40, Wall time: 2742.64, ETA: 0m 6s (- 0m 59s)
Iter: 80, Loss 0.001114, Num updates: 80, Wall time: 2748.02, ETA: 0m 11s (- 0m 47s)
Iter: 120, Loss 0.001127, Num updates: 120, Wall time: 2753.04, ETA: 0m 16s (- 0m 39s)
Iter: 160, Loss 0.001134, Num updates: 160, Wall time: 2758.41, ETA: 0m 22s (- 0m 33s)
Iter: 200, Loss 0.001138, Num updates: 200, Wall time: 2763.78, ETA: 0m 27s (- 0m 27s)
Iter: 240, Loss 0.001137, Num updates: 240, Wall time: 2769.01, ETA: 0m 32s (- 0m 22s)
Iter: 280, Loss 0.001143, Num updates: 280, Wall time: 2774.33, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001148, Num updates: 320, Wall time: 2779.57, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001148, Num updates: 360, Wall time: 2785.02, ETA: 0m 48s (- 0m 5s)
Iter: 400, Loss 0.001149, Num updates: 400, Wall time: 2790.62, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 49, time: 55.37
	train_loss: 0.0012, score: 27.34
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001080, Num updates: 40, Wall time: 2798.35, ETA: 0m 6s (- 1m 0s)
Iter: 80, Loss 0.001111, Num updates: 80, Wall time: 2803.65, ETA: 0m 11s (- 0m 48s)
Iter: 120, Loss 0.001127, Num updates: 120, Wall time: 2808.80, ETA: 0m 16s (- 0m 40s)
Iter: 160, Loss 0.001134, Num updates: 160, Wall time: 2814.08, ETA: 0m 22s (- 0m 33s)
Iter: 200, Loss 0.001137, Num updates: 200, Wall time: 2819.68, ETA: 0m 27s (- 0m 28s)
Iter: 240, Loss 0.001141, Num updates: 240, Wall time: 2825.00, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001139, Num updates: 280, Wall time: 2830.40, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001135, Num updates: 320, Wall time: 2835.88, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001140, Num updates: 360, Wall time: 2841.35, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001144, Num updates: 400, Wall time: 2846.72, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 50, time: 55.72
	train_loss: 0.0011, score: 27.43
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001113, Num updates: 40, Wall time: 2854.22, ETA: 0m 6s (- 0m 59s)
Iter: 80, Loss 0.001123, Num updates: 80, Wall time: 2859.55, ETA: 0m 11s (- 0m 47s)
Iter: 120, Loss 0.001124, Num updates: 120, Wall time: 2865.20, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001130, Num updates: 160, Wall time: 2870.64, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001127, Num updates: 200, Wall time: 2876.13, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001130, Num updates: 240, Wall time: 2881.62, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001132, Num updates: 280, Wall time: 2887.21, ETA: 0m 39s (- 0m 17s)
Iter: 320, Loss 0.001132, Num updates: 320, Wall time: 2892.51, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001135, Num updates: 360, Wall time: 2897.95, ETA: 0m 50s (- 0m 5s)
Iter: 400, Loss 0.001136, Num updates: 400, Wall time: 2903.19, ETA: 0m 55s (- 0m 0s)
Evaluating...
epoch 51, time: 56.42
	train_loss: 0.0011, score: 27.73
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001103, Num updates: 40, Wall time: 2911.14, ETA: 0m 6s (- 1m 2s)
Iter: 80, Loss 0.001118, Num updates: 80, Wall time: 2916.56, ETA: 0m 12s (- 0m 49s)
Iter: 120, Loss 0.001124, Num updates: 120, Wall time: 2921.89, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001124, Num updates: 160, Wall time: 2927.09, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001133, Num updates: 200, Wall time: 2932.48, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001138, Num updates: 240, Wall time: 2937.86, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001137, Num updates: 280, Wall time: 2943.37, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001138, Num updates: 320, Wall time: 2948.98, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001138, Num updates: 360, Wall time: 2954.30, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001136, Num updates: 400, Wall time: 2959.09, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 52, time: 55.80
	train_loss: 0.0011, score: 27.74
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001096, Num updates: 40, Wall time: 2967.01, ETA: 0m 6s (- 1m 0s)
Iter: 80, Loss 0.001112, Num updates: 80, Wall time: 2972.51, ETA: 0m 12s (- 0m 49s)
Iter: 120, Loss 0.001119, Num updates: 120, Wall time: 2977.78, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001122, Num updates: 160, Wall time: 2983.03, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001122, Num updates: 200, Wall time: 2988.46, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001121, Num updates: 240, Wall time: 2993.90, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001127, Num updates: 280, Wall time: 2999.27, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001129, Num updates: 320, Wall time: 3004.78, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001130, Num updates: 360, Wall time: 3009.85, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001133, Num updates: 400, Wall time: 3015.16, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 53, time: 55.69
	train_loss: 0.0011, score: 27.83
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001077, Num updates: 40, Wall time: 3023.12, ETA: 0m 6s (- 1m 2s)
Iter: 80, Loss 0.001093, Num updates: 80, Wall time: 3028.77, ETA: 0m 12s (- 0m 50s)
Iter: 120, Loss 0.001094, Num updates: 120, Wall time: 3034.13, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001100, Num updates: 160, Wall time: 3039.04, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001108, Num updates: 200, Wall time: 3044.37, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001111, Num updates: 240, Wall time: 3049.43, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001117, Num updates: 280, Wall time: 3054.68, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001120, Num updates: 320, Wall time: 3059.99, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001122, Num updates: 360, Wall time: 3065.34, ETA: 0m 48s (- 0m 5s)
Iter: 400, Loss 0.001125, Num updates: 400, Wall time: 3070.66, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 54, time: 55.17
	train_loss: 0.0011, score: 27.73
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001097, Num updates: 40, Wall time: 3078.49, ETA: 0m 6s (- 1m 2s)
Iter: 80, Loss 0.001117, Num updates: 80, Wall time: 3083.80, ETA: 0m 12s (- 0m 48s)
Iter: 120, Loss 0.001118, Num updates: 120, Wall time: 3089.12, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001117, Num updates: 160, Wall time: 3094.46, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001113, Num updates: 200, Wall time: 3099.81, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001116, Num updates: 240, Wall time: 3105.02, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001117, Num updates: 280, Wall time: 3110.46, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001120, Num updates: 320, Wall time: 3115.80, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001122, Num updates: 360, Wall time: 3121.19, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001123, Num updates: 400, Wall time: 3126.19, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 55, time: 55.48
	train_loss: 0.0011, score: 28.02
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001097, Num updates: 40, Wall time: 3133.90, ETA: 0m 6s (- 0m 59s)
Iter: 80, Loss 0.001096, Num updates: 80, Wall time: 3139.16, ETA: 0m 11s (- 0m 47s)
Iter: 120, Loss 0.001102, Num updates: 120, Wall time: 3144.71, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001115, Num updates: 160, Wall time: 3149.96, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001115, Num updates: 200, Wall time: 3155.33, ETA: 0m 27s (- 0m 28s)
Iter: 240, Loss 0.001117, Num updates: 240, Wall time: 3160.58, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001120, Num updates: 280, Wall time: 3166.14, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001118, Num updates: 320, Wall time: 3171.58, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001114, Num updates: 360, Wall time: 3176.95, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001117, Num updates: 400, Wall time: 3182.26, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 56, time: 55.88
	train_loss: 0.0011, score: 27.44
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001102, Num updates: 40, Wall time: 3190.26, ETA: 0m 6s (- 1m 2s)
Iter: 80, Loss 0.001113, Num updates: 80, Wall time: 3195.72, ETA: 0m 12s (- 0m 49s)
Iter: 120, Loss 0.001114, Num updates: 120, Wall time: 3200.48, ETA: 0m 16s (- 0m 39s)
Iter: 160, Loss 0.001112, Num updates: 160, Wall time: 3205.69, ETA: 0m 22s (- 0m 33s)
Iter: 200, Loss 0.001115, Num updates: 200, Wall time: 3210.85, ETA: 0m 27s (- 0m 27s)
Iter: 240, Loss 0.001116, Num updates: 240, Wall time: 3216.49, ETA: 0m 32s (- 0m 22s)
Iter: 280, Loss 0.001116, Num updates: 280, Wall time: 3221.89, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001118, Num updates: 320, Wall time: 3226.86, ETA: 0m 43s (- 0m 10s)
Iter: 360, Loss 0.001116, Num updates: 360, Wall time: 3231.85, ETA: 0m 48s (- 0m 5s)
Iter: 400, Loss 0.001115, Num updates: 400, Wall time: 3236.62, ETA: 0m 53s (- 0m 0s)
Evaluating...
epoch 57, time: 53.97
	train_loss: 0.0011, score: 27.33
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001064, Num updates: 40, Wall time: 3244.49, ETA: 0m 6s (- 1m 2s)
Iter: 80, Loss 0.001079, Num updates: 80, Wall time: 3249.74, ETA: 0m 11s (- 0m 48s)
Iter: 120, Loss 0.001089, Num updates: 120, Wall time: 3255.11, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001095, Num updates: 160, Wall time: 3260.53, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001100, Num updates: 200, Wall time: 3266.02, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001104, Num updates: 240, Wall time: 3271.33, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001106, Num updates: 280, Wall time: 3276.85, ETA: 0m 39s (- 0m 16s)
Iter: 320, Loss 0.001111, Num updates: 320, Wall time: 3282.31, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001109, Num updates: 360, Wall time: 3287.46, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001110, Num updates: 400, Wall time: 3292.80, ETA: 0m 55s (- 0m 0s)
Evaluating...
epoch 58, time: 55.97
	train_loss: 0.0011, score: 28.06
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001079, Num updates: 40, Wall time: 3300.55, ETA: 0m 6s (- 1m 0s)
Iter: 80, Loss 0.001089, Num updates: 80, Wall time: 3305.85, ETA: 0m 11s (- 0m 48s)
Iter: 120, Loss 0.001086, Num updates: 120, Wall time: 3311.22, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001095, Num updates: 160, Wall time: 3316.86, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001097, Num updates: 200, Wall time: 3322.53, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001105, Num updates: 240, Wall time: 3327.94, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001107, Num updates: 280, Wall time: 3333.26, ETA: 0m 39s (- 0m 17s)
Iter: 320, Loss 0.001110, Num updates: 320, Wall time: 3338.76, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001111, Num updates: 360, Wall time: 3343.91, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001111, Num updates: 400, Wall time: 3349.19, ETA: 0m 55s (- 0m 0s)
Evaluating...
epoch 59, time: 56.21
	train_loss: 0.0011, score: 27.34
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001056, Num updates: 40, Wall time: 3357.30, ETA: 0m 6s (- 1m 3s)
Iter: 80, Loss 0.001077, Num updates: 80, Wall time: 3362.42, ETA: 0m 11s (- 0m 48s)
Iter: 120, Loss 0.001090, Num updates: 120, Wall time: 3367.80, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001087, Num updates: 160, Wall time: 3373.16, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001090, Num updates: 200, Wall time: 3378.37, ETA: 0m 27s (- 0m 28s)
Iter: 240, Loss 0.001096, Num updates: 240, Wall time: 3383.81, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001100, Num updates: 280, Wall time: 3389.33, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001102, Num updates: 320, Wall time: 3394.84, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001101, Num updates: 360, Wall time: 3400.01, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001103, Num updates: 400, Wall time: 3405.25, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 60, time: 55.80
	train_loss: 0.0011, score: 27.64
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001072, Num updates: 40, Wall time: 3412.97, ETA: 0m 6s (- 1m 0s)
Iter: 80, Loss 0.001084, Num updates: 80, Wall time: 3418.27, ETA: 0m 11s (- 0m 47s)
Iter: 120, Loss 0.001083, Num updates: 120, Wall time: 3423.80, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001089, Num updates: 160, Wall time: 3429.18, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001090, Num updates: 200, Wall time: 3434.19, ETA: 0m 27s (- 0m 27s)
Iter: 240, Loss 0.001093, Num updates: 240, Wall time: 3439.47, ETA: 0m 32s (- 0m 22s)
Iter: 280, Loss 0.001096, Num updates: 280, Wall time: 3444.59, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001097, Num updates: 320, Wall time: 3449.75, ETA: 0m 43s (- 0m 10s)
Iter: 360, Loss 0.001098, Num updates: 360, Wall time: 3455.01, ETA: 0m 48s (- 0m 5s)
Iter: 400, Loss 0.001101, Num updates: 400, Wall time: 3460.24, ETA: 0m 53s (- 0m 0s)
Evaluating...
epoch 61, time: 54.77
	train_loss: 0.0011, score: 27.88
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001072, Num updates: 40, Wall time: 3467.30, ETA: 0m 5s (- 0m 54s)
Iter: 80, Loss 0.001079, Num updates: 80, Wall time: 3472.70, ETA: 0m 11s (- 0m 45s)
Iter: 120, Loss 0.001092, Num updates: 120, Wall time: 3478.16, ETA: 0m 16s (- 0m 39s)
Iter: 160, Loss 0.001090, Num updates: 160, Wall time: 3483.81, ETA: 0m 22s (- 0m 33s)
Iter: 200, Loss 0.001088, Num updates: 200, Wall time: 3489.51, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001095, Num updates: 240, Wall time: 3495.13, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001097, Num updates: 280, Wall time: 3500.30, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001097, Num updates: 320, Wall time: 3505.44, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001098, Num updates: 360, Wall time: 3510.80, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001098, Num updates: 400, Wall time: 3515.44, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 62, time: 54.80
	train_loss: 0.0011, score: 26.68
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001052, Num updates: 40, Wall time: 3523.12, ETA: 0m 6s (- 1m 1s)
Iter: 80, Loss 0.001074, Num updates: 80, Wall time: 3528.15, ETA: 0m 11s (- 0m 47s)
Iter: 120, Loss 0.001073, Num updates: 120, Wall time: 3533.50, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001078, Num updates: 160, Wall time: 3538.77, ETA: 0m 22s (- 0m 33s)
Iter: 200, Loss 0.001080, Num updates: 200, Wall time: 3544.15, ETA: 0m 27s (- 0m 27s)
Iter: 240, Loss 0.001086, Num updates: 240, Wall time: 3549.44, ETA: 0m 32s (- 0m 22s)
Iter: 280, Loss 0.001090, Num updates: 280, Wall time: 3554.87, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001092, Num updates: 320, Wall time: 3559.89, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001094, Num updates: 360, Wall time: 3564.95, ETA: 0m 48s (- 0m 5s)
Iter: 400, Loss 0.001096, Num updates: 400, Wall time: 3570.37, ETA: 0m 53s (- 0m 0s)
Evaluating...
epoch 63, time: 55.03
	train_loss: 0.0011, score: 27.41
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001064, Num updates: 40, Wall time: 3578.19, ETA: 0m 6s (- 0m 59s)
Iter: 80, Loss 0.001073, Num updates: 80, Wall time: 3583.48, ETA: 0m 11s (- 0m 47s)
Iter: 120, Loss 0.001079, Num updates: 120, Wall time: 3588.99, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001083, Num updates: 160, Wall time: 3594.40, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001089, Num updates: 200, Wall time: 3599.81, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001089, Num updates: 240, Wall time: 3605.11, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001093, Num updates: 280, Wall time: 3610.50, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001093, Num updates: 320, Wall time: 3615.74, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001093, Num updates: 360, Wall time: 3621.08, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001093, Num updates: 400, Wall time: 3626.70, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 64, time: 56.00
	train_loss: 0.0011, score: 27.16
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001051, Num updates: 40, Wall time: 3634.48, ETA: 0m 6s (- 1m 0s)
Iter: 80, Loss 0.001071, Num updates: 80, Wall time: 3639.88, ETA: 0m 11s (- 0m 48s)
Iter: 120, Loss 0.001077, Num updates: 120, Wall time: 3645.21, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001078, Num updates: 160, Wall time: 3650.90, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001082, Num updates: 200, Wall time: 3656.52, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001081, Num updates: 240, Wall time: 3661.91, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001084, Num updates: 280, Wall time: 3667.40, ETA: 0m 39s (- 0m 17s)
Iter: 320, Loss 0.001085, Num updates: 320, Wall time: 3672.64, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001087, Num updates: 360, Wall time: 3677.99, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001088, Num updates: 400, Wall time: 3683.59, ETA: 0m 55s (- 0m 0s)
Evaluating...
epoch 65, time: 56.41
	train_loss: 0.0011, score: 27.41
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001040, Num updates: 40, Wall time: 3691.17, ETA: 0m 6s (- 1m 0s)
Iter: 80, Loss 0.001059, Num updates: 80, Wall time: 3696.45, ETA: 0m 11s (- 0m 48s)
Iter: 120, Loss 0.001074, Num updates: 120, Wall time: 3702.16, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001081, Num updates: 160, Wall time: 3707.42, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001081, Num updates: 200, Wall time: 3713.11, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001079, Num updates: 240, Wall time: 3718.57, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001083, Num updates: 280, Wall time: 3724.17, ETA: 0m 39s (- 0m 17s)
Iter: 320, Loss 0.001082, Num updates: 320, Wall time: 3729.52, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001086, Num updates: 360, Wall time: 3734.57, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001086, Num updates: 400, Wall time: 3739.49, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 66, time: 55.95
	train_loss: 0.0011, score: 27.66
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001051, Num updates: 40, Wall time: 3747.62, ETA: 0m 6s (- 1m 2s)
Iter: 80, Loss 0.001063, Num updates: 80, Wall time: 3753.00, ETA: 0m 12s (- 0m 49s)
Iter: 120, Loss 0.001071, Num updates: 120, Wall time: 3758.27, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001073, Num updates: 160, Wall time: 3763.69, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001081, Num updates: 200, Wall time: 3768.91, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001084, Num updates: 240, Wall time: 3774.28, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001086, Num updates: 280, Wall time: 3779.65, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001086, Num updates: 320, Wall time: 3785.14, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001086, Num updates: 360, Wall time: 3790.09, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001087, Num updates: 400, Wall time: 3795.12, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 67, time: 55.26
	train_loss: 0.0011, score: 26.94
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001056, Num updates: 40, Wall time: 3803.10, ETA: 0m 6s (- 1m 2s)
Iter: 80, Loss 0.001062, Num updates: 80, Wall time: 3808.36, ETA: 0m 12s (- 0m 48s)
Iter: 120, Loss 0.001069, Num updates: 120, Wall time: 3813.66, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001071, Num updates: 160, Wall time: 3818.91, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001073, Num updates: 200, Wall time: 3824.33, ETA: 0m 27s (- 0m 28s)
Iter: 240, Loss 0.001076, Num updates: 240, Wall time: 3829.54, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001077, Num updates: 280, Wall time: 3834.96, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001078, Num updates: 320, Wall time: 3840.13, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001077, Num updates: 360, Wall time: 3845.39, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001080, Num updates: 400, Wall time: 3850.90, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 68, time: 55.62
	train_loss: 0.0011, score: 27.16
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001040, Num updates: 40, Wall time: 3858.61, ETA: 0m 6s (- 0m 59s)
Iter: 80, Loss 0.001057, Num updates: 80, Wall time: 3864.01, ETA: 0m 11s (- 0m 48s)
Iter: 120, Loss 0.001055, Num updates: 120, Wall time: 3869.14, ETA: 0m 16s (- 0m 40s)
Iter: 160, Loss 0.001065, Num updates: 160, Wall time: 3874.51, ETA: 0m 22s (- 0m 33s)
Iter: 200, Loss 0.001070, Num updates: 200, Wall time: 3879.88, ETA: 0m 27s (- 0m 27s)
Iter: 240, Loss 0.001073, Num updates: 240, Wall time: 3885.21, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001077, Num updates: 280, Wall time: 3890.65, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001078, Num updates: 320, Wall time: 3896.11, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001078, Num updates: 360, Wall time: 3901.27, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001075, Num updates: 400, Wall time: 3907.19, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 69, time: 55.78
	train_loss: 0.0011, score: 26.97
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001037, Num updates: 40, Wall time: 3915.04, ETA: 0m 6s (- 1m 2s)
Iter: 80, Loss 0.001052, Num updates: 80, Wall time: 3920.63, ETA: 0m 12s (- 0m 50s)
Iter: 120, Loss 0.001054, Num updates: 120, Wall time: 3925.78, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001063, Num updates: 160, Wall time: 3930.97, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001063, Num updates: 200, Wall time: 3936.08, ETA: 0m 27s (- 0m 28s)
Iter: 240, Loss 0.001070, Num updates: 240, Wall time: 3941.87, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001069, Num updates: 280, Wall time: 3947.10, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001072, Num updates: 320, Wall time: 3951.98, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001075, Num updates: 360, Wall time: 3957.47, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001074, Num updates: 400, Wall time: 3962.76, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 70, time: 55.56
	train_loss: 0.0011, score: 27.27
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001009, Num updates: 40, Wall time: 3970.49, ETA: 0m 6s (- 0m 59s)
Iter: 80, Loss 0.001040, Num updates: 80, Wall time: 3975.87, ETA: 0m 11s (- 0m 48s)
Iter: 120, Loss 0.001047, Num updates: 120, Wall time: 3981.30, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001053, Num updates: 160, Wall time: 3986.33, ETA: 0m 22s (- 0m 33s)
Iter: 200, Loss 0.001056, Num updates: 200, Wall time: 3991.66, ETA: 0m 27s (- 0m 27s)
Iter: 240, Loss 0.001059, Num updates: 240, Wall time: 3996.66, ETA: 0m 32s (- 0m 21s)
Iter: 280, Loss 0.001066, Num updates: 280, Wall time: 4001.93, ETA: 0m 37s (- 0m 16s)
Iter: 320, Loss 0.001067, Num updates: 320, Wall time: 4007.38, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001071, Num updates: 360, Wall time: 4012.60, ETA: 0m 48s (- 0m 5s)
Iter: 400, Loss 0.001072, Num updates: 400, Wall time: 4018.07, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 71, time: 55.19
	train_loss: 0.0011, score: 26.81
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001033, Num updates: 40, Wall time: 4025.40, ETA: 0m 5s (- 0m 54s)
Iter: 80, Loss 0.001048, Num updates: 80, Wall time: 4030.61, ETA: 0m 11s (- 0m 45s)
Iter: 120, Loss 0.001051, Num updates: 120, Wall time: 4035.95, ETA: 0m 16s (- 0m 38s)
Iter: 160, Loss 0.001063, Num updates: 160, Wall time: 4041.24, ETA: 0m 21s (- 0m 32s)
Iter: 200, Loss 0.001064, Num updates: 200, Wall time: 4046.81, ETA: 0m 27s (- 0m 27s)
Iter: 240, Loss 0.001063, Num updates: 240, Wall time: 4052.02, ETA: 0m 32s (- 0m 21s)
Iter: 280, Loss 0.001063, Num updates: 280, Wall time: 4057.40, ETA: 0m 37s (- 0m 16s)
Iter: 320, Loss 0.001061, Num updates: 320, Wall time: 4063.02, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001067, Num updates: 360, Wall time: 4068.60, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001068, Num updates: 400, Wall time: 4074.11, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 72, time: 55.54
	train_loss: 0.0011, score: 26.80
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001041, Num updates: 40, Wall time: 4081.73, ETA: 0m 6s (- 0m 59s)
Iter: 80, Loss 0.001058, Num updates: 80, Wall time: 4087.14, ETA: 0m 11s (- 0m 48s)
Iter: 120, Loss 0.001057, Num updates: 120, Wall time: 4092.40, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001059, Num updates: 160, Wall time: 4097.63, ETA: 0m 22s (- 0m 33s)
Iter: 200, Loss 0.001058, Num updates: 200, Wall time: 4103.23, ETA: 0m 27s (- 0m 28s)
Iter: 240, Loss 0.001063, Num updates: 240, Wall time: 4108.60, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001067, Num updates: 280, Wall time: 4113.72, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001067, Num updates: 320, Wall time: 4118.95, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001069, Num updates: 360, Wall time: 4124.63, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001067, Num updates: 400, Wall time: 4129.86, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 73, time: 55.55
	train_loss: 0.0011, score: 27.12
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001046, Num updates: 40, Wall time: 4138.06, ETA: 0m 7s (- 1m 5s)
Iter: 80, Loss 0.001047, Num updates: 80, Wall time: 4143.22, ETA: 0m 12s (- 0m 49s)
Iter: 120, Loss 0.001054, Num updates: 120, Wall time: 4148.07, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001053, Num updates: 160, Wall time: 4153.72, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001056, Num updates: 200, Wall time: 4159.40, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001061, Num updates: 240, Wall time: 4165.22, ETA: 0m 34s (- 0m 23s)
Iter: 280, Loss 0.001061, Num updates: 280, Wall time: 4170.96, ETA: 0m 39s (- 0m 17s)
Iter: 320, Loss 0.001060, Num updates: 320, Wall time: 4176.34, ETA: 0m 45s (- 0m 11s)
Iter: 360, Loss 0.001064, Num updates: 360, Wall time: 4181.56, ETA: 0m 50s (- 0m 5s)
Iter: 400, Loss 0.001064, Num updates: 400, Wall time: 4187.03, ETA: 0m 55s (- 0m 0s)
Evaluating...
epoch 74, time: 56.65
	train_loss: 0.0011, score: 26.91
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001042, Num updates: 40, Wall time: 4194.64, ETA: 0m 6s (- 1m 2s)
Iter: 80, Loss 0.001051, Num updates: 80, Wall time: 4199.97, ETA: 0m 12s (- 0m 49s)
Iter: 120, Loss 0.001053, Num updates: 120, Wall time: 4204.94, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001056, Num updates: 160, Wall time: 4209.67, ETA: 0m 21s (- 0m 33s)
Iter: 200, Loss 0.001060, Num updates: 200, Wall time: 4215.10, ETA: 0m 27s (- 0m 27s)
Iter: 240, Loss 0.001062, Num updates: 240, Wall time: 4220.15, ETA: 0m 32s (- 0m 21s)
Iter: 280, Loss 0.001062, Num updates: 280, Wall time: 4224.73, ETA: 0m 36s (- 0m 15s)
Iter: 320, Loss 0.001062, Num updates: 320, Wall time: 4230.06, ETA: 0m 42s (- 0m 10s)
Iter: 360, Loss 0.001064, Num updates: 360, Wall time: 4235.62, ETA: 0m 47s (- 0m 5s)
Iter: 400, Loss 0.001065, Num updates: 400, Wall time: 4240.69, ETA: 0m 52s (- 0m 0s)
Evaluating...
epoch 75, time: 53.76
	train_loss: 0.0011, score: 26.48
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001026, Num updates: 40, Wall time: 4248.71, ETA: 0m 6s (- 1m 3s)
Iter: 80, Loss 0.001047, Num updates: 80, Wall time: 4254.21, ETA: 0m 12s (- 0m 50s)
Iter: 120, Loss 0.001044, Num updates: 120, Wall time: 4259.60, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001050, Num updates: 160, Wall time: 4264.96, ETA: 0m 23s (- 0m 35s)
Iter: 200, Loss 0.001049, Num updates: 200, Wall time: 4270.48, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001052, Num updates: 240, Wall time: 4275.98, ETA: 0m 34s (- 0m 22s)
Iter: 280, Loss 0.001052, Num updates: 280, Wall time: 4281.55, ETA: 0m 39s (- 0m 17s)
Iter: 320, Loss 0.001058, Num updates: 320, Wall time: 4286.72, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001060, Num updates: 360, Wall time: 4292.08, ETA: 0m 50s (- 0m 5s)
Iter: 400, Loss 0.001061, Num updates: 400, Wall time: 4297.30, ETA: 0m 55s (- 0m 0s)
Evaluating...
epoch 76, time: 56.44
	train_loss: 0.0011, score: 26.87
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001026, Num updates: 40, Wall time: 4305.21, ETA: 0m 6s (- 1m 1s)
Iter: 80, Loss 0.001043, Num updates: 80, Wall time: 4310.43, ETA: 0m 11s (- 0m 48s)
Iter: 120, Loss 0.001048, Num updates: 120, Wall time: 4315.74, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001053, Num updates: 160, Wall time: 4321.25, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001051, Num updates: 200, Wall time: 4326.53, ETA: 0m 27s (- 0m 28s)
Iter: 240, Loss 0.001052, Num updates: 240, Wall time: 4331.72, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001052, Num updates: 280, Wall time: 4337.42, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001053, Num updates: 320, Wall time: 4342.86, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001059, Num updates: 360, Wall time: 4348.02, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001059, Num updates: 400, Wall time: 4353.37, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 77, time: 55.75
	train_loss: 0.0011, score: 26.35
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001031, Num updates: 40, Wall time: 4361.31, ETA: 0m 6s (- 1m 2s)
Iter: 80, Loss 0.001034, Num updates: 80, Wall time: 4366.76, ETA: 0m 12s (- 0m 49s)
Iter: 120, Loss 0.001042, Num updates: 120, Wall time: 4371.90, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001041, Num updates: 160, Wall time: 4377.39, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001043, Num updates: 200, Wall time: 4382.70, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001047, Num updates: 240, Wall time: 4387.80, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001052, Num updates: 280, Wall time: 4393.32, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001052, Num updates: 320, Wall time: 4398.67, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001052, Num updates: 360, Wall time: 4403.51, ETA: 0m 48s (- 0m 5s)
Iter: 400, Loss 0.001055, Num updates: 400, Wall time: 4408.55, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 78, time: 54.84
	train_loss: 0.0011, score: 26.77
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001013, Num updates: 40, Wall time: 4416.52, ETA: 0m 6s (- 1m 4s)
Iter: 80, Loss 0.001042, Num updates: 80, Wall time: 4421.76, ETA: 0m 12s (- 0m 49s)
Iter: 120, Loss 0.001050, Num updates: 120, Wall time: 4427.24, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001053, Num updates: 160, Wall time: 4432.48, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001057, Num updates: 200, Wall time: 4437.89, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001058, Num updates: 240, Wall time: 4443.38, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001054, Num updates: 280, Wall time: 4448.85, ETA: 0m 39s (- 0m 17s)
Iter: 320, Loss 0.001052, Num updates: 320, Wall time: 4453.98, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001054, Num updates: 360, Wall time: 4459.41, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001055, Num updates: 400, Wall time: 4464.34, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 79, time: 55.73
	train_loss: 0.0011, score: 26.35
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001026, Num updates: 40, Wall time: 4472.33, ETA: 0m 6s (- 1m 2s)
Iter: 80, Loss 0.001040, Num updates: 80, Wall time: 4477.57, ETA: 0m 12s (- 0m 48s)
Iter: 120, Loss 0.001047, Num updates: 120, Wall time: 4482.83, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001043, Num updates: 160, Wall time: 4488.25, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001047, Num updates: 200, Wall time: 4493.51, ETA: 0m 27s (- 0m 28s)
Iter: 240, Loss 0.001049, Num updates: 240, Wall time: 4498.92, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001049, Num updates: 280, Wall time: 4504.12, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001048, Num updates: 320, Wall time: 4509.20, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001048, Num updates: 360, Wall time: 4514.38, ETA: 0m 48s (- 0m 5s)
Iter: 400, Loss 0.001048, Num updates: 400, Wall time: 4519.84, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 80, time: 55.21
	train_loss: 0.0011, score: 26.64
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001001, Num updates: 40, Wall time: 4527.75, ETA: 0m 6s (- 1m 2s)
Iter: 80, Loss 0.001010, Num updates: 80, Wall time: 4533.16, ETA: 0m 12s (- 0m 49s)
Iter: 120, Loss 0.001023, Num updates: 120, Wall time: 4538.62, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001034, Num updates: 160, Wall time: 4544.05, ETA: 0m 23s (- 0m 34s)
Iter: 200, Loss 0.001036, Num updates: 200, Wall time: 4549.43, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001042, Num updates: 240, Wall time: 4554.75, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001048, Num updates: 280, Wall time: 4559.77, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001049, Num updates: 320, Wall time: 4565.18, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001049, Num updates: 360, Wall time: 4570.51, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001050, Num updates: 400, Wall time: 4575.51, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 81, time: 55.37
	train_loss: 0.0011, score: 26.77
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001020, Num updates: 40, Wall time: 4583.57, ETA: 0m 7s (- 1m 4s)
Iter: 80, Loss 0.001033, Num updates: 80, Wall time: 4588.92, ETA: 0m 12s (- 0m 50s)
Iter: 120, Loss 0.001044, Num updates: 120, Wall time: 4593.95, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001042, Num updates: 160, Wall time: 4599.69, ETA: 0m 23s (- 0m 35s)
Iter: 200, Loss 0.001040, Num updates: 200, Wall time: 4605.11, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001043, Num updates: 240, Wall time: 4610.94, ETA: 0m 34s (- 0m 23s)
Iter: 280, Loss 0.001043, Num updates: 280, Wall time: 4616.39, ETA: 0m 39s (- 0m 17s)
Iter: 320, Loss 0.001047, Num updates: 320, Wall time: 4621.91, ETA: 0m 45s (- 0m 11s)
Iter: 360, Loss 0.001044, Num updates: 360, Wall time: 4627.53, ETA: 0m 50s (- 0m 5s)
Iter: 400, Loss 0.001047, Num updates: 400, Wall time: 4633.08, ETA: 0m 56s (- 0m 0s)
Evaluating...
epoch 82, time: 57.46
	train_loss: 0.0010, score: 26.59
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001020, Num updates: 40, Wall time: 4640.89, ETA: 0m 6s (- 1m 1s)
Iter: 80, Loss 0.001025, Num updates: 80, Wall time: 4646.12, ETA: 0m 11s (- 0m 48s)
Iter: 120, Loss 0.001026, Num updates: 120, Wall time: 4651.72, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001029, Num updates: 160, Wall time: 4657.01, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001035, Num updates: 200, Wall time: 4662.33, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001040, Num updates: 240, Wall time: 4667.55, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001044, Num updates: 280, Wall time: 4672.88, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001043, Num updates: 320, Wall time: 4678.12, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001045, Num updates: 360, Wall time: 4683.61, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001046, Num updates: 400, Wall time: 4688.90, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 83, time: 55.36
	train_loss: 0.0010, score: 26.66
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001011, Num updates: 40, Wall time: 4696.64, ETA: 0m 6s (- 1m 3s)
Iter: 80, Loss 0.001018, Num updates: 80, Wall time: 4701.84, ETA: 0m 12s (- 0m 48s)
Iter: 120, Loss 0.001026, Num updates: 120, Wall time: 4707.36, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001032, Num updates: 160, Wall time: 4712.86, ETA: 0m 23s (- 0m 34s)
Iter: 200, Loss 0.001036, Num updates: 200, Wall time: 4718.18, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001038, Num updates: 240, Wall time: 4723.66, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001036, Num updates: 280, Wall time: 4728.82, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001039, Num updates: 320, Wall time: 4734.44, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001040, Num updates: 360, Wall time: 4739.71, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001042, Num updates: 400, Wall time: 4744.72, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 84, time: 55.86
	train_loss: 0.0010, score: 26.35
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.000992, Num updates: 40, Wall time: 4752.60, ETA: 0m 6s (- 1m 1s)
Iter: 80, Loss 0.001012, Num updates: 80, Wall time: 4757.76, ETA: 0m 11s (- 0m 48s)
Iter: 120, Loss 0.001032, Num updates: 120, Wall time: 4763.29, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001035, Num updates: 160, Wall time: 4768.81, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001035, Num updates: 200, Wall time: 4774.13, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001039, Num updates: 240, Wall time: 4779.55, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001039, Num updates: 280, Wall time: 4784.74, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001039, Num updates: 320, Wall time: 4790.15, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001044, Num updates: 360, Wall time: 4795.63, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001041, Num updates: 400, Wall time: 4800.90, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 85, time: 56.04
	train_loss: 0.0010, score: 26.44
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001003, Num updates: 40, Wall time: 4808.85, ETA: 0m 6s (- 1m 1s)
Iter: 80, Loss 0.001012, Num updates: 80, Wall time: 4814.28, ETA: 0m 12s (- 0m 48s)
Iter: 120, Loss 0.001019, Num updates: 120, Wall time: 4819.89, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001026, Num updates: 160, Wall time: 4825.64, ETA: 0m 23s (- 0m 35s)
Iter: 200, Loss 0.001033, Num updates: 200, Wall time: 4830.71, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001034, Num updates: 240, Wall time: 4836.16, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001033, Num updates: 280, Wall time: 4841.53, ETA: 0m 39s (- 0m 17s)
Iter: 320, Loss 0.001034, Num updates: 320, Wall time: 4846.71, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001036, Num updates: 360, Wall time: 4851.84, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001038, Num updates: 400, Wall time: 4857.22, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 86, time: 55.94
	train_loss: 0.0010, score: 26.80
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001009, Num updates: 40, Wall time: 4864.92, ETA: 0m 6s (- 1m 0s)
Iter: 80, Loss 0.001009, Num updates: 80, Wall time: 4869.91, ETA: 0m 11s (- 0m 46s)
Iter: 120, Loss 0.001019, Num updates: 120, Wall time: 4875.28, ETA: 0m 16s (- 0m 39s)
Iter: 160, Loss 0.001025, Num updates: 160, Wall time: 4880.87, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001029, Num updates: 200, Wall time: 4886.10, ETA: 0m 27s (- 0m 27s)
Iter: 240, Loss 0.001032, Num updates: 240, Wall time: 4891.59, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001035, Num updates: 280, Wall time: 4896.59, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001036, Num updates: 320, Wall time: 4901.82, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001038, Num updates: 360, Wall time: 4906.67, ETA: 0m 48s (- 0m 5s)
Iter: 400, Loss 0.001039, Num updates: 400, Wall time: 4911.63, ETA: 0m 53s (- 0m 0s)
Evaluating...
epoch 87, time: 54.22
	train_loss: 0.0010, score: 26.48
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001014, Num updates: 40, Wall time: 4919.50, ETA: 0m 6s (- 1m 1s)
Iter: 80, Loss 0.001015, Num updates: 80, Wall time: 4925.04, ETA: 0m 12s (- 0m 49s)
Iter: 120, Loss 0.001025, Num updates: 120, Wall time: 4930.32, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001023, Num updates: 160, Wall time: 4935.57, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001025, Num updates: 200, Wall time: 4940.63, ETA: 0m 27s (- 0m 28s)
Iter: 240, Loss 0.001026, Num updates: 240, Wall time: 4946.38, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001028, Num updates: 280, Wall time: 4951.32, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001032, Num updates: 320, Wall time: 4957.15, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001033, Num updates: 360, Wall time: 4962.80, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001035, Num updates: 400, Wall time: 4968.00, ETA: 0m 55s (- 0m 0s)
Evaluating...
epoch 88, time: 56.07
	train_loss: 0.0010, score: 26.50
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001000, Num updates: 40, Wall time: 4975.58, ETA: 0m 6s (- 0m 59s)
Iter: 80, Loss 0.001015, Num updates: 80, Wall time: 4980.83, ETA: 0m 11s (- 0m 47s)
Iter: 120, Loss 0.001018, Num updates: 120, Wall time: 4985.80, ETA: 0m 16s (- 0m 39s)
Iter: 160, Loss 0.001027, Num updates: 160, Wall time: 4991.26, ETA: 0m 22s (- 0m 33s)
Iter: 200, Loss 0.001025, Num updates: 200, Wall time: 4996.49, ETA: 0m 27s (- 0m 27s)
Iter: 240, Loss 0.001026, Num updates: 240, Wall time: 5001.72, ETA: 0m 32s (- 0m 21s)
Iter: 280, Loss 0.001029, Num updates: 280, Wall time: 5006.99, ETA: 0m 37s (- 0m 16s)
Iter: 320, Loss 0.001033, Num updates: 320, Wall time: 5012.21, ETA: 0m 43s (- 0m 10s)
Iter: 360, Loss 0.001031, Num updates: 360, Wall time: 5017.63, ETA: 0m 48s (- 0m 5s)
Iter: 400, Loss 0.001034, Num updates: 400, Wall time: 5022.75, ETA: 0m 53s (- 0m 0s)
Evaluating...
epoch 89, time: 54.58
	train_loss: 0.0010, score: 26.29
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001026, Num updates: 40, Wall time: 5030.43, ETA: 0m 6s (- 0m 59s)
Iter: 80, Loss 0.001027, Num updates: 80, Wall time: 5035.60, ETA: 0m 11s (- 0m 47s)
Iter: 120, Loss 0.001026, Num updates: 120, Wall time: 5041.07, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001019, Num updates: 160, Wall time: 5046.50, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001023, Num updates: 200, Wall time: 5051.70, ETA: 0m 27s (- 0m 28s)
Iter: 240, Loss 0.001025, Num updates: 240, Wall time: 5057.00, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001028, Num updates: 280, Wall time: 5061.98, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001030, Num updates: 320, Wall time: 5067.06, ETA: 0m 43s (- 0m 10s)
Iter: 360, Loss 0.001033, Num updates: 360, Wall time: 5072.58, ETA: 0m 48s (- 0m 5s)
Iter: 400, Loss 0.001031, Num updates: 400, Wall time: 5077.94, ETA: 0m 53s (- 0m 0s)
Evaluating...
epoch 90, time: 55.03
	train_loss: 0.0010, score: 26.12
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001002, Num updates: 40, Wall time: 5085.95, ETA: 0m 6s (- 1m 2s)
Iter: 80, Loss 0.001013, Num updates: 80, Wall time: 5091.52, ETA: 0m 12s (- 0m 50s)
Iter: 120, Loss 0.001022, Num updates: 120, Wall time: 5096.76, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001027, Num updates: 160, Wall time: 5102.39, ETA: 0m 23s (- 0m 35s)
Iter: 200, Loss 0.001026, Num updates: 200, Wall time: 5107.91, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001025, Num updates: 240, Wall time: 5113.31, ETA: 0m 34s (- 0m 22s)
Iter: 280, Loss 0.001030, Num updates: 280, Wall time: 5118.55, ETA: 0m 39s (- 0m 17s)
Iter: 320, Loss 0.001033, Num updates: 320, Wall time: 5123.71, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001033, Num updates: 360, Wall time: 5129.16, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001034, Num updates: 400, Wall time: 5134.14, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 91, time: 55.83
	train_loss: 0.0010, score: 26.46
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.000986, Num updates: 40, Wall time: 5141.98, ETA: 0m 6s (- 1m 2s)
Iter: 80, Loss 0.001005, Num updates: 80, Wall time: 5147.40, ETA: 0m 12s (- 0m 49s)
Iter: 120, Loss 0.001015, Num updates: 120, Wall time: 5152.61, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001019, Num updates: 160, Wall time: 5157.63, ETA: 0m 22s (- 0m 33s)
Iter: 200, Loss 0.001021, Num updates: 200, Wall time: 5162.69, ETA: 0m 27s (- 0m 27s)
Iter: 240, Loss 0.001021, Num updates: 240, Wall time: 5167.86, ETA: 0m 32s (- 0m 21s)
Iter: 280, Loss 0.001026, Num updates: 280, Wall time: 5172.98, ETA: 0m 37s (- 0m 16s)
Iter: 320, Loss 0.001027, Num updates: 320, Wall time: 5178.63, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001028, Num updates: 360, Wall time: 5183.86, ETA: 0m 48s (- 0m 5s)
Iter: 400, Loss 0.001030, Num updates: 400, Wall time: 5188.87, ETA: 0m 53s (- 0m 0s)
Evaluating...
epoch 92, time: 54.46
	train_loss: 0.0010, score: 26.33
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001012, Num updates: 40, Wall time: 5196.51, ETA: 0m 6s (- 1m 0s)
Iter: 80, Loss 0.001025, Num updates: 80, Wall time: 5201.75, ETA: 0m 11s (- 0m 47s)
Iter: 120, Loss 0.001025, Num updates: 120, Wall time: 5207.36, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001026, Num updates: 160, Wall time: 5212.65, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001029, Num updates: 200, Wall time: 5218.20, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001028, Num updates: 240, Wall time: 5223.54, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001028, Num updates: 280, Wall time: 5229.29, ETA: 0m 39s (- 0m 17s)
Iter: 320, Loss 0.001028, Num updates: 320, Wall time: 5234.75, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001029, Num updates: 360, Wall time: 5240.13, ETA: 0m 50s (- 0m 5s)
Iter: 400, Loss 0.001027, Num updates: 400, Wall time: 5245.48, ETA: 0m 55s (- 0m 0s)
Evaluating...
epoch 93, time: 56.45
	train_loss: 0.0010, score: 26.23
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001008, Num updates: 40, Wall time: 5253.46, ETA: 0m 6s (- 1m 3s)
Iter: 80, Loss 0.001006, Num updates: 80, Wall time: 5258.71, ETA: 0m 12s (- 0m 49s)
Iter: 120, Loss 0.001017, Num updates: 120, Wall time: 5263.90, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001015, Num updates: 160, Wall time: 5269.15, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001019, Num updates: 200, Wall time: 5274.20, ETA: 0m 27s (- 0m 27s)
Iter: 240, Loss 0.001023, Num updates: 240, Wall time: 5279.73, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001024, Num updates: 280, Wall time: 5285.25, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001025, Num updates: 320, Wall time: 5290.50, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001026, Num updates: 360, Wall time: 5295.42, ETA: 0m 48s (- 0m 5s)
Iter: 400, Loss 0.001028, Num updates: 400, Wall time: 5300.71, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 94, time: 55.04
	train_loss: 0.0010, score: 26.27
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.000986, Num updates: 40, Wall time: 5308.56, ETA: 0m 6s (- 1m 1s)
Iter: 80, Loss 0.001000, Num updates: 80, Wall time: 5313.41, ETA: 0m 11s (- 0m 46s)
Iter: 120, Loss 0.001012, Num updates: 120, Wall time: 5318.54, ETA: 0m 16s (- 0m 39s)
Iter: 160, Loss 0.001020, Num updates: 160, Wall time: 5323.38, ETA: 0m 21s (- 0m 32s)
Iter: 200, Loss 0.001016, Num updates: 200, Wall time: 5327.68, ETA: 0m 25s (- 0m 26s)
Iter: 240, Loss 0.001018, Num updates: 240, Wall time: 5332.03, ETA: 0m 30s (- 0m 20s)
Iter: 280, Loss 0.001018, Num updates: 280, Wall time: 5336.41, ETA: 0m 34s (- 0m 14s)
Iter: 320, Loss 0.001018, Num updates: 320, Wall time: 5340.95, ETA: 0m 39s (- 0m 9s)
Iter: 360, Loss 0.001022, Num updates: 360, Wall time: 5345.53, ETA: 0m 43s (- 0m 4s)
Iter: 400, Loss 0.001023, Num updates: 400, Wall time: 5349.90, ETA: 0m 47s (- 0m 0s)
Evaluating...
epoch 95, time: 49.17
	train_loss: 0.0010, score: 26.30
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001008, Num updates: 40, Wall time: 5358.89, ETA: 0m 7s (- 1m 9s)
Iter: 80, Loss 0.001015, Num updates: 80, Wall time: 5364.10, ETA: 0m 12s (- 0m 51s)
Iter: 120, Loss 0.001018, Num updates: 120, Wall time: 5369.14, ETA: 0m 17s (- 0m 42s)
Iter: 160, Loss 0.001015, Num updates: 160, Wall time: 5374.29, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001013, Num updates: 200, Wall time: 5379.23, ETA: 0m 27s (- 0m 28s)
Iter: 240, Loss 0.001017, Num updates: 240, Wall time: 5384.13, ETA: 0m 32s (- 0m 22s)
Iter: 280, Loss 0.001017, Num updates: 280, Wall time: 5389.39, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001017, Num updates: 320, Wall time: 5394.36, ETA: 0m 43s (- 0m 10s)
Iter: 360, Loss 0.001018, Num updates: 360, Wall time: 5399.55, ETA: 0m 48s (- 0m 5s)
Iter: 400, Loss 0.001020, Num updates: 400, Wall time: 5404.40, ETA: 0m 53s (- 0m 0s)
Evaluating...
epoch 96, time: 54.08
	train_loss: 0.0010, score: 26.17
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.000989, Num updates: 40, Wall time: 5413.19, ETA: 0m 7s (- 1m 9s)
Iter: 80, Loss 0.001010, Num updates: 80, Wall time: 5418.51, ETA: 0m 12s (- 0m 52s)
Iter: 120, Loss 0.001014, Num updates: 120, Wall time: 5423.84, ETA: 0m 18s (- 0m 42s)
Iter: 160, Loss 0.001010, Num updates: 160, Wall time: 5428.88, ETA: 0m 23s (- 0m 35s)
Iter: 200, Loss 0.001013, Num updates: 200, Wall time: 5434.24, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001011, Num updates: 240, Wall time: 5439.73, ETA: 0m 34s (- 0m 22s)
Iter: 280, Loss 0.001014, Num updates: 280, Wall time: 5444.84, ETA: 0m 39s (- 0m 16s)
Iter: 320, Loss 0.001018, Num updates: 320, Wall time: 5450.07, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001018, Num updates: 360, Wall time: 5455.50, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001020, Num updates: 400, Wall time: 5460.81, ETA: 0m 55s (- 0m 0s)
Evaluating...
epoch 97, time: 56.38
	train_loss: 0.0010, score: 25.94
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.000998, Num updates: 40, Wall time: 5469.85, ETA: 0m 7s (- 1m 10s)
Iter: 80, Loss 0.001015, Num updates: 80, Wall time: 5475.27, ETA: 0m 13s (- 0m 52s)
Iter: 120, Loss 0.001023, Num updates: 120, Wall time: 5480.66, ETA: 0m 18s (- 0m 43s)
Iter: 160, Loss 0.001024, Num updates: 160, Wall time: 5486.12, ETA: 0m 23s (- 0m 36s)
Iter: 200, Loss 0.001021, Num updates: 200, Wall time: 5491.45, ETA: 0m 29s (- 0m 29s)
Iter: 240, Loss 0.001022, Num updates: 240, Wall time: 5496.84, ETA: 0m 34s (- 0m 23s)
Iter: 280, Loss 0.001023, Num updates: 280, Wall time: 5502.11, ETA: 0m 39s (- 0m 17s)
Iter: 320, Loss 0.001023, Num updates: 320, Wall time: 5507.41, ETA: 0m 45s (- 0m 11s)
Iter: 360, Loss 0.001023, Num updates: 360, Wall time: 5512.98, ETA: 0m 50s (- 0m 5s)
Iter: 400, Loss 0.001022, Num updates: 400, Wall time: 5517.90, ETA: 0m 55s (- 0m 0s)
Evaluating...
epoch 98, time: 56.89
	train_loss: 0.0010, score: 25.54
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001004, Num updates: 40, Wall time: 5526.55, ETA: 0m 7s (- 1m 6s)
Iter: 80, Loss 0.001007, Num updates: 80, Wall time: 5532.21, ETA: 0m 12s (- 0m 52s)
Iter: 120, Loss 0.001010, Num updates: 120, Wall time: 5537.69, ETA: 0m 18s (- 0m 43s)
Iter: 160, Loss 0.001014, Num updates: 160, Wall time: 5542.89, ETA: 0m 23s (- 0m 35s)
Iter: 200, Loss 0.001016, Num updates: 200, Wall time: 5548.22, ETA: 0m 28s (- 0m 29s)
Iter: 240, Loss 0.001018, Num updates: 240, Wall time: 5553.76, ETA: 0m 34s (- 0m 23s)
Iter: 280, Loss 0.001018, Num updates: 280, Wall time: 5559.03, ETA: 0m 39s (- 0m 17s)
Iter: 320, Loss 0.001018, Num updates: 320, Wall time: 5564.37, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001019, Num updates: 360, Wall time: 5569.49, ETA: 0m 50s (- 0m 5s)
Iter: 400, Loss 0.001018, Num updates: 400, Wall time: 5574.68, ETA: 0m 55s (- 0m 0s)
Evaluating...
epoch 99, time: 56.42
	train_loss: 0.0010, score: 25.93
	eval score: 0.00 (0.00)
0.00404,0.00179,0.00172,0.00167,0.00165,0.00163,0.00161,0.00159,0.00158,0.00156,0.00154,0.00152,0.00151,0.00149,0.00147,0.00146,0.00144,0.00142,0.00141,0.00139,0.00138,0.00136,0.00135,0.00133,0.00133,0.00131,0.0013,0.00129,0.00128,0.00127,0.00126,0.00126,0.00125,0.00124,0.00123,0.00122,0.00122,0.00122,0.0012,0.0012,0.0012,0.00119,0.00119,0.00118,0.00117,0.00117,0.00117,0.00116,0.00115,0.00115,0.00115,0.00114,0.00114,0.00114,0.00113,0.00113,0.00112,0.00112,0.00111,0.00111,0.00111,0.0011,0.0011,0.0011,0.0011,0.00109,0.00109,0.00109,0.00108,0.00108,0.00108,0.00108,0.00107,0.00107,0.00107,0.00107,0.00106,0.00106,0.00106,0.00106,0.00105,0.00105,0.00105,0.00105,0.00104,0.00104,0.00104,0.00104,0.00104,0.00104,0.00103,0.00104,0.00103,0.00103,0.00103,0.00103,0.00102,0.00102,0.00102,0.00102
0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
saved_model_Med2019/BAN_MEVF
Namespace(RAD_dir='/home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019', activation='relu', ae_alpha=0.001, ae_model_path='pretrained_ae.pth', alpha=1.0, autoencoder=True, batch_size=32, clip_norm=0.25, dropout=0.5, epochs=60, eps_cnn=1e-05, feat_dim=32, five_fold=False, gamma=2, gpu=0, input=None, lr=0.03, maml=True, maml_model_path='pretrained_maml.weights', model='BAN', momentum_cnn=0.05, num_hid=1024, num_stacks=2, op='c', output='saved_model_Med2019/BAN_MEVF', pow=2, print_interval=40, qc_model_path='./saved_models/QC/rad_best.pth', question_len=12, record_id=1, rescale_factor=1.5, rnn='LSTM', seed=3, tfidf=True, update_freq='1', use_RAD=True, use_ablation=False, use_ablation_q=False, use_ablation_v=False, use_counter=False, use_grad_cam=False, use_kl_mix=False, use_mix=True, use_mix_all=False, use_mix_cond=True, use_mix_cond_q=True, use_mix_cond_v=False, use_mix_cond_vq_in=False, use_mix_cond_vq_union=False, use_partial_label=False, use_rescale=False, use_sep_mix=False)
loading dictionary from /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/dictionary.pkl
loading MAML image data from file: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/images84x84.pkl
loading DAE image data from file: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/images128x128.pkl
loading MAML image data from file: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/images84x84.pkl
loading DAE image data from file: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/images128x128.pkl
load initial weights MAML from: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/pretrained_maml.weights
load initial weights DAE from: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/pretrained_ae.pth
loading dictionary from /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/dictionary.pkl
Loading embedding tfidf and weights from file
Load embedding tfidf and weights from file successfully
Namespace(RAD_dir='/home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019', activation='relu', ae_alpha=0.001, ae_model_path='pretrained_ae.pth', alpha=1.0, autoencoder=True, batch_size=32, clip_norm=0.25, device=device(type='cuda', index=0), dropout=0.5, epochs=60, eps_cnn=1e-05, feat_dim=64, five_fold=False, gamma=2, gpu=0, input=None, lr=0.03, maml=True, maml_model_path='pretrained_maml.weights', model='BAN', momentum_cnn=0.05, num_hid=1024, num_stacks=2, op='c', output='saved_model_Med2019/BAN_MEVF', pow=2, print_interval=40, qc_model_path='./saved_models/QC/rad_best.pth', question_len=12, record_id=1, rescale_factor=1.5, rnn='LSTM', seed=3, tfidf=True, update_freq='1', use_RAD=True, use_ablation=False, use_ablation_q=False, use_ablation_v=False, use_counter=False, use_grad_cam=False, use_kl_mix=False, use_mix=True, use_mix_all=False, use_mix_cond=True, use_mix_cond_q=True, use_mix_cond_v=False, use_mix_cond_vq_in=False, use_mix_cond_vq_union=False, use_partial_label=False, use_rescale=False, use_sep_mix=False)
nParams=	21342541
optim: adamax lr=0.0300, decay_step=3, decay_rate=0.75, grad_clip=0.25
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'language_model.WordEmbedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Iter: 40, Loss 0.021839, Num updates: 40, Wall time: 4.73, ETA: 0m 4s (- 0m 39s)
Iter: 80, Loss 0.012096, Num updates: 80, Wall time: 7.67, ETA: 0m 7s (- 0m 29s)
Iter: 120, Loss 0.008773, Num updates: 120, Wall time: 10.55, ETA: 0m 10s (- 0m 23s)
Iter: 160, Loss 0.007119, Num updates: 160, Wall time: 13.39, ETA: 0m 12s (- 0m 19s)
Iter: 200, Loss 0.006112, Num updates: 200, Wall time: 16.44, ETA: 0m 15s (- 0m 16s)
Iter: 240, Loss 0.005429, Num updates: 240, Wall time: 19.38, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.004942, Num updates: 280, Wall time: 22.15, ETA: 0m 21s (- 0m 9s)
Iter: 320, Loss 0.004570, Num updates: 320, Wall time: 25.01, ETA: 0m 24s (- 0m 6s)
Iter: 360, Loss 0.004274, Num updates: 360, Wall time: 28.33, ETA: 0m 27s (- 0m 3s)
Iter: 400, Loss 0.004034, Num updates: 400, Wall time: 31.60, ETA: 0m 31s (- 0m 0s)
Evaluating...
epoch 0, time: 31.92
	train_loss: 0.0040, score: 14.34
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001794, Num updates: 40, Wall time: 36.35, ETA: 0m 3s (- 0m 34s)
Iter: 80, Loss 0.001808, Num updates: 80, Wall time: 39.14, ETA: 0m 6s (- 0m 26s)
Iter: 120, Loss 0.001799, Num updates: 120, Wall time: 41.90, ETA: 0m 9s (- 0m 21s)
Iter: 160, Loss 0.001797, Num updates: 160, Wall time: 44.75, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001800, Num updates: 200, Wall time: 47.74, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001795, Num updates: 240, Wall time: 50.49, ETA: 0m 17s (- 0m 12s)
Iter: 280, Loss 0.001798, Num updates: 280, Wall time: 53.38, ETA: 0m 20s (- 0m 8s)
Iter: 320, Loss 0.001798, Num updates: 320, Wall time: 56.16, ETA: 0m 23s (- 0m 5s)
Iter: 360, Loss 0.001794, Num updates: 360, Wall time: 58.97, ETA: 0m 26s (- 0m 3s)
Iter: 400, Loss 0.001787, Num updates: 400, Wall time: 61.61, ETA: 0m 28s (- 0m 0s)
Evaluating...
epoch 1, time: 29.67
	train_loss: 0.0018, score: 20.15
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001689, Num updates: 40, Wall time: 66.35, ETA: 0m 3s (- 0m 35s)
Iter: 80, Loss 0.001715, Num updates: 80, Wall time: 69.08, ETA: 0m 6s (- 0m 26s)
Iter: 120, Loss 0.001732, Num updates: 120, Wall time: 72.07, ETA: 0m 9s (- 0m 22s)
Iter: 160, Loss 0.001722, Num updates: 160, Wall time: 75.03, ETA: 0m 12s (- 0m 19s)
Iter: 200, Loss 0.001712, Num updates: 200, Wall time: 77.95, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001711, Num updates: 240, Wall time: 80.87, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001712, Num updates: 280, Wall time: 83.94, ETA: 0m 21s (- 0m 9s)
Iter: 320, Loss 0.001713, Num updates: 320, Wall time: 87.13, ETA: 0m 24s (- 0m 6s)
Iter: 360, Loss 0.001715, Num updates: 360, Wall time: 90.05, ETA: 0m 27s (- 0m 3s)
Iter: 400, Loss 0.001713, Num updates: 400, Wall time: 93.26, ETA: 0m 30s (- 0m 0s)
Evaluating...
epoch 2, time: 31.50
	train_loss: 0.0017, score: 21.00
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001611, Num updates: 40, Wall time: 98.02, ETA: 0m 3s (- 0m 35s)
Iter: 80, Loss 0.001644, Num updates: 80, Wall time: 100.84, ETA: 0m 6s (- 0m 27s)
Iter: 120, Loss 0.001644, Num updates: 120, Wall time: 104.31, ETA: 0m 10s (- 0m 23s)
Iter: 160, Loss 0.001655, Num updates: 160, Wall time: 107.78, ETA: 0m 13s (- 0m 20s)
Iter: 200, Loss 0.001663, Num updates: 200, Wall time: 111.14, ETA: 0m 16s (- 0m 17s)
Iter: 240, Loss 0.001666, Num updates: 240, Wall time: 114.10, ETA: 0m 19s (- 0m 13s)
Iter: 280, Loss 0.001666, Num updates: 280, Wall time: 117.27, ETA: 0m 23s (- 0m 10s)
Iter: 320, Loss 0.001668, Num updates: 320, Wall time: 120.51, ETA: 0m 26s (- 0m 6s)
Iter: 360, Loss 0.001668, Num updates: 360, Wall time: 124.14, ETA: 0m 29s (- 0m 3s)
Iter: 400, Loss 0.001670, Num updates: 400, Wall time: 127.49, ETA: 0m 33s (- 0m 0s)
Evaluating...
epoch 3, time: 34.10
	train_loss: 0.0017, score: 22.05
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001633, Num updates: 40, Wall time: 133.34, ETA: 0m 4s (- 0m 44s)
Iter: 80, Loss 0.001627, Num updates: 80, Wall time: 136.98, ETA: 0m 8s (- 0m 34s)
Iter: 120, Loss 0.001650, Num updates: 120, Wall time: 140.50, ETA: 0m 12s (- 0m 28s)
Iter: 160, Loss 0.001656, Num updates: 160, Wall time: 144.19, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001655, Num updates: 200, Wall time: 147.53, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001650, Num updates: 240, Wall time: 150.48, ETA: 0m 21s (- 0m 14s)
Iter: 280, Loss 0.001647, Num updates: 280, Wall time: 153.35, ETA: 0m 24s (- 0m 10s)
Iter: 320, Loss 0.001648, Num updates: 320, Wall time: 156.23, ETA: 0m 27s (- 0m 7s)
Iter: 360, Loss 0.001646, Num updates: 360, Wall time: 159.10, ETA: 0m 30s (- 0m 3s)
Iter: 400, Loss 0.001645, Num updates: 400, Wall time: 161.86, ETA: 0m 33s (- 0m 0s)
Evaluating...
epoch 4, time: 34.14
	train_loss: 0.0016, score: 21.98
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001636, Num updates: 40, Wall time: 166.67, ETA: 0m 3s (- 0m 35s)
Iter: 80, Loss 0.001625, Num updates: 80, Wall time: 169.58, ETA: 0m 6s (- 0m 27s)
Iter: 120, Loss 0.001614, Num updates: 120, Wall time: 172.68, ETA: 0m 9s (- 0m 23s)
Iter: 160, Loss 0.001617, Num updates: 160, Wall time: 175.45, ETA: 0m 12s (- 0m 19s)
Iter: 200, Loss 0.001619, Num updates: 200, Wall time: 178.04, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001613, Num updates: 240, Wall time: 181.06, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001614, Num updates: 280, Wall time: 183.95, ETA: 0m 21s (- 0m 9s)
Iter: 320, Loss 0.001617, Num updates: 320, Wall time: 186.79, ETA: 0m 23s (- 0m 6s)
Iter: 360, Loss 0.001622, Num updates: 360, Wall time: 189.62, ETA: 0m 26s (- 0m 3s)
Iter: 400, Loss 0.001623, Num updates: 400, Wall time: 192.35, ETA: 0m 29s (- 0m 0s)
Evaluating...
epoch 5, time: 30.36
	train_loss: 0.0016, score: 22.59
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001520, Num updates: 40, Wall time: 197.61, ETA: 0m 4s (- 0m 38s)
Iter: 80, Loss 0.001583, Num updates: 80, Wall time: 200.57, ETA: 0m 7s (- 0m 29s)
Iter: 120, Loss 0.001610, Num updates: 120, Wall time: 203.39, ETA: 0m 9s (- 0m 23s)
Iter: 160, Loss 0.001606, Num updates: 160, Wall time: 206.45, ETA: 0m 13s (- 0m 19s)
Iter: 200, Loss 0.001609, Num updates: 200, Wall time: 209.42, ETA: 0m 16s (- 0m 16s)
Iter: 240, Loss 0.001601, Num updates: 240, Wall time: 212.55, ETA: 0m 19s (- 0m 12s)
Iter: 280, Loss 0.001607, Num updates: 280, Wall time: 215.42, ETA: 0m 22s (- 0m 9s)
Iter: 320, Loss 0.001608, Num updates: 320, Wall time: 218.28, ETA: 0m 24s (- 0m 6s)
Iter: 360, Loss 0.001608, Num updates: 360, Wall time: 221.79, ETA: 0m 28s (- 0m 3s)
Iter: 400, Loss 0.001604, Num updates: 400, Wall time: 224.69, ETA: 0m 31s (- 0m 0s)
Evaluating...
epoch 6, time: 32.01
	train_loss: 0.0016, score: 23.72
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001558, Num updates: 40, Wall time: 229.44, ETA: 0m 3s (- 0m 35s)
Iter: 80, Loss 0.001578, Num updates: 80, Wall time: 232.43, ETA: 0m 6s (- 0m 27s)
Iter: 120, Loss 0.001587, Num updates: 120, Wall time: 235.34, ETA: 0m 9s (- 0m 22s)
Iter: 160, Loss 0.001586, Num updates: 160, Wall time: 238.30, ETA: 0m 12s (- 0m 19s)
Iter: 200, Loss 0.001584, Num updates: 200, Wall time: 241.26, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001587, Num updates: 240, Wall time: 244.23, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001583, Num updates: 280, Wall time: 247.10, ETA: 0m 21s (- 0m 9s)
Iter: 320, Loss 0.001590, Num updates: 320, Wall time: 249.88, ETA: 0m 24s (- 0m 6s)
Iter: 360, Loss 0.001588, Num updates: 360, Wall time: 252.73, ETA: 0m 27s (- 0m 3s)
Iter: 400, Loss 0.001588, Num updates: 400, Wall time: 255.59, ETA: 0m 29s (- 0m 0s)
Evaluating...
epoch 7, time: 30.79
	train_loss: 0.0016, score: 23.54
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001523, Num updates: 40, Wall time: 260.30, ETA: 0m 3s (- 0m 34s)
Iter: 80, Loss 0.001558, Num updates: 80, Wall time: 262.92, ETA: 0m 6s (- 0m 25s)
Iter: 120, Loss 0.001564, Num updates: 120, Wall time: 265.90, ETA: 0m 9s (- 0m 21s)
Iter: 160, Loss 0.001566, Num updates: 160, Wall time: 269.80, ETA: 0m 13s (- 0m 20s)
Iter: 200, Loss 0.001570, Num updates: 200, Wall time: 272.84, ETA: 0m 16s (- 0m 16s)
Iter: 240, Loss 0.001574, Num updates: 240, Wall time: 275.82, ETA: 0m 19s (- 0m 12s)
Iter: 280, Loss 0.001573, Num updates: 280, Wall time: 278.45, ETA: 0m 21s (- 0m 9s)
Iter: 320, Loss 0.001572, Num updates: 320, Wall time: 281.29, ETA: 0m 24s (- 0m 6s)
Iter: 360, Loss 0.001573, Num updates: 360, Wall time: 284.27, ETA: 0m 27s (- 0m 3s)
Iter: 400, Loss 0.001571, Num updates: 400, Wall time: 287.14, ETA: 0m 30s (- 0m 0s)
Evaluating...
epoch 8, time: 31.34
	train_loss: 0.0016, score: 23.40
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001481, Num updates: 40, Wall time: 291.63, ETA: 0m 3s (- 0m 32s)
Iter: 80, Loss 0.001507, Num updates: 80, Wall time: 294.41, ETA: 0m 6s (- 0m 25s)
Iter: 120, Loss 0.001520, Num updates: 120, Wall time: 297.21, ETA: 0m 9s (- 0m 21s)
Iter: 160, Loss 0.001538, Num updates: 160, Wall time: 300.29, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001546, Num updates: 200, Wall time: 303.24, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001550, Num updates: 240, Wall time: 306.23, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001557, Num updates: 280, Wall time: 309.22, ETA: 0m 21s (- 0m 9s)
Iter: 320, Loss 0.001557, Num updates: 320, Wall time: 311.64, ETA: 0m 23s (- 0m 5s)
Iter: 360, Loss 0.001558, Num updates: 360, Wall time: 314.57, ETA: 0m 26s (- 0m 3s)
Iter: 400, Loss 0.001555, Num updates: 400, Wall time: 317.56, ETA: 0m 29s (- 0m 0s)
Evaluating...
epoch 9, time: 30.22
	train_loss: 0.0016, score: 23.98
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001482, Num updates: 40, Wall time: 321.91, ETA: 0m 3s (- 0m 31s)
Iter: 80, Loss 0.001513, Num updates: 80, Wall time: 324.74, ETA: 0m 6s (- 0m 25s)
Iter: 120, Loss 0.001515, Num updates: 120, Wall time: 327.66, ETA: 0m 9s (- 0m 21s)
Iter: 160, Loss 0.001521, Num updates: 160, Wall time: 330.57, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001537, Num updates: 200, Wall time: 333.44, ETA: 0m 14s (- 0m 15s)
Iter: 240, Loss 0.001533, Num updates: 240, Wall time: 336.23, ETA: 0m 17s (- 0m 11s)
Iter: 280, Loss 0.001536, Num updates: 280, Wall time: 339.15, ETA: 0m 20s (- 0m 8s)
Iter: 320, Loss 0.001538, Num updates: 320, Wall time: 342.10, ETA: 0m 23s (- 0m 5s)
Iter: 360, Loss 0.001534, Num updates: 360, Wall time: 345.11, ETA: 0m 26s (- 0m 3s)
Iter: 400, Loss 0.001538, Num updates: 400, Wall time: 347.82, ETA: 0m 29s (- 0m 0s)
Evaluating...
epoch 10, time: 30.13
	train_loss: 0.0015, score: 24.36
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001508, Num updates: 40, Wall time: 352.61, ETA: 0m 3s (- 0m 35s)
Iter: 80, Loss 0.001519, Num updates: 80, Wall time: 355.48, ETA: 0m 6s (- 0m 27s)
Iter: 120, Loss 0.001527, Num updates: 120, Wall time: 358.39, ETA: 0m 9s (- 0m 22s)
Iter: 160, Loss 0.001517, Num updates: 160, Wall time: 361.38, ETA: 0m 12s (- 0m 19s)
Iter: 200, Loss 0.001513, Num updates: 200, Wall time: 364.07, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001518, Num updates: 240, Wall time: 367.13, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001521, Num updates: 280, Wall time: 370.10, ETA: 0m 21s (- 0m 9s)
Iter: 320, Loss 0.001515, Num updates: 320, Wall time: 373.04, ETA: 0m 24s (- 0m 6s)
Iter: 360, Loss 0.001516, Num updates: 360, Wall time: 376.03, ETA: 0m 27s (- 0m 3s)
Iter: 400, Loss 0.001519, Num updates: 400, Wall time: 378.87, ETA: 0m 30s (- 0m 0s)
Evaluating...
epoch 11, time: 30.84
	train_loss: 0.0015, score: 24.22
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001475, Num updates: 40, Wall time: 383.50, ETA: 0m 3s (- 0m 34s)
Iter: 80, Loss 0.001484, Num updates: 80, Wall time: 386.41, ETA: 0m 6s (- 0m 26s)
Iter: 120, Loss 0.001483, Num updates: 120, Wall time: 389.20, ETA: 0m 9s (- 0m 22s)
Iter: 160, Loss 0.001478, Num updates: 160, Wall time: 392.08, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001487, Num updates: 200, Wall time: 395.08, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001489, Num updates: 240, Wall time: 397.96, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001495, Num updates: 280, Wall time: 400.81, ETA: 0m 20s (- 0m 9s)
Iter: 320, Loss 0.001498, Num updates: 320, Wall time: 403.82, ETA: 0m 24s (- 0m 6s)
Iter: 360, Loss 0.001500, Num updates: 360, Wall time: 406.80, ETA: 0m 26s (- 0m 3s)
Iter: 400, Loss 0.001504, Num updates: 400, Wall time: 409.57, ETA: 0m 29s (- 0m 0s)
Evaluating...
epoch 12, time: 30.51
	train_loss: 0.0015, score: 24.05
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001435, Num updates: 40, Wall time: 414.02, ETA: 0m 3s (- 0m 32s)
Iter: 80, Loss 0.001443, Num updates: 80, Wall time: 416.96, ETA: 0m 6s (- 0m 26s)
Iter: 120, Loss 0.001461, Num updates: 120, Wall time: 419.96, ETA: 0m 9s (- 0m 22s)
Iter: 160, Loss 0.001470, Num updates: 160, Wall time: 422.77, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001480, Num updates: 200, Wall time: 425.46, ETA: 0m 14s (- 0m 15s)
Iter: 240, Loss 0.001478, Num updates: 240, Wall time: 428.15, ETA: 0m 17s (- 0m 11s)
Iter: 280, Loss 0.001480, Num updates: 280, Wall time: 430.89, ETA: 0m 20s (- 0m 8s)
Iter: 320, Loss 0.001482, Num updates: 320, Wall time: 433.65, ETA: 0m 23s (- 0m 5s)
Iter: 360, Loss 0.001482, Num updates: 360, Wall time: 436.46, ETA: 0m 25s (- 0m 2s)
Iter: 400, Loss 0.001487, Num updates: 400, Wall time: 439.04, ETA: 0m 28s (- 0m 0s)
Evaluating...
epoch 13, time: 29.21
	train_loss: 0.0015, score: 24.52
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001467, Num updates: 40, Wall time: 443.53, ETA: 0m 3s (- 0m 33s)
Iter: 80, Loss 0.001449, Num updates: 80, Wall time: 446.11, ETA: 0m 6s (- 0m 25s)
Iter: 120, Loss 0.001446, Num updates: 120, Wall time: 449.07, ETA: 0m 9s (- 0m 21s)
Iter: 160, Loss 0.001447, Num updates: 160, Wall time: 452.00, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001452, Num updates: 200, Wall time: 454.80, ETA: 0m 14s (- 0m 15s)
Iter: 240, Loss 0.001454, Num updates: 240, Wall time: 457.76, ETA: 0m 17s (- 0m 12s)
Iter: 280, Loss 0.001463, Num updates: 280, Wall time: 460.65, ETA: 0m 20s (- 0m 8s)
Iter: 320, Loss 0.001462, Num updates: 320, Wall time: 463.56, ETA: 0m 23s (- 0m 5s)
Iter: 360, Loss 0.001466, Num updates: 360, Wall time: 466.46, ETA: 0m 26s (- 0m 3s)
Iter: 400, Loss 0.001465, Num updates: 400, Wall time: 469.21, ETA: 0m 29s (- 0m 0s)
Evaluating...
epoch 14, time: 29.90
	train_loss: 0.0015, score: 25.58
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001478, Num updates: 40, Wall time: 473.62, ETA: 0m 3s (- 0m 33s)
Iter: 80, Loss 0.001456, Num updates: 80, Wall time: 476.49, ETA: 0m 6s (- 0m 26s)
Iter: 120, Loss 0.001453, Num updates: 120, Wall time: 479.33, ETA: 0m 9s (- 0m 21s)
Iter: 160, Loss 0.001456, Num updates: 160, Wall time: 482.28, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001458, Num updates: 200, Wall time: 485.15, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001462, Num updates: 240, Wall time: 487.99, ETA: 0m 17s (- 0m 12s)
Iter: 280, Loss 0.001461, Num updates: 280, Wall time: 490.85, ETA: 0m 20s (- 0m 9s)
Iter: 320, Loss 0.001456, Num updates: 320, Wall time: 493.99, ETA: 0m 23s (- 0m 6s)
Iter: 360, Loss 0.001452, Num updates: 360, Wall time: 496.84, ETA: 0m 26s (- 0m 3s)
Iter: 400, Loss 0.001451, Num updates: 400, Wall time: 499.65, ETA: 0m 29s (- 0m 0s)
Evaluating...
epoch 15, time: 30.33
	train_loss: 0.0015, score: 25.22
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001392, Num updates: 40, Wall time: 504.30, ETA: 0m 3s (- 0m 34s)
Iter: 80, Loss 0.001408, Num updates: 80, Wall time: 507.06, ETA: 0m 6s (- 0m 26s)
Iter: 120, Loss 0.001410, Num updates: 120, Wall time: 510.00, ETA: 0m 9s (- 0m 22s)
Iter: 160, Loss 0.001419, Num updates: 160, Wall time: 512.93, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001424, Num updates: 200, Wall time: 515.85, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001427, Num updates: 240, Wall time: 518.63, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001428, Num updates: 280, Wall time: 521.54, ETA: 0m 20s (- 0m 9s)
Iter: 320, Loss 0.001432, Num updates: 320, Wall time: 524.32, ETA: 0m 23s (- 0m 6s)
Iter: 360, Loss 0.001435, Num updates: 360, Wall time: 527.17, ETA: 0m 26s (- 0m 3s)
Iter: 400, Loss 0.001433, Num updates: 400, Wall time: 529.79, ETA: 0m 29s (- 0m 0s)
Evaluating...
epoch 16, time: 29.91
	train_loss: 0.0014, score: 24.64
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001356, Num updates: 40, Wall time: 534.33, ETA: 0m 3s (- 0m 34s)
Iter: 80, Loss 0.001383, Num updates: 80, Wall time: 537.28, ETA: 0m 6s (- 0m 26s)
Iter: 120, Loss 0.001393, Num updates: 120, Wall time: 540.21, ETA: 0m 9s (- 0m 22s)
Iter: 160, Loss 0.001402, Num updates: 160, Wall time: 543.19, ETA: 0m 12s (- 0m 19s)
Iter: 200, Loss 0.001402, Num updates: 200, Wall time: 546.35, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001407, Num updates: 240, Wall time: 549.25, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001404, Num updates: 280, Wall time: 552.17, ETA: 0m 21s (- 0m 9s)
Iter: 320, Loss 0.001407, Num updates: 320, Wall time: 554.98, ETA: 0m 24s (- 0m 6s)
Iter: 360, Loss 0.001412, Num updates: 360, Wall time: 558.06, ETA: 0m 27s (- 0m 3s)
Iter: 400, Loss 0.001413, Num updates: 400, Wall time: 560.82, ETA: 0m 30s (- 0m 0s)
Evaluating...
epoch 17, time: 30.93
	train_loss: 0.0014, score: 25.88
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001377, Num updates: 40, Wall time: 565.66, ETA: 0m 3s (- 0m 35s)
Iter: 80, Loss 0.001378, Num updates: 80, Wall time: 568.49, ETA: 0m 6s (- 0m 27s)
Iter: 120, Loss 0.001386, Num updates: 120, Wall time: 571.26, ETA: 0m 9s (- 0m 22s)
Iter: 160, Loss 0.001393, Num updates: 160, Wall time: 574.13, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001394, Num updates: 200, Wall time: 576.76, ETA: 0m 14s (- 0m 15s)
Iter: 240, Loss 0.001393, Num updates: 240, Wall time: 579.64, ETA: 0m 17s (- 0m 12s)
Iter: 280, Loss 0.001396, Num updates: 280, Wall time: 582.48, ETA: 0m 20s (- 0m 8s)
Iter: 320, Loss 0.001394, Num updates: 320, Wall time: 585.35, ETA: 0m 23s (- 0m 5s)
Iter: 360, Loss 0.001398, Num updates: 360, Wall time: 588.16, ETA: 0m 26s (- 0m 3s)
Iter: 400, Loss 0.001399, Num updates: 400, Wall time: 590.76, ETA: 0m 28s (- 0m 0s)
Evaluating...
epoch 18, time: 29.67
	train_loss: 0.0014, score: 26.22
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001338, Num updates: 40, Wall time: 595.69, ETA: 0m 3s (- 0m 36s)
Iter: 80, Loss 0.001356, Num updates: 80, Wall time: 598.56, ETA: 0m 6s (- 0m 27s)
Iter: 120, Loss 0.001368, Num updates: 120, Wall time: 601.49, ETA: 0m 9s (- 0m 23s)
Iter: 160, Loss 0.001374, Num updates: 160, Wall time: 604.38, ETA: 0m 12s (- 0m 19s)
Iter: 200, Loss 0.001374, Num updates: 200, Wall time: 607.13, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001377, Num updates: 240, Wall time: 610.06, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001383, Num updates: 280, Wall time: 612.90, ETA: 0m 21s (- 0m 9s)
Iter: 320, Loss 0.001385, Num updates: 320, Wall time: 615.51, ETA: 0m 23s (- 0m 6s)
Iter: 360, Loss 0.001388, Num updates: 360, Wall time: 618.51, ETA: 0m 26s (- 0m 3s)
Iter: 400, Loss 0.001385, Num updates: 400, Wall time: 621.43, ETA: 0m 29s (- 0m 0s)
Evaluating...
epoch 19, time: 30.35
	train_loss: 0.0014, score: 25.86
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001317, Num updates: 40, Wall time: 625.84, ETA: 0m 3s (- 0m 33s)
Iter: 80, Loss 0.001344, Num updates: 80, Wall time: 628.74, ETA: 0m 6s (- 0m 26s)
Iter: 120, Loss 0.001358, Num updates: 120, Wall time: 631.64, ETA: 0m 9s (- 0m 22s)
Iter: 160, Loss 0.001359, Num updates: 160, Wall time: 634.63, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001358, Num updates: 200, Wall time: 637.55, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001361, Num updates: 240, Wall time: 640.51, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001362, Num updates: 280, Wall time: 643.36, ETA: 0m 21s (- 0m 9s)
Iter: 320, Loss 0.001363, Num updates: 320, Wall time: 646.25, ETA: 0m 24s (- 0m 6s)
Iter: 360, Loss 0.001367, Num updates: 360, Wall time: 649.25, ETA: 0m 27s (- 0m 3s)
Iter: 400, Loss 0.001367, Num updates: 400, Wall time: 652.05, ETA: 0m 29s (- 0m 0s)
Evaluating...
epoch 20, time: 30.56
	train_loss: 0.0014, score: 26.00
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001339, Num updates: 40, Wall time: 656.64, ETA: 0m 3s (- 0m 33s)
Iter: 80, Loss 0.001337, Num updates: 80, Wall time: 659.58, ETA: 0m 6s (- 0m 26s)
Iter: 120, Loss 0.001338, Num updates: 120, Wall time: 662.46, ETA: 0m 9s (- 0m 22s)
Iter: 160, Loss 0.001339, Num updates: 160, Wall time: 665.22, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001336, Num updates: 200, Wall time: 667.94, ETA: 0m 14s (- 0m 15s)
Iter: 240, Loss 0.001347, Num updates: 240, Wall time: 670.77, ETA: 0m 17s (- 0m 11s)
Iter: 280, Loss 0.001352, Num updates: 280, Wall time: 673.48, ETA: 0m 20s (- 0m 8s)
Iter: 320, Loss 0.001350, Num updates: 320, Wall time: 676.32, ETA: 0m 23s (- 0m 5s)
Iter: 360, Loss 0.001351, Num updates: 360, Wall time: 679.16, ETA: 0m 26s (- 0m 2s)
Iter: 400, Loss 0.001354, Num updates: 400, Wall time: 681.87, ETA: 0m 28s (- 0m 0s)
Evaluating...
epoch 21, time: 29.62
	train_loss: 0.0014, score: 26.69
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001299, Num updates: 40, Wall time: 686.54, ETA: 0m 3s (- 0m 34s)
Iter: 80, Loss 0.001321, Num updates: 80, Wall time: 689.37, ETA: 0m 6s (- 0m 26s)
Iter: 120, Loss 0.001330, Num updates: 120, Wall time: 692.10, ETA: 0m 9s (- 0m 21s)
Iter: 160, Loss 0.001329, Num updates: 160, Wall time: 694.97, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001332, Num updates: 200, Wall time: 697.67, ETA: 0m 14s (- 0m 15s)
Iter: 240, Loss 0.001337, Num updates: 240, Wall time: 700.43, ETA: 0m 17s (- 0m 11s)
Iter: 280, Loss 0.001340, Num updates: 280, Wall time: 703.30, ETA: 0m 20s (- 0m 8s)
Iter: 320, Loss 0.001336, Num updates: 320, Wall time: 706.18, ETA: 0m 23s (- 0m 5s)
Iter: 360, Loss 0.001338, Num updates: 360, Wall time: 709.14, ETA: 0m 26s (- 0m 3s)
Iter: 400, Loss 0.001340, Num updates: 400, Wall time: 711.87, ETA: 0m 29s (- 0m 0s)
Evaluating...
epoch 22, time: 29.83
	train_loss: 0.0013, score: 26.23
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001293, Num updates: 40, Wall time: 716.47, ETA: 0m 3s (- 0m 33s)
Iter: 80, Loss 0.001314, Num updates: 80, Wall time: 719.28, ETA: 0m 6s (- 0m 26s)
Iter: 120, Loss 0.001316, Num updates: 120, Wall time: 722.08, ETA: 0m 9s (- 0m 21s)
Iter: 160, Loss 0.001314, Num updates: 160, Wall time: 724.78, ETA: 0m 11s (- 0m 18s)
Iter: 200, Loss 0.001317, Num updates: 200, Wall time: 727.58, ETA: 0m 14s (- 0m 14s)
Iter: 240, Loss 0.001318, Num updates: 240, Wall time: 730.75, ETA: 0m 17s (- 0m 12s)
Iter: 280, Loss 0.001321, Num updates: 280, Wall time: 733.70, ETA: 0m 20s (- 0m 9s)
Iter: 320, Loss 0.001325, Num updates: 320, Wall time: 736.59, ETA: 0m 23s (- 0m 6s)
Iter: 360, Loss 0.001326, Num updates: 360, Wall time: 739.55, ETA: 0m 26s (- 0m 3s)
Iter: 400, Loss 0.001327, Num updates: 400, Wall time: 742.35, ETA: 0m 29s (- 0m 0s)
Evaluating...
epoch 23, time: 30.28
	train_loss: 0.0013, score: 27.07
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001241, Num updates: 40, Wall time: 746.97, ETA: 0m 3s (- 0m 34s)
Iter: 80, Loss 0.001286, Num updates: 80, Wall time: 750.00, ETA: 0m 6s (- 0m 27s)
Iter: 120, Loss 0.001293, Num updates: 120, Wall time: 752.95, ETA: 0m 9s (- 0m 22s)
Iter: 160, Loss 0.001304, Num updates: 160, Wall time: 755.80, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001303, Num updates: 200, Wall time: 758.70, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001308, Num updates: 240, Wall time: 761.50, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001311, Num updates: 280, Wall time: 764.30, ETA: 0m 21s (- 0m 9s)
Iter: 320, Loss 0.001313, Num updates: 320, Wall time: 767.12, ETA: 0m 23s (- 0m 6s)
Iter: 360, Loss 0.001318, Num updates: 360, Wall time: 770.06, ETA: 0m 26s (- 0m 3s)
Iter: 400, Loss 0.001317, Num updates: 400, Wall time: 772.76, ETA: 0m 29s (- 0m 0s)
Evaluating...
epoch 24, time: 30.26
	train_loss: 0.0013, score: 27.64
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001242, Num updates: 40, Wall time: 777.41, ETA: 0m 3s (- 0m 33s)
Iter: 80, Loss 0.001273, Num updates: 80, Wall time: 780.35, ETA: 0m 6s (- 0m 26s)
Iter: 120, Loss 0.001275, Num updates: 120, Wall time: 783.23, ETA: 0m 9s (- 0m 22s)
Iter: 160, Loss 0.001287, Num updates: 160, Wall time: 786.09, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001293, Num updates: 200, Wall time: 789.02, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001293, Num updates: 240, Wall time: 791.89, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001295, Num updates: 280, Wall time: 794.80, ETA: 0m 21s (- 0m 9s)
Iter: 320, Loss 0.001298, Num updates: 320, Wall time: 797.71, ETA: 0m 23s (- 0m 6s)
Iter: 360, Loss 0.001301, Num updates: 360, Wall time: 800.58, ETA: 0m 26s (- 0m 3s)
Iter: 400, Loss 0.001306, Num updates: 400, Wall time: 803.39, ETA: 0m 29s (- 0m 0s)
Evaluating...
epoch 25, time: 30.34
	train_loss: 0.0013, score: 27.19
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001259, Num updates: 40, Wall time: 807.92, ETA: 0m 3s (- 0m 33s)
Iter: 80, Loss 0.001284, Num updates: 80, Wall time: 810.64, ETA: 0m 6s (- 0m 25s)
Iter: 120, Loss 0.001293, Num updates: 120, Wall time: 813.40, ETA: 0m 9s (- 0m 21s)
Iter: 160, Loss 0.001285, Num updates: 160, Wall time: 816.22, ETA: 0m 11s (- 0m 18s)
Iter: 200, Loss 0.001289, Num updates: 200, Wall time: 819.02, ETA: 0m 14s (- 0m 14s)
Iter: 240, Loss 0.001290, Num updates: 240, Wall time: 821.80, ETA: 0m 17s (- 0m 11s)
Iter: 280, Loss 0.001291, Num updates: 280, Wall time: 824.64, ETA: 0m 20s (- 0m 8s)
Iter: 320, Loss 0.001289, Num updates: 320, Wall time: 827.62, ETA: 0m 23s (- 0m 5s)
Iter: 360, Loss 0.001290, Num updates: 360, Wall time: 830.47, ETA: 0m 26s (- 0m 2s)
Iter: 400, Loss 0.001293, Num updates: 400, Wall time: 833.31, ETA: 0m 29s (- 0m 0s)
Evaluating...
epoch 26, time: 29.76
	train_loss: 0.0013, score: 27.94
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001223, Num updates: 40, Wall time: 837.76, ETA: 0m 3s (- 0m 32s)
Iter: 80, Loss 0.001253, Num updates: 80, Wall time: 840.65, ETA: 0m 6s (- 0m 26s)
Iter: 120, Loss 0.001254, Num updates: 120, Wall time: 843.52, ETA: 0m 9s (- 0m 22s)
Iter: 160, Loss 0.001261, Num updates: 160, Wall time: 846.38, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001266, Num updates: 200, Wall time: 849.22, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001275, Num updates: 240, Wall time: 852.28, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001281, Num updates: 280, Wall time: 855.17, ETA: 0m 20s (- 0m 9s)
Iter: 320, Loss 0.001283, Num updates: 320, Wall time: 858.05, ETA: 0m 23s (- 0m 6s)
Iter: 360, Loss 0.001282, Num updates: 360, Wall time: 860.85, ETA: 0m 26s (- 0m 3s)
Iter: 400, Loss 0.001284, Num updates: 400, Wall time: 863.59, ETA: 0m 29s (- 0m 0s)
Evaluating...
epoch 27, time: 30.11
	train_loss: 0.0013, score: 27.15
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001222, Num updates: 40, Wall time: 868.19, ETA: 0m 3s (- 0m 33s)
Iter: 80, Loss 0.001224, Num updates: 80, Wall time: 871.00, ETA: 0m 6s (- 0m 26s)
Iter: 120, Loss 0.001242, Num updates: 120, Wall time: 873.79, ETA: 0m 9s (- 0m 21s)
Iter: 160, Loss 0.001248, Num updates: 160, Wall time: 876.55, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001259, Num updates: 200, Wall time: 879.50, ETA: 0m 14s (- 0m 15s)
Iter: 240, Loss 0.001264, Num updates: 240, Wall time: 882.47, ETA: 0m 17s (- 0m 12s)
Iter: 280, Loss 0.001263, Num updates: 280, Wall time: 885.37, ETA: 0m 20s (- 0m 9s)
Iter: 320, Loss 0.001270, Num updates: 320, Wall time: 888.22, ETA: 0m 23s (- 0m 6s)
Iter: 360, Loss 0.001273, Num updates: 360, Wall time: 891.16, ETA: 0m 26s (- 0m 3s)
Iter: 400, Loss 0.001276, Num updates: 400, Wall time: 894.00, ETA: 0m 29s (- 0m 0s)
Evaluating...
epoch 28, time: 30.21
	train_loss: 0.0013, score: 27.90
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001228, Num updates: 40, Wall time: 898.69, ETA: 0m 3s (- 0m 34s)
Iter: 80, Loss 0.001234, Num updates: 80, Wall time: 901.70, ETA: 0m 6s (- 0m 27s)
Iter: 120, Loss 0.001244, Num updates: 120, Wall time: 904.70, ETA: 0m 9s (- 0m 23s)
Iter: 160, Loss 0.001255, Num updates: 160, Wall time: 907.47, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001250, Num updates: 200, Wall time: 910.52, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001252, Num updates: 240, Wall time: 913.50, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001257, Num updates: 280, Wall time: 916.38, ETA: 0m 21s (- 0m 9s)
Iter: 320, Loss 0.001256, Num updates: 320, Wall time: 919.44, ETA: 0m 24s (- 0m 6s)
Iter: 360, Loss 0.001261, Num updates: 360, Wall time: 922.38, ETA: 0m 27s (- 0m 3s)
Iter: 400, Loss 0.001265, Num updates: 400, Wall time: 925.30, ETA: 0m 30s (- 0m 0s)
Evaluating...
epoch 29, time: 31.08
	train_loss: 0.0013, score: 28.58
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001201, Num updates: 40, Wall time: 929.74, ETA: 0m 3s (- 0m 32s)
Iter: 80, Loss 0.001213, Num updates: 80, Wall time: 932.62, ETA: 0m 6s (- 0m 25s)
Iter: 120, Loss 0.001229, Num updates: 120, Wall time: 935.45, ETA: 0m 9s (- 0m 21s)
Iter: 160, Loss 0.001234, Num updates: 160, Wall time: 938.45, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001240, Num updates: 200, Wall time: 941.34, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001250, Num updates: 240, Wall time: 945.12, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001250, Num updates: 280, Wall time: 948.02, ETA: 0m 21s (- 0m 9s)
Iter: 320, Loss 0.001253, Num updates: 320, Wall time: 951.10, ETA: 0m 24s (- 0m 6s)
Iter: 360, Loss 0.001253, Num updates: 360, Wall time: 954.65, ETA: 0m 28s (- 0m 3s)
Iter: 400, Loss 0.001258, Num updates: 400, Wall time: 957.47, ETA: 0m 31s (- 0m 0s)
Evaluating...
epoch 30, time: 31.97
	train_loss: 0.0013, score: 27.46
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001215, Num updates: 40, Wall time: 962.08, ETA: 0m 3s (- 0m 34s)
Iter: 80, Loss 0.001235, Num updates: 80, Wall time: 964.94, ETA: 0m 6s (- 0m 26s)
Iter: 120, Loss 0.001237, Num updates: 120, Wall time: 967.76, ETA: 0m 9s (- 0m 22s)
Iter: 160, Loss 0.001247, Num updates: 160, Wall time: 970.65, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001255, Num updates: 200, Wall time: 973.54, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001256, Num updates: 240, Wall time: 976.60, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001251, Num updates: 280, Wall time: 979.53, ETA: 0m 21s (- 0m 9s)
Iter: 320, Loss 0.001251, Num updates: 320, Wall time: 982.71, ETA: 0m 24s (- 0m 6s)
Iter: 360, Loss 0.001249, Num updates: 360, Wall time: 985.58, ETA: 0m 27s (- 0m 3s)
Iter: 400, Loss 0.001251, Num updates: 400, Wall time: 988.48, ETA: 0m 30s (- 0m 0s)
Evaluating...
epoch 31, time: 30.78
	train_loss: 0.0013, score: 27.65
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001201, Num updates: 40, Wall time: 992.94, ETA: 0m 3s (- 0m 33s)
Iter: 80, Loss 0.001216, Num updates: 80, Wall time: 995.94, ETA: 0m 6s (- 0m 26s)
Iter: 120, Loss 0.001222, Num updates: 120, Wall time: 998.79, ETA: 0m 9s (- 0m 22s)
Iter: 160, Loss 0.001224, Num updates: 160, Wall time: 1001.77, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001227, Num updates: 200, Wall time: 1004.59, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001237, Num updates: 240, Wall time: 1007.51, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001239, Num updates: 280, Wall time: 1010.33, ETA: 0m 20s (- 0m 9s)
Iter: 320, Loss 0.001239, Num updates: 320, Wall time: 1013.23, ETA: 0m 23s (- 0m 6s)
Iter: 360, Loss 0.001239, Num updates: 360, Wall time: 1016.10, ETA: 0m 26s (- 0m 3s)
Iter: 400, Loss 0.001241, Num updates: 400, Wall time: 1018.66, ETA: 0m 29s (- 0m 0s)
Evaluating...
epoch 32, time: 30.21
	train_loss: 0.0012, score: 28.31
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001198, Num updates: 40, Wall time: 1023.23, ETA: 0m 3s (- 0m 32s)
Iter: 80, Loss 0.001205, Num updates: 80, Wall time: 1026.17, ETA: 0m 6s (- 0m 26s)
Iter: 120, Loss 0.001211, Num updates: 120, Wall time: 1028.87, ETA: 0m 9s (- 0m 21s)
Iter: 160, Loss 0.001213, Num updates: 160, Wall time: 1031.63, ETA: 0m 11s (- 0m 18s)
Iter: 200, Loss 0.001222, Num updates: 200, Wall time: 1034.37, ETA: 0m 14s (- 0m 14s)
Iter: 240, Loss 0.001225, Num updates: 240, Wall time: 1037.25, ETA: 0m 17s (- 0m 11s)
Iter: 280, Loss 0.001228, Num updates: 280, Wall time: 1040.22, ETA: 0m 20s (- 0m 8s)
Iter: 320, Loss 0.001230, Num updates: 320, Wall time: 1042.87, ETA: 0m 23s (- 0m 5s)
Iter: 360, Loss 0.001232, Num updates: 360, Wall time: 1046.86, ETA: 0m 27s (- 0m 3s)
Iter: 400, Loss 0.001235, Num updates: 400, Wall time: 1051.09, ETA: 0m 31s (- 0m 0s)
Evaluating...
epoch 33, time: 32.37
	train_loss: 0.0012, score: 27.62
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001214, Num updates: 40, Wall time: 1057.03, ETA: 0m 4s (- 0m 44s)
Iter: 80, Loss 0.001214, Num updates: 80, Wall time: 1059.97, ETA: 0m 7s (- 0m 31s)
Iter: 120, Loss 0.001209, Num updates: 120, Wall time: 1062.72, ETA: 0m 10s (- 0m 24s)
Iter: 160, Loss 0.001208, Num updates: 160, Wall time: 1065.95, ETA: 0m 13s (- 0m 20s)
Iter: 200, Loss 0.001210, Num updates: 200, Wall time: 1068.89, ETA: 0m 16s (- 0m 16s)
Iter: 240, Loss 0.001210, Num updates: 240, Wall time: 1071.60, ETA: 0m 19s (- 0m 13s)
Iter: 280, Loss 0.001217, Num updates: 280, Wall time: 1074.48, ETA: 0m 22s (- 0m 9s)
Iter: 320, Loss 0.001216, Num updates: 320, Wall time: 1077.26, ETA: 0m 24s (- 0m 6s)
Iter: 360, Loss 0.001221, Num updates: 360, Wall time: 1080.14, ETA: 0m 27s (- 0m 3s)
Iter: 400, Loss 0.001224, Num updates: 400, Wall time: 1082.89, ETA: 0m 30s (- 0m 0s)
Evaluating...
epoch 34, time: 31.45
	train_loss: 0.0012, score: 28.04
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001151, Num updates: 40, Wall time: 1087.88, ETA: 0m 3s (- 0m 36s)
Iter: 80, Loss 0.001184, Num updates: 80, Wall time: 1091.21, ETA: 0m 7s (- 0m 29s)
Iter: 120, Loss 0.001196, Num updates: 120, Wall time: 1094.15, ETA: 0m 10s (- 0m 24s)
Iter: 160, Loss 0.001204, Num updates: 160, Wall time: 1096.97, ETA: 0m 13s (- 0m 19s)
Iter: 200, Loss 0.001205, Num updates: 200, Wall time: 1099.71, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001208, Num updates: 240, Wall time: 1102.56, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001209, Num updates: 280, Wall time: 1105.30, ETA: 0m 21s (- 0m 9s)
Iter: 320, Loss 0.001214, Num updates: 320, Wall time: 1108.20, ETA: 0m 24s (- 0m 6s)
Iter: 360, Loss 0.001218, Num updates: 360, Wall time: 1111.01, ETA: 0m 27s (- 0m 3s)
Iter: 400, Loss 0.001219, Num updates: 400, Wall time: 1113.78, ETA: 0m 29s (- 0m 0s)
Evaluating...
epoch 35, time: 30.58
	train_loss: 0.0012, score: 28.66
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001163, Num updates: 40, Wall time: 1118.74, ETA: 0m 4s (- 0m 37s)
Iter: 80, Loss 0.001184, Num updates: 80, Wall time: 1121.57, ETA: 0m 6s (- 0m 27s)
Iter: 120, Loss 0.001205, Num updates: 120, Wall time: 1124.41, ETA: 0m 9s (- 0m 22s)
Iter: 160, Loss 0.001205, Num updates: 160, Wall time: 1127.24, ETA: 0m 12s (- 0m 19s)
Iter: 200, Loss 0.001208, Num updates: 200, Wall time: 1130.01, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001212, Num updates: 240, Wall time: 1132.97, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001214, Num updates: 280, Wall time: 1135.97, ETA: 0m 21s (- 0m 9s)
Iter: 320, Loss 0.001215, Num updates: 320, Wall time: 1138.75, ETA: 0m 24s (- 0m 6s)
Iter: 360, Loss 0.001213, Num updates: 360, Wall time: 1141.77, ETA: 0m 27s (- 0m 3s)
Iter: 400, Loss 0.001214, Num updates: 400, Wall time: 1144.77, ETA: 0m 30s (- 0m 0s)
Evaluating...
epoch 36, time: 30.75
	train_loss: 0.0012, score: 27.85
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001158, Num updates: 40, Wall time: 1149.88, ETA: 0m 4s (- 0m 39s)
Iter: 80, Loss 0.001185, Num updates: 80, Wall time: 1152.79, ETA: 0m 7s (- 0m 29s)
Iter: 120, Loss 0.001184, Num updates: 120, Wall time: 1155.64, ETA: 0m 10s (- 0m 23s)
Iter: 160, Loss 0.001188, Num updates: 160, Wall time: 1158.52, ETA: 0m 12s (- 0m 19s)
Iter: 200, Loss 0.001195, Num updates: 200, Wall time: 1161.61, ETA: 0m 15s (- 0m 16s)
Iter: 240, Loss 0.001197, Num updates: 240, Wall time: 1164.53, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001202, Num updates: 280, Wall time: 1167.44, ETA: 0m 21s (- 0m 9s)
Iter: 320, Loss 0.001201, Num updates: 320, Wall time: 1170.58, ETA: 0m 24s (- 0m 6s)
Iter: 360, Loss 0.001205, Num updates: 360, Wall time: 1173.75, ETA: 0m 28s (- 0m 3s)
Iter: 400, Loss 0.001206, Num updates: 400, Wall time: 1176.58, ETA: 0m 30s (- 0m 0s)
Evaluating...
epoch 37, time: 31.74
	train_loss: 0.0012, score: 27.82
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001144, Num updates: 40, Wall time: 1181.81, ETA: 0m 4s (- 0m 39s)
Iter: 80, Loss 0.001166, Num updates: 80, Wall time: 1184.61, ETA: 0m 7s (- 0m 28s)
Iter: 120, Loss 0.001176, Num updates: 120, Wall time: 1187.51, ETA: 0m 9s (- 0m 23s)
Iter: 160, Loss 0.001180, Num updates: 160, Wall time: 1190.37, ETA: 0m 12s (- 0m 19s)
Iter: 200, Loss 0.001187, Num updates: 200, Wall time: 1193.22, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001189, Num updates: 240, Wall time: 1196.00, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001194, Num updates: 280, Wall time: 1198.92, ETA: 0m 21s (- 0m 9s)
Iter: 320, Loss 0.001193, Num updates: 320, Wall time: 1201.70, ETA: 0m 24s (- 0m 6s)
Iter: 360, Loss 0.001195, Num updates: 360, Wall time: 1204.57, ETA: 0m 27s (- 0m 3s)
Iter: 400, Loss 0.001196, Num updates: 400, Wall time: 1207.19, ETA: 0m 29s (- 0m 0s)
Evaluating...
epoch 38, time: 30.37
	train_loss: 0.0012, score: 28.26
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001179, Num updates: 40, Wall time: 1211.71, ETA: 0m 3s (- 0m 33s)
Iter: 80, Loss 0.001177, Num updates: 80, Wall time: 1214.66, ETA: 0m 6s (- 0m 26s)
Iter: 120, Loss 0.001180, Num updates: 120, Wall time: 1217.53, ETA: 0m 9s (- 0m 22s)
Iter: 160, Loss 0.001182, Num updates: 160, Wall time: 1220.55, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001181, Num updates: 200, Wall time: 1223.56, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001187, Num updates: 240, Wall time: 1226.45, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001192, Num updates: 280, Wall time: 1229.31, ETA: 0m 21s (- 0m 9s)
Iter: 320, Loss 0.001193, Num updates: 320, Wall time: 1232.21, ETA: 0m 24s (- 0m 6s)
Iter: 360, Loss 0.001194, Num updates: 360, Wall time: 1235.06, ETA: 0m 26s (- 0m 3s)
Iter: 400, Loss 0.001195, Num updates: 400, Wall time: 1237.94, ETA: 0m 29s (- 0m 0s)
Evaluating...
epoch 39, time: 30.60
	train_loss: 0.0012, score: 27.66
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001145, Num updates: 40, Wall time: 1242.63, ETA: 0m 3s (- 0m 34s)
Iter: 80, Loss 0.001169, Num updates: 80, Wall time: 1245.70, ETA: 0m 6s (- 0m 27s)
Iter: 120, Loss 0.001184, Num updates: 120, Wall time: 1248.37, ETA: 0m 9s (- 0m 22s)
Iter: 160, Loss 0.001180, Num updates: 160, Wall time: 1251.32, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001179, Num updates: 200, Wall time: 1254.23, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001180, Num updates: 240, Wall time: 1257.14, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001183, Num updates: 280, Wall time: 1260.03, ETA: 0m 21s (- 0m 9s)
Iter: 320, Loss 0.001186, Num updates: 320, Wall time: 1262.92, ETA: 0m 24s (- 0m 6s)
Iter: 360, Loss 0.001190, Num updates: 360, Wall time: 1266.16, ETA: 0m 27s (- 0m 3s)
Iter: 400, Loss 0.001191, Num updates: 400, Wall time: 1268.88, ETA: 0m 29s (- 0m 0s)
Evaluating...
epoch 40, time: 30.71
	train_loss: 0.0012, score: 27.65
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001134, Num updates: 40, Wall time: 1273.60, ETA: 0m 3s (- 0m 34s)
Iter: 80, Loss 0.001168, Num updates: 80, Wall time: 1276.26, ETA: 0m 6s (- 0m 26s)
Iter: 120, Loss 0.001170, Num updates: 120, Wall time: 1279.20, ETA: 0m 9s (- 0m 22s)
Iter: 160, Loss 0.001183, Num updates: 160, Wall time: 1282.01, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001183, Num updates: 200, Wall time: 1284.97, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001185, Num updates: 240, Wall time: 1287.78, ETA: 0m 17s (- 0m 12s)
Iter: 280, Loss 0.001186, Num updates: 280, Wall time: 1290.64, ETA: 0m 20s (- 0m 9s)
Iter: 320, Loss 0.001186, Num updates: 320, Wall time: 1293.51, ETA: 0m 23s (- 0m 6s)
Iter: 360, Loss 0.001186, Num updates: 360, Wall time: 1296.46, ETA: 0m 26s (- 0m 3s)
Iter: 400, Loss 0.001186, Num updates: 400, Wall time: 1299.18, ETA: 0m 29s (- 0m 0s)
Evaluating...
epoch 41, time: 29.85
	train_loss: 0.0012, score: 28.44
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001139, Num updates: 40, Wall time: 1303.65, ETA: 0m 3s (- 0m 35s)
Iter: 80, Loss 0.001159, Num updates: 80, Wall time: 1306.47, ETA: 0m 6s (- 0m 26s)
Iter: 120, Loss 0.001164, Num updates: 120, Wall time: 1309.23, ETA: 0m 9s (- 0m 22s)
Iter: 160, Loss 0.001170, Num updates: 160, Wall time: 1312.07, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001173, Num updates: 200, Wall time: 1315.01, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001174, Num updates: 240, Wall time: 1317.85, ETA: 0m 17s (- 0m 12s)
Iter: 280, Loss 0.001175, Num updates: 280, Wall time: 1320.69, ETA: 0m 20s (- 0m 9s)
Iter: 320, Loss 0.001176, Num updates: 320, Wall time: 1323.74, ETA: 0m 23s (- 0m 6s)
Iter: 360, Loss 0.001177, Num updates: 360, Wall time: 1327.13, ETA: 0m 27s (- 0m 3s)
Iter: 400, Loss 0.001179, Num updates: 400, Wall time: 1330.73, ETA: 0m 30s (- 0m 0s)
Evaluating...
epoch 42, time: 31.79
	train_loss: 0.0012, score: 27.35
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001147, Num updates: 40, Wall time: 1335.76, ETA: 0m 3s (- 0m 36s)
Iter: 80, Loss 0.001156, Num updates: 80, Wall time: 1338.62, ETA: 0m 6s (- 0m 27s)
Iter: 120, Loss 0.001163, Num updates: 120, Wall time: 1341.57, ETA: 0m 9s (- 0m 22s)
Iter: 160, Loss 0.001159, Num updates: 160, Wall time: 1344.41, ETA: 0m 12s (- 0m 19s)
Iter: 200, Loss 0.001166, Num updates: 200, Wall time: 1347.30, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001168, Num updates: 240, Wall time: 1350.23, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001168, Num updates: 280, Wall time: 1353.06, ETA: 0m 21s (- 0m 9s)
Iter: 320, Loss 0.001169, Num updates: 320, Wall time: 1355.94, ETA: 0m 24s (- 0m 6s)
Iter: 360, Loss 0.001170, Num updates: 360, Wall time: 1358.89, ETA: 0m 27s (- 0m 3s)
Iter: 400, Loss 0.001172, Num updates: 400, Wall time: 1362.33, ETA: 0m 30s (- 0m 0s)
Evaluating...
epoch 43, time: 31.29
	train_loss: 0.0012, score: 27.10
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001131, Num updates: 40, Wall time: 1366.98, ETA: 0m 3s (- 0m 34s)
Iter: 80, Loss 0.001157, Num updates: 80, Wall time: 1369.77, ETA: 0m 6s (- 0m 26s)
Iter: 120, Loss 0.001141, Num updates: 120, Wall time: 1372.39, ETA: 0m 9s (- 0m 21s)
Iter: 160, Loss 0.001149, Num updates: 160, Wall time: 1375.41, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001154, Num updates: 200, Wall time: 1378.25, ETA: 0m 14s (- 0m 15s)
Iter: 240, Loss 0.001156, Num updates: 240, Wall time: 1381.10, ETA: 0m 17s (- 0m 11s)
Iter: 280, Loss 0.001159, Num updates: 280, Wall time: 1384.17, ETA: 0m 20s (- 0m 9s)
Iter: 320, Loss 0.001163, Num updates: 320, Wall time: 1386.99, ETA: 0m 23s (- 0m 6s)
Iter: 360, Loss 0.001166, Num updates: 360, Wall time: 1389.93, ETA: 0m 26s (- 0m 3s)
Iter: 400, Loss 0.001167, Num updates: 400, Wall time: 1392.81, ETA: 0m 29s (- 0m 0s)
Evaluating...
epoch 44, time: 30.34
	train_loss: 0.0012, score: 28.30
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001145, Num updates: 40, Wall time: 1397.50, ETA: 0m 3s (- 0m 34s)
Iter: 80, Loss 0.001145, Num updates: 80, Wall time: 1400.54, ETA: 0m 6s (- 0m 27s)
Iter: 120, Loss 0.001147, Num updates: 120, Wall time: 1403.29, ETA: 0m 9s (- 0m 22s)
Iter: 160, Loss 0.001158, Num updates: 160, Wall time: 1406.10, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001155, Num updates: 200, Wall time: 1408.99, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001159, Num updates: 240, Wall time: 1411.97, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001164, Num updates: 280, Wall time: 1414.96, ETA: 0m 21s (- 0m 9s)
Iter: 320, Loss 0.001161, Num updates: 320, Wall time: 1417.79, ETA: 0m 24s (- 0m 6s)
Iter: 360, Loss 0.001161, Num updates: 360, Wall time: 1420.65, ETA: 0m 26s (- 0m 3s)
Iter: 400, Loss 0.001161, Num updates: 400, Wall time: 1423.57, ETA: 0m 29s (- 0m 0s)
Evaluating...
epoch 45, time: 30.58
	train_loss: 0.0012, score: 27.62
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001143, Num updates: 40, Wall time: 1428.23, ETA: 0m 3s (- 0m 33s)
Iter: 80, Loss 0.001151, Num updates: 80, Wall time: 1431.19, ETA: 0m 6s (- 0m 26s)
Iter: 120, Loss 0.001159, Num updates: 120, Wall time: 1433.95, ETA: 0m 9s (- 0m 22s)
Iter: 160, Loss 0.001150, Num updates: 160, Wall time: 1436.76, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001152, Num updates: 200, Wall time: 1439.69, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001151, Num updates: 240, Wall time: 1442.69, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001157, Num updates: 280, Wall time: 1445.66, ETA: 0m 21s (- 0m 9s)
Iter: 320, Loss 0.001157, Num updates: 320, Wall time: 1448.64, ETA: 0m 24s (- 0m 6s)
Iter: 360, Loss 0.001157, Num updates: 360, Wall time: 1451.55, ETA: 0m 26s (- 0m 3s)
Iter: 400, Loss 0.001159, Num updates: 400, Wall time: 1454.40, ETA: 0m 29s (- 0m 0s)
Evaluating...
epoch 46, time: 30.57
	train_loss: 0.0012, score: 27.55
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001113, Num updates: 40, Wall time: 1458.97, ETA: 0m 3s (- 0m 33s)
Iter: 80, Loss 0.001136, Num updates: 80, Wall time: 1461.85, ETA: 0m 6s (- 0m 26s)
Iter: 120, Loss 0.001143, Num updates: 120, Wall time: 1464.61, ETA: 0m 9s (- 0m 21s)
Iter: 160, Loss 0.001143, Num updates: 160, Wall time: 1467.52, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001148, Num updates: 200, Wall time: 1470.53, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001153, Num updates: 240, Wall time: 1473.40, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001151, Num updates: 280, Wall time: 1476.26, ETA: 0m 20s (- 0m 9s)
Iter: 320, Loss 0.001149, Num updates: 320, Wall time: 1479.17, ETA: 0m 23s (- 0m 6s)
Iter: 360, Loss 0.001150, Num updates: 360, Wall time: 1482.16, ETA: 0m 26s (- 0m 3s)
Iter: 400, Loss 0.001152, Num updates: 400, Wall time: 1485.04, ETA: 0m 29s (- 0m 0s)
Evaluating...
epoch 47, time: 30.47
	train_loss: 0.0012, score: 28.37
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001107, Num updates: 40, Wall time: 1489.89, ETA: 0m 3s (- 0m 35s)
Iter: 80, Loss 0.001121, Num updates: 80, Wall time: 1492.74, ETA: 0m 6s (- 0m 27s)
Iter: 120, Loss 0.001138, Num updates: 120, Wall time: 1495.75, ETA: 0m 9s (- 0m 23s)
Iter: 160, Loss 0.001146, Num updates: 160, Wall time: 1498.60, ETA: 0m 12s (- 0m 19s)
Iter: 200, Loss 0.001148, Num updates: 200, Wall time: 1501.27, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001145, Num updates: 240, Wall time: 1504.02, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001140, Num updates: 280, Wall time: 1506.83, ETA: 0m 20s (- 0m 9s)
Iter: 320, Loss 0.001144, Num updates: 320, Wall time: 1509.80, ETA: 0m 23s (- 0m 6s)
Iter: 360, Loss 0.001147, Num updates: 360, Wall time: 1512.66, ETA: 0m 26s (- 0m 3s)
Iter: 400, Loss 0.001148, Num updates: 400, Wall time: 1515.39, ETA: 0m 29s (- 0m 0s)
Evaluating...
epoch 48, time: 30.12
	train_loss: 0.0012, score: 27.48
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001098, Num updates: 40, Wall time: 1519.82, ETA: 0m 3s (- 0m 32s)
Iter: 80, Loss 0.001110, Num updates: 80, Wall time: 1522.75, ETA: 0m 6s (- 0m 26s)
Iter: 120, Loss 0.001123, Num updates: 120, Wall time: 1525.72, ETA: 0m 9s (- 0m 22s)
Iter: 160, Loss 0.001130, Num updates: 160, Wall time: 1528.67, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001133, Num updates: 200, Wall time: 1531.55, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001133, Num updates: 240, Wall time: 1534.51, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001138, Num updates: 280, Wall time: 1537.39, ETA: 0m 21s (- 0m 9s)
Iter: 320, Loss 0.001143, Num updates: 320, Wall time: 1540.30, ETA: 0m 23s (- 0m 6s)
Iter: 360, Loss 0.001143, Num updates: 360, Wall time: 1543.21, ETA: 0m 26s (- 0m 3s)
Iter: 400, Loss 0.001145, Num updates: 400, Wall time: 1546.07, ETA: 0m 29s (- 0m 0s)
Evaluating...
epoch 49, time: 30.51
	train_loss: 0.0011, score: 27.39
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001079, Num updates: 40, Wall time: 1550.85, ETA: 0m 3s (- 0m 35s)
Iter: 80, Loss 0.001105, Num updates: 80, Wall time: 1553.84, ETA: 0m 6s (- 0m 27s)
Iter: 120, Loss 0.001123, Num updates: 120, Wall time: 1556.78, ETA: 0m 9s (- 0m 22s)
Iter: 160, Loss 0.001130, Num updates: 160, Wall time: 1559.76, ETA: 0m 12s (- 0m 19s)
Iter: 200, Loss 0.001131, Num updates: 200, Wall time: 1562.65, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001136, Num updates: 240, Wall time: 1565.62, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001134, Num updates: 280, Wall time: 1568.52, ETA: 0m 21s (- 0m 9s)
Iter: 320, Loss 0.001131, Num updates: 320, Wall time: 1571.51, ETA: 0m 24s (- 0m 6s)
Iter: 360, Loss 0.001135, Num updates: 360, Wall time: 1574.41, ETA: 0m 27s (- 0m 3s)
Iter: 400, Loss 0.001139, Num updates: 400, Wall time: 1576.98, ETA: 0m 29s (- 0m 0s)
Evaluating...
epoch 50, time: 30.72
	train_loss: 0.0011, score: 27.54
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001103, Num updates: 40, Wall time: 1581.86, ETA: 0m 3s (- 0m 33s)
Iter: 80, Loss 0.001117, Num updates: 80, Wall time: 1584.64, ETA: 0m 6s (- 0m 25s)
Iter: 120, Loss 0.001117, Num updates: 120, Wall time: 1587.43, ETA: 0m 9s (- 0m 21s)
Iter: 160, Loss 0.001124, Num updates: 160, Wall time: 1590.32, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001123, Num updates: 200, Wall time: 1593.23, ETA: 0m 14s (- 0m 15s)
Iter: 240, Loss 0.001126, Num updates: 240, Wall time: 1595.98, ETA: 0m 17s (- 0m 11s)
Iter: 280, Loss 0.001128, Num updates: 280, Wall time: 1598.91, ETA: 0m 20s (- 0m 8s)
Iter: 320, Loss 0.001129, Num updates: 320, Wall time: 1601.60, ETA: 0m 23s (- 0m 5s)
Iter: 360, Loss 0.001133, Num updates: 360, Wall time: 1604.33, ETA: 0m 26s (- 0m 2s)
Iter: 400, Loss 0.001134, Num updates: 400, Wall time: 1607.01, ETA: 0m 28s (- 0m 0s)
Evaluating...
epoch 51, time: 29.46
	train_loss: 0.0011, score: 27.36
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001092, Num updates: 40, Wall time: 1611.41, ETA: 0m 3s (- 0m 32s)
Iter: 80, Loss 0.001111, Num updates: 80, Wall time: 1614.27, ETA: 0m 6s (- 0m 25s)
Iter: 120, Loss 0.001117, Num updates: 120, Wall time: 1617.16, ETA: 0m 9s (- 0m 21s)
Iter: 160, Loss 0.001117, Num updates: 160, Wall time: 1620.16, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001128, Num updates: 200, Wall time: 1622.98, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001132, Num updates: 240, Wall time: 1625.92, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001132, Num updates: 280, Wall time: 1628.88, ETA: 0m 20s (- 0m 9s)
Iter: 320, Loss 0.001133, Num updates: 320, Wall time: 1631.69, ETA: 0m 23s (- 0m 6s)
Iter: 360, Loss 0.001133, Num updates: 360, Wall time: 1634.54, ETA: 0m 26s (- 0m 3s)
Iter: 400, Loss 0.001131, Num updates: 400, Wall time: 1637.31, ETA: 0m 29s (- 0m 0s)
Evaluating...
epoch 52, time: 30.07
	train_loss: 0.0011, score: 27.73
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001096, Num updates: 40, Wall time: 1641.87, ETA: 0m 3s (- 0m 34s)
Iter: 80, Loss 0.001111, Num updates: 80, Wall time: 1644.66, ETA: 0m 6s (- 0m 26s)
Iter: 120, Loss 0.001116, Num updates: 120, Wall time: 1647.51, ETA: 0m 9s (- 0m 22s)
Iter: 160, Loss 0.001119, Num updates: 160, Wall time: 1650.50, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001119, Num updates: 200, Wall time: 1653.43, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001119, Num updates: 240, Wall time: 1656.28, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001124, Num updates: 280, Wall time: 1658.88, ETA: 0m 20s (- 0m 8s)
Iter: 320, Loss 0.001125, Num updates: 320, Wall time: 1661.76, ETA: 0m 23s (- 0m 5s)
Iter: 360, Loss 0.001127, Num updates: 360, Wall time: 1664.70, ETA: 0m 26s (- 0m 3s)
Iter: 400, Loss 0.001129, Num updates: 400, Wall time: 1667.68, ETA: 0m 29s (- 0m 0s)
Evaluating...
epoch 53, time: 30.22
	train_loss: 0.0011, score: 27.68
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001070, Num updates: 40, Wall time: 1672.42, ETA: 0m 3s (- 0m 35s)
Iter: 80, Loss 0.001089, Num updates: 80, Wall time: 1675.21, ETA: 0m 6s (- 0m 26s)
Iter: 120, Loss 0.001090, Num updates: 120, Wall time: 1678.12, ETA: 0m 9s (- 0m 22s)
Iter: 160, Loss 0.001096, Num updates: 160, Wall time: 1681.05, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001104, Num updates: 200, Wall time: 1683.91, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001106, Num updates: 240, Wall time: 1686.88, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001113, Num updates: 280, Wall time: 1689.94, ETA: 0m 21s (- 0m 9s)
Iter: 320, Loss 0.001116, Num updates: 320, Wall time: 1692.90, ETA: 0m 24s (- 0m 6s)
Iter: 360, Loss 0.001119, Num updates: 360, Wall time: 1695.98, ETA: 0m 27s (- 0m 3s)
Iter: 400, Loss 0.001121, Num updates: 400, Wall time: 1698.74, ETA: 0m 30s (- 0m 0s)
Evaluating...
epoch 54, time: 31.00
	train_loss: 0.0011, score: 27.71
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001087, Num updates: 40, Wall time: 1704.17, ETA: 0m 4s (- 0m 40s)
Iter: 80, Loss 0.001111, Num updates: 80, Wall time: 1707.06, ETA: 0m 7s (- 0m 29s)
Iter: 120, Loss 0.001112, Num updates: 120, Wall time: 1709.95, ETA: 0m 10s (- 0m 23s)
Iter: 160, Loss 0.001114, Num updates: 160, Wall time: 1712.82, ETA: 0m 13s (- 0m 19s)
Iter: 200, Loss 0.001108, Num updates: 200, Wall time: 1716.05, ETA: 0m 16s (- 0m 16s)
Iter: 240, Loss 0.001111, Num updates: 240, Wall time: 1718.87, ETA: 0m 19s (- 0m 12s)
Iter: 280, Loss 0.001113, Num updates: 280, Wall time: 1721.75, ETA: 0m 21s (- 0m 9s)
Iter: 320, Loss 0.001115, Num updates: 320, Wall time: 1724.62, ETA: 0m 24s (- 0m 6s)
Iter: 360, Loss 0.001117, Num updates: 360, Wall time: 1727.24, ETA: 0m 27s (- 0m 3s)
Iter: 400, Loss 0.001118, Num updates: 400, Wall time: 1730.05, ETA: 0m 30s (- 0m 0s)
Evaluating...
epoch 55, time: 30.93
	train_loss: 0.0011, score: 28.10
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001093, Num updates: 40, Wall time: 1734.75, ETA: 0m 3s (- 0m 35s)
Iter: 80, Loss 0.001096, Num updates: 80, Wall time: 1737.55, ETA: 0m 6s (- 0m 27s)
Iter: 120, Loss 0.001100, Num updates: 120, Wall time: 1740.38, ETA: 0m 9s (- 0m 22s)
Iter: 160, Loss 0.001113, Num updates: 160, Wall time: 1743.33, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001113, Num updates: 200, Wall time: 1746.30, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001115, Num updates: 240, Wall time: 1749.21, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001119, Num updates: 280, Wall time: 1752.14, ETA: 0m 21s (- 0m 9s)
Iter: 320, Loss 0.001116, Num updates: 320, Wall time: 1755.27, ETA: 0m 24s (- 0m 6s)
Iter: 360, Loss 0.001112, Num updates: 360, Wall time: 1758.14, ETA: 0m 27s (- 0m 3s)
Iter: 400, Loss 0.001114, Num updates: 400, Wall time: 1761.12, ETA: 0m 30s (- 0m 0s)
Evaluating...
epoch 56, time: 30.93
	train_loss: 0.0011, score: 27.27
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001094, Num updates: 40, Wall time: 1766.16, ETA: 0m 4s (- 0m 38s)
Iter: 80, Loss 0.001106, Num updates: 80, Wall time: 1768.97, ETA: 0m 6s (- 0m 28s)
Iter: 120, Loss 0.001107, Num updates: 120, Wall time: 1772.05, ETA: 0m 10s (- 0m 23s)
Iter: 160, Loss 0.001106, Num updates: 160, Wall time: 1774.80, ETA: 0m 12s (- 0m 19s)
Iter: 200, Loss 0.001109, Num updates: 200, Wall time: 1777.88, ETA: 0m 15s (- 0m 16s)
Iter: 240, Loss 0.001110, Num updates: 240, Wall time: 1780.78, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001110, Num updates: 280, Wall time: 1783.84, ETA: 0m 21s (- 0m 9s)
Iter: 320, Loss 0.001112, Num updates: 320, Wall time: 1786.72, ETA: 0m 24s (- 0m 6s)
Iter: 360, Loss 0.001111, Num updates: 360, Wall time: 1789.63, ETA: 0m 27s (- 0m 3s)
Iter: 400, Loss 0.001111, Num updates: 400, Wall time: 1792.42, ETA: 0m 30s (- 0m 0s)
Evaluating...
epoch 57, time: 30.92
	train_loss: 0.0011, score: 27.44
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001057, Num updates: 40, Wall time: 1796.97, ETA: 0m 3s (- 0m 35s)
Iter: 80, Loss 0.001073, Num updates: 80, Wall time: 1800.06, ETA: 0m 6s (- 0m 28s)
Iter: 120, Loss 0.001084, Num updates: 120, Wall time: 1803.02, ETA: 0m 9s (- 0m 23s)
Iter: 160, Loss 0.001092, Num updates: 160, Wall time: 1806.21, ETA: 0m 13s (- 0m 19s)
Iter: 200, Loss 0.001100, Num updates: 200, Wall time: 1809.12, ETA: 0m 15s (- 0m 16s)
Iter: 240, Loss 0.001103, Num updates: 240, Wall time: 1812.05, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001104, Num updates: 280, Wall time: 1814.84, ETA: 0m 21s (- 0m 9s)
Iter: 320, Loss 0.001109, Num updates: 320, Wall time: 1817.71, ETA: 0m 24s (- 0m 6s)
Iter: 360, Loss 0.001107, Num updates: 360, Wall time: 1820.76, ETA: 0m 27s (- 0m 3s)
Iter: 400, Loss 0.001108, Num updates: 400, Wall time: 1823.56, ETA: 0m 30s (- 0m 0s)
Evaluating...
epoch 58, time: 31.13
	train_loss: 0.0011, score: 27.80
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001083, Num updates: 40, Wall time: 1828.09, ETA: 0m 3s (- 0m 33s)
Iter: 80, Loss 0.001090, Num updates: 80, Wall time: 1831.06, ETA: 0m 6s (- 0m 26s)
Iter: 120, Loss 0.001084, Num updates: 120, Wall time: 1833.93, ETA: 0m 9s (- 0m 22s)
Iter: 160, Loss 0.001089, Num updates: 160, Wall time: 1836.81, ETA: 0m 12s (- 0m 18s)
Iter: 200, Loss 0.001093, Num updates: 200, Wall time: 1839.50, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001100, Num updates: 240, Wall time: 1842.71, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001102, Num updates: 280, Wall time: 1846.06, ETA: 0m 21s (- 0m 9s)
Iter: 320, Loss 0.001105, Num updates: 320, Wall time: 1848.77, ETA: 0m 24s (- 0m 6s)
Iter: 360, Loss 0.001107, Num updates: 360, Wall time: 1851.63, ETA: 0m 27s (- 0m 3s)
Iter: 400, Loss 0.001107, Num updates: 400, Wall time: 1854.55, ETA: 0m 30s (- 0m 0s)
Evaluating...
epoch 59, time: 30.62
	train_loss: 0.0011, score: 27.56
	eval score: 0.00 (0.00)
0.00404,0.00179,0.00172,0.00167,0.00165,0.00163,0.00161,0.00159,0.00158,0.00156,0.00154,0.00152,0.00151,0.00149,0.00147,0.00145,0.00144,0.00142,0.0014,0.00139,0.00137,0.00136,0.00134,0.00133,0.00132,0.00131,0.0013,0.00129,0.00128,0.00127,0.00126,0.00125,0.00124,0.00124,0.00123,0.00122,0.00122,0.00121,0.0012,0.0012,0.00119,0.00119,0.00118,0.00117,0.00117,0.00116,0.00116,0.00115,0.00115,0.00115,0.00114,0.00114,0.00113,0.00113,0.00112,0.00112,0.00112,0.00111,0.00111,0.00111
0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
saved_model_Med2019/BAN_MEVF
Namespace(RAD_dir='/home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019', activation='relu', ae_alpha=0.001, ae_model_path='pretrained_ae.pth', alpha=1.0, autoencoder=True, batch_size=32, clip_norm=0.25, dropout=0.5, epochs=50, eps_cnn=1e-05, feat_dim=32, five_fold=False, gamma=2, gpu=0, input=None, lr=0.03, maml=True, maml_model_path='pretrained_maml.weights', model='BAN', momentum_cnn=0.05, num_hid=1024, num_stacks=2, op='c', output='saved_model_Med2019/BAN_MEVF', pow=2, print_interval=40, qc_model_path='./saved_models/QC/rad_best.pth', question_len=12, record_id=1, rescale_factor=1.5, rnn='LSTM', seed=3, tfidf=True, update_freq='1', use_RAD=True, use_ablation=False, use_ablation_q=False, use_ablation_v=False, use_counter=False, use_grad_cam=False, use_kl_mix=False, use_mix=True, use_mix_all=False, use_mix_cond=True, use_mix_cond_q=True, use_mix_cond_v=False, use_mix_cond_vq_in=False, use_mix_cond_vq_union=False, use_partial_label=False, use_rescale=False, use_sep_mix=False)
loading dictionary from /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/dictionary.pkl
loading MAML image data from file: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/images84x84.pkl
loading DAE image data from file: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/images128x128.pkl
loading MAML image data from file: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/images84x84.pkl
loading DAE image data from file: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/images128x128.pkl
load initial weights MAML from: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/pretrained_maml.weights
load initial weights DAE from: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/pretrained_ae.pth
loading dictionary from /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/dictionary.pkl
Loading embedding tfidf and weights from file
Load embedding tfidf and weights from file successfully
Namespace(RAD_dir='/home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019', activation='relu', ae_alpha=0.001, ae_model_path='pretrained_ae.pth', alpha=1.0, autoencoder=True, batch_size=32, clip_norm=0.25, device=device(type='cuda', index=0), dropout=0.5, epochs=50, eps_cnn=1e-05, feat_dim=64, five_fold=False, gamma=2, gpu=0, input=None, lr=0.03, maml=True, maml_model_path='pretrained_maml.weights', model='BAN', momentum_cnn=0.05, num_hid=1024, num_stacks=2, op='c', output='saved_model_Med2019/BAN_MEVF', pow=2, print_interval=40, qc_model_path='./saved_models/QC/rad_best.pth', question_len=12, record_id=1, rescale_factor=1.5, rnn='LSTM', seed=3, tfidf=True, update_freq='1', use_RAD=True, use_ablation=False, use_ablation_q=False, use_ablation_v=False, use_counter=False, use_grad_cam=False, use_kl_mix=False, use_mix=True, use_mix_all=False, use_mix_cond=True, use_mix_cond_q=True, use_mix_cond_v=False, use_mix_cond_vq_in=False, use_mix_cond_vq_union=False, use_partial_label=False, use_rescale=False, use_sep_mix=False)
nParams=	21342541
optim: adamax lr=0.0300, decay_step=3, decay_rate=0.75, grad_clip=0.25
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'language_model.WordEmbedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Iter: 40, Loss 0.021839, Num updates: 40, Wall time: 4.81, ETA: 0m 4s (- 0m 38s)
Iter: 80, Loss 0.012096, Num updates: 80, Wall time: 7.80, ETA: 0m 7s (- 0m 29s)
Iter: 120, Loss 0.008773, Num updates: 120, Wall time: 11.14, ETA: 0m 10s (- 0m 24s)
Iter: 160, Loss 0.007119, Num updates: 160, Wall time: 14.42, ETA: 0m 13s (- 0m 20s)
Iter: 200, Loss 0.006112, Num updates: 200, Wall time: 17.35, ETA: 0m 16s (- 0m 16s)
Iter: 240, Loss 0.005429, Num updates: 240, Wall time: 20.55, ETA: 0m 19s (- 0m 13s)
Iter: 280, Loss 0.004942, Num updates: 280, Wall time: 23.74, ETA: 0m 23s (- 0m 10s)
Iter: 320, Loss 0.004570, Num updates: 320, Wall time: 26.85, ETA: 0m 26s (- 0m 6s)
Iter: 360, Loss 0.004274, Num updates: 360, Wall time: 30.02, ETA: 0m 29s (- 0m 3s)
Iter: 400, Loss 0.004034, Num updates: 400, Wall time: 33.31, ETA: 0m 32s (- 0m 0s)
Evaluating...
epoch 0, time: 33.60
	train_loss: 0.0040, score: 14.34
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001794, Num updates: 40, Wall time: 38.54, ETA: 0m 4s (- 0m 37s)
Iter: 80, Loss 0.001808, Num updates: 80, Wall time: 41.62, ETA: 0m 7s (- 0m 28s)
Iter: 120, Loss 0.001799, Num updates: 120, Wall time: 44.53, ETA: 0m 10s (- 0m 23s)
Iter: 160, Loss 0.001797, Num updates: 160, Wall time: 47.43, ETA: 0m 12s (- 0m 19s)
Iter: 200, Loss 0.001800, Num updates: 200, Wall time: 50.45, ETA: 0m 15s (- 0m 16s)
Iter: 240, Loss 0.001795, Num updates: 240, Wall time: 53.67, ETA: 0m 19s (- 0m 12s)
Iter: 280, Loss 0.001798, Num updates: 280, Wall time: 56.39, ETA: 0m 21s (- 0m 9s)
Iter: 320, Loss 0.001798, Num updates: 320, Wall time: 59.56, ETA: 0m 25s (- 0m 6s)
Iter: 360, Loss 0.001794, Num updates: 360, Wall time: 62.87, ETA: 0m 28s (- 0m 3s)
Iter: 400, Loss 0.001787, Num updates: 400, Wall time: 65.83, ETA: 0m 31s (- 0m 0s)
Evaluating...
epoch 1, time: 32.34
	train_loss: 0.0018, score: 20.15
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001689, Num updates: 40, Wall time: 70.95, ETA: 0m 3s (- 0m 35s)
Iter: 80, Loss 0.001715, Num updates: 80, Wall time: 73.71, ETA: 0m 6s (- 0m 26s)
Iter: 120, Loss 0.001732, Num updates: 120, Wall time: 76.74, ETA: 0m 9s (- 0m 22s)
Iter: 160, Loss 0.001722, Num updates: 160, Wall time: 80.01, ETA: 0m 12s (- 0m 19s)
Iter: 200, Loss 0.001712, Num updates: 200, Wall time: 82.94, ETA: 0m 15s (- 0m 15s)
Iter: 240, Loss 0.001711, Num updates: 240, Wall time: 85.97, ETA: 0m 18s (- 0m 12s)
Iter: 280, Loss 0.001712, Num updates: 280, Wall time: 89.16, ETA: 0m 22s (- 0m 9s)
Iter: 320, Loss 0.001713, Num updates: 320, Wall time: 92.55, ETA: 0m 25s (- 0m 6s)
Iter: 360, Loss 0.001715, Num updates: 360, Wall time: 96.11, ETA: 0m 28s (- 0m 3s)
Iter: 400, Loss 0.001713, Num updates: 400, Wall time: 98.95, ETA: 0m 31s (- 0m 0s)
Evaluating...
epoch 2, time: 32.86
	train_loss: 0.0017, score: 21.00
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001611, Num updates: 40, Wall time: 104.12, ETA: 0m 3s (- 0m 35s)
Iter: 80, Loss 0.001644, Num updates: 80, Wall time: 107.02, ETA: 0m 6s (- 0m 27s)
Iter: 120, Loss 0.001644, Num updates: 120, Wall time: 110.39, ETA: 0m 10s (- 0m 23s)
Iter: 160, Loss 0.001655, Num updates: 160, Wall time: 113.68, ETA: 0m 13s (- 0m 20s)
Iter: 200, Loss 0.001663, Num updates: 200, Wall time: 117.24, ETA: 0m 17s (- 0m 17s)
Iter: 240, Loss 0.001666, Num updates: 240, Wall time: 120.51, ETA: 0m 20s (- 0m 13s)
Iter: 280, Loss 0.001666, Num updates: 280, Wall time: 123.98, ETA: 0m 23s (- 0m 10s)
Iter: 320, Loss 0.001668, Num updates: 320, Wall time: 128.25, ETA: 0m 28s (- 0m 7s)
Iter: 360, Loss 0.001668, Num updates: 360, Wall time: 130.89, ETA: 0m 30s (- 0m 3s)
Iter: 400, Loss 0.001670, Num updates: 400, Wall time: 133.63, ETA: 0m 33s (- 0m 0s)
Evaluating...
epoch 3, time: 34.29
	train_loss: 0.0017, score: 22.05
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001633, Num updates: 40, Wall time: 138.62, ETA: 0m 3s (- 0m 35s)
Iter: 80, Loss 0.001627, Num updates: 80, Wall time: 141.12, ETA: 0m 6s (- 0m 25s)
Iter: 120, Loss 0.001650, Num updates: 120, Wall time: 143.85, ETA: 0m 9s (- 0m 21s)
Iter: 160, Loss 0.001656, Num updates: 160, Wall time: 147.39, ETA: 0m 12s (- 0m 19s)
Iter: 200, Loss 0.001655, Num updates: 200, Wall time: 151.35, ETA: 0m 16s (- 0m 16s)
Iter: 240, Loss 0.001650, Num updates: 240, Wall time: 155.13, ETA: 0m 20s (- 0m 13s)
Iter: 280, Loss 0.001647, Num updates: 280, Wall time: 158.90, ETA: 0m 24s (- 0m 10s)
Iter: 320, Loss 0.001648, Num updates: 320, Wall time: 162.68, ETA: 0m 27s (- 0m 7s)
Iter: 360, Loss 0.001646, Num updates: 360, Wall time: 166.42, ETA: 0m 31s (- 0m 3s)
Iter: 400, Loss 0.001645, Num updates: 400, Wall time: 170.01, ETA: 0m 35s (- 0m 0s)
Evaluating...
epoch 4, time: 36.33
	train_loss: 0.0016, score: 21.98
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001636, Num updates: 40, Wall time: 177.16, ETA: 0m 5s (- 0m 53s)
Iter: 80, Loss 0.001625, Num updates: 80, Wall time: 180.89, ETA: 0m 9s (- 0m 38s)
Iter: 120, Loss 0.001614, Num updates: 120, Wall time: 184.54, ETA: 0m 13s (- 0m 31s)
Iter: 160, Loss 0.001617, Num updates: 160, Wall time: 188.09, ETA: 0m 16s (- 0m 25s)
Iter: 200, Loss 0.001619, Num updates: 200, Wall time: 190.78, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001613, Num updates: 240, Wall time: 193.77, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001614, Num updates: 280, Wall time: 196.71, ETA: 0m 25s (- 0m 10s)
Iter: 320, Loss 0.001617, Num updates: 320, Wall time: 199.74, ETA: 0m 28s (- 0m 7s)
Iter: 360, Loss 0.001622, Num updates: 360, Wall time: 202.62, ETA: 0m 31s (- 0m 3s)
Iter: 400, Loss 0.001623, Num updates: 400, Wall time: 205.42, ETA: 0m 34s (- 0m 0s)
Evaluating...
epoch 5, time: 34.59
	train_loss: 0.0016, score: 22.59
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001520, Num updates: 40, Wall time: 210.69, ETA: 0m 4s (- 0m 41s)
Iter: 80, Loss 0.001583, Num updates: 80, Wall time: 213.91, ETA: 0m 7s (- 0m 31s)
Iter: 120, Loss 0.001610, Num updates: 120, Wall time: 217.07, ETA: 0m 10s (- 0m 25s)
Iter: 160, Loss 0.001606, Num updates: 160, Wall time: 220.01, ETA: 0m 13s (- 0m 20s)
Iter: 200, Loss 0.001609, Num updates: 200, Wall time: 223.01, ETA: 0m 16s (- 0m 16s)
Iter: 240, Loss 0.001601, Num updates: 240, Wall time: 226.20, ETA: 0m 19s (- 0m 13s)
Iter: 280, Loss 0.001607, Num updates: 280, Wall time: 229.19, ETA: 0m 22s (- 0m 9s)
Iter: 320, Loss 0.001608, Num updates: 320, Wall time: 232.34, ETA: 0m 26s (- 0m 6s)
Iter: 360, Loss 0.001608, Num updates: 360, Wall time: 235.58, ETA: 0m 29s (- 0m 3s)
Iter: 400, Loss 0.001604, Num updates: 400, Wall time: 238.49, ETA: 0m 32s (- 0m 0s)
Evaluating...
epoch 6, time: 33.29
	train_loss: 0.0016, score: 23.72
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001558, Num updates: 40, Wall time: 245.02, ETA: 0m 5s (- 0m 48s)
Iter: 80, Loss 0.001578, Num updates: 80, Wall time: 248.80, ETA: 0m 9s (- 0m 36s)
Iter: 120, Loss 0.001587, Num updates: 120, Wall time: 252.16, ETA: 0m 12s (- 0m 29s)
Iter: 160, Loss 0.001586, Num updates: 160, Wall time: 255.87, ETA: 0m 16s (- 0m 24s)
Iter: 200, Loss 0.001584, Num updates: 200, Wall time: 259.58, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001587, Num updates: 240, Wall time: 263.35, ETA: 0m 23s (- 0m 15s)
Iter: 280, Loss 0.001583, Num updates: 280, Wall time: 267.38, ETA: 0m 27s (- 0m 11s)
Iter: 320, Loss 0.001590, Num updates: 320, Wall time: 270.79, ETA: 0m 31s (- 0m 7s)
Iter: 360, Loss 0.001588, Num updates: 360, Wall time: 274.60, ETA: 0m 34s (- 0m 3s)
Iter: 400, Loss 0.001588, Num updates: 400, Wall time: 278.55, ETA: 0m 38s (- 0m 0s)
Evaluating...
epoch 7, time: 39.96
	train_loss: 0.0016, score: 23.54
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001523, Num updates: 40, Wall time: 285.91, ETA: 0m 5s (- 0m 54s)
Iter: 80, Loss 0.001558, Num updates: 80, Wall time: 290.31, ETA: 0m 10s (- 0m 41s)
Iter: 120, Loss 0.001564, Num updates: 120, Wall time: 294.20, ETA: 0m 14s (- 0m 33s)
Iter: 160, Loss 0.001566, Num updates: 160, Wall time: 298.18, ETA: 0m 18s (- 0m 27s)
Iter: 200, Loss 0.001570, Num updates: 200, Wall time: 302.35, ETA: 0m 22s (- 0m 22s)
Iter: 240, Loss 0.001574, Num updates: 240, Wall time: 306.43, ETA: 0m 26s (- 0m 17s)
Iter: 280, Loss 0.001573, Num updates: 280, Wall time: 310.36, ETA: 0m 30s (- 0m 13s)
Iter: 320, Loss 0.001572, Num updates: 320, Wall time: 314.89, ETA: 0m 34s (- 0m 8s)
Iter: 360, Loss 0.001573, Num updates: 360, Wall time: 320.32, ETA: 0m 40s (- 0m 4s)
Iter: 400, Loss 0.001571, Num updates: 400, Wall time: 324.95, ETA: 0m 44s (- 0m 0s)
Evaluating...
epoch 8, time: 46.27
	train_loss: 0.0016, score: 23.40
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001481, Num updates: 40, Wall time: 332.23, ETA: 0m 5s (- 0m 52s)
Iter: 80, Loss 0.001507, Num updates: 80, Wall time: 335.54, ETA: 0m 9s (- 0m 36s)
Iter: 120, Loss 0.001520, Num updates: 120, Wall time: 338.83, ETA: 0m 12s (- 0m 29s)
Iter: 160, Loss 0.001538, Num updates: 160, Wall time: 342.24, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001546, Num updates: 200, Wall time: 345.94, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001550, Num updates: 240, Wall time: 350.11, ETA: 0m 23s (- 0m 15s)
Iter: 280, Loss 0.001557, Num updates: 280, Wall time: 354.17, ETA: 0m 27s (- 0m 11s)
Iter: 320, Loss 0.001557, Num updates: 320, Wall time: 358.26, ETA: 0m 31s (- 0m 8s)
Iter: 360, Loss 0.001558, Num updates: 360, Wall time: 362.28, ETA: 0m 35s (- 0m 4s)
Iter: 400, Loss 0.001555, Num updates: 400, Wall time: 366.49, ETA: 0m 39s (- 0m 0s)
Evaluating...
epoch 9, time: 40.90
	train_loss: 0.0016, score: 23.98
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001482, Num updates: 40, Wall time: 373.67, ETA: 0m 6s (- 0m 55s)
Iter: 80, Loss 0.001513, Num updates: 80, Wall time: 378.80, ETA: 0m 11s (- 0m 45s)
Iter: 120, Loss 0.001515, Num updates: 120, Wall time: 384.24, ETA: 0m 16s (- 0m 39s)
Iter: 160, Loss 0.001521, Num updates: 160, Wall time: 389.49, ETA: 0m 21s (- 0m 33s)
Iter: 200, Loss 0.001537, Num updates: 200, Wall time: 394.87, ETA: 0m 27s (- 0m 27s)
Iter: 240, Loss 0.001533, Num updates: 240, Wall time: 399.91, ETA: 0m 32s (- 0m 21s)
Iter: 280, Loss 0.001536, Num updates: 280, Wall time: 405.37, ETA: 0m 37s (- 0m 16s)
Iter: 320, Loss 0.001538, Num updates: 320, Wall time: 410.65, ETA: 0m 42s (- 0m 10s)
Iter: 360, Loss 0.001534, Num updates: 360, Wall time: 415.87, ETA: 0m 48s (- 0m 5s)
Iter: 400, Loss 0.001538, Num updates: 400, Wall time: 421.16, ETA: 0m 53s (- 0m 0s)
Evaluating...
epoch 10, time: 54.52
	train_loss: 0.0015, score: 24.36
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001508, Num updates: 40, Wall time: 429.44, ETA: 0m 6s (- 1m 4s)
Iter: 80, Loss 0.001519, Num updates: 80, Wall time: 434.60, ETA: 0m 12s (- 0m 49s)
Iter: 120, Loss 0.001527, Num updates: 120, Wall time: 439.94, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001517, Num updates: 160, Wall time: 445.23, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001513, Num updates: 200, Wall time: 450.67, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001518, Num updates: 240, Wall time: 455.82, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001521, Num updates: 280, Wall time: 460.93, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001515, Num updates: 320, Wall time: 466.22, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001516, Num updates: 360, Wall time: 471.46, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001519, Num updates: 400, Wall time: 476.72, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 11, time: 55.11
	train_loss: 0.0015, score: 24.22
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001475, Num updates: 40, Wall time: 484.77, ETA: 0m 6s (- 1m 4s)
Iter: 80, Loss 0.001484, Num updates: 80, Wall time: 489.98, ETA: 0m 12s (- 0m 49s)
Iter: 120, Loss 0.001483, Num updates: 120, Wall time: 495.41, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001478, Num updates: 160, Wall time: 500.82, ETA: 0m 23s (- 0m 34s)
Iter: 200, Loss 0.001487, Num updates: 200, Wall time: 506.11, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001489, Num updates: 240, Wall time: 511.32, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001495, Num updates: 280, Wall time: 516.38, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001498, Num updates: 320, Wall time: 521.28, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001500, Num updates: 360, Wall time: 526.70, ETA: 0m 48s (- 0m 5s)
Iter: 400, Loss 0.001504, Num updates: 400, Wall time: 531.95, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 12, time: 55.14
	train_loss: 0.0015, score: 24.05
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001435, Num updates: 40, Wall time: 540.06, ETA: 0m 6s (- 1m 3s)
Iter: 80, Loss 0.001443, Num updates: 80, Wall time: 545.47, ETA: 0m 12s (- 0m 49s)
Iter: 120, Loss 0.001461, Num updates: 120, Wall time: 550.81, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001470, Num updates: 160, Wall time: 556.34, ETA: 0m 23s (- 0m 35s)
Iter: 200, Loss 0.001480, Num updates: 200, Wall time: 561.77, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001478, Num updates: 240, Wall time: 567.21, ETA: 0m 34s (- 0m 22s)
Iter: 280, Loss 0.001480, Num updates: 280, Wall time: 572.48, ETA: 0m 39s (- 0m 17s)
Iter: 320, Loss 0.001482, Num updates: 320, Wall time: 577.63, ETA: 0m 44s (- 0m 11s)
Iter: 360, Loss 0.001482, Num updates: 360, Wall time: 582.83, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001487, Num updates: 400, Wall time: 588.22, ETA: 0m 55s (- 0m 0s)
Evaluating...
epoch 13, time: 56.09
	train_loss: 0.0015, score: 24.52
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001467, Num updates: 40, Wall time: 596.32, ETA: 0m 6s (- 1m 2s)
Iter: 80, Loss 0.001449, Num updates: 80, Wall time: 601.62, ETA: 0m 12s (- 0m 49s)
Iter: 120, Loss 0.001446, Num updates: 120, Wall time: 606.77, ETA: 0m 17s (- 0m 40s)
Iter: 160, Loss 0.001447, Num updates: 160, Wall time: 612.24, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001452, Num updates: 200, Wall time: 617.60, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001454, Num updates: 240, Wall time: 622.49, ETA: 0m 32s (- 0m 22s)
Iter: 280, Loss 0.001463, Num updates: 280, Wall time: 627.53, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001462, Num updates: 320, Wall time: 633.11, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001466, Num updates: 360, Wall time: 638.65, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001465, Num updates: 400, Wall time: 643.89, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 14, time: 55.43
	train_loss: 0.0015, score: 25.58
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001478, Num updates: 40, Wall time: 652.18, ETA: 0m 6s (- 1m 4s)
Iter: 80, Loss 0.001456, Num updates: 80, Wall time: 656.99, ETA: 0m 11s (- 0m 47s)
Iter: 120, Loss 0.001453, Num updates: 120, Wall time: 662.01, ETA: 0m 16s (- 0m 39s)
Iter: 160, Loss 0.001456, Num updates: 160, Wall time: 667.27, ETA: 0m 22s (- 0m 33s)
Iter: 200, Loss 0.001458, Num updates: 200, Wall time: 672.83, ETA: 0m 27s (- 0m 27s)
Iter: 240, Loss 0.001462, Num updates: 240, Wall time: 678.26, ETA: 0m 33s (- 0m 22s)
Iter: 280, Loss 0.001461, Num updates: 280, Wall time: 683.40, ETA: 0m 38s (- 0m 16s)
Iter: 320, Loss 0.001456, Num updates: 320, Wall time: 688.59, ETA: 0m 43s (- 0m 11s)
Iter: 360, Loss 0.001452, Num updates: 360, Wall time: 694.29, ETA: 0m 49s (- 0m 5s)
Iter: 400, Loss 0.001451, Num updates: 400, Wall time: 699.58, ETA: 0m 54s (- 0m 0s)
Evaluating...
epoch 15, time: 55.37
	train_loss: 0.0015, score: 25.22
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001392, Num updates: 40, Wall time: 708.10, ETA: 0m 7s (- 1m 7s)
Iter: 80, Loss 0.001408, Num updates: 80, Wall time: 713.49, ETA: 0m 12s (- 0m 51s)
Iter: 120, Loss 0.001410, Num updates: 120, Wall time: 718.87, ETA: 0m 18s (- 0m 42s)
Iter: 160, Loss 0.001419, Num updates: 160, Wall time: 724.11, ETA: 0m 23s (- 0m 35s)
Iter: 200, Loss 0.001424, Num updates: 200, Wall time: 729.39, ETA: 0m 28s (- 0m 28s)
Iter: 240, Loss 0.001427, Num updates: 240, Wall time: 734.87, ETA: 0m 34s (- 0m 22s)
Iter: 280, Loss 0.001428, Num updates: 280, Wall time: 740.40, ETA: 0m 39s (- 0m 17s)
Iter: 320, Loss 0.001432, Num updates: 320, Wall time: 745.93, ETA: 0m 45s (- 0m 11s)
Iter: 360, Loss 0.001435, Num updates: 360, Wall time: 751.25, ETA: 0m 50s (- 0m 5s)
Iter: 400, Loss 0.001433, Num updates: 400, Wall time: 756.29, ETA: 0m 55s (- 0m 0s)
Evaluating...
epoch 16, time: 56.48
	train_loss: 0.0014, score: 24.64
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001356, Num updates: 40, Wall time: 763.60, ETA: 0m 6s (- 0m 55s)
Iter: 80, Loss 0.001383, Num updates: 80, Wall time: 768.31, ETA: 0m 10s (- 0m 43s)
Iter: 120, Loss 0.001393, Num updates: 120, Wall time: 772.67, ETA: 0m 15s (- 0m 35s)
Iter: 160, Loss 0.001402, Num updates: 160, Wall time: 777.08, ETA: 0m 19s (- 0m 29s)
Iter: 200, Loss 0.001402, Num updates: 200, Wall time: 781.32, ETA: 0m 23s (- 0m 23s)
Iter: 240, Loss 0.001407, Num updates: 240, Wall time: 784.99, ETA: 0m 27s (- 0m 18s)
Iter: 280, Loss 0.001404, Num updates: 280, Wall time: 788.93, ETA: 0m 31s (- 0m 13s)
Iter: 320, Loss 0.001407, Num updates: 320, Wall time: 793.20, ETA: 0m 35s (- 0m 9s)
Iter: 360, Loss 0.001412, Num updates: 360, Wall time: 797.57, ETA: 0m 40s (- 0m 4s)
Iter: 400, Loss 0.001413, Num updates: 400, Wall time: 801.85, ETA: 0m 44s (- 0m 0s)
Evaluating...
epoch 17, time: 45.30
	train_loss: 0.0014, score: 25.88
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001377, Num updates: 40, Wall time: 808.97, ETA: 0m 5s (- 0m 54s)
Iter: 80, Loss 0.001378, Num updates: 80, Wall time: 812.92, ETA: 0m 9s (- 0m 39s)
Iter: 120, Loss 0.001386, Num updates: 120, Wall time: 817.00, ETA: 0m 13s (- 0m 32s)
Iter: 160, Loss 0.001393, Num updates: 160, Wall time: 821.25, ETA: 0m 18s (- 0m 27s)
Iter: 200, Loss 0.001394, Num updates: 200, Wall time: 825.20, ETA: 0m 22s (- 0m 22s)
Iter: 240, Loss 0.001393, Num updates: 240, Wall time: 829.43, ETA: 0m 26s (- 0m 17s)
Iter: 280, Loss 0.001396, Num updates: 280, Wall time: 833.88, ETA: 0m 30s (- 0m 13s)
Iter: 320, Loss 0.001394, Num updates: 320, Wall time: 838.01, ETA: 0m 34s (- 0m 8s)
Iter: 360, Loss 0.001398, Num updates: 360, Wall time: 842.19, ETA: 0m 39s (- 0m 4s)
Iter: 400, Loss 0.001399, Num updates: 400, Wall time: 846.24, ETA: 0m 43s (- 0m 0s)
Evaluating...
epoch 18, time: 44.04
	train_loss: 0.0014, score: 26.22
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001338, Num updates: 40, Wall time: 853.20, ETA: 0m 5s (- 0m 53s)
Iter: 80, Loss 0.001356, Num updates: 80, Wall time: 857.25, ETA: 0m 9s (- 0m 39s)
Iter: 120, Loss 0.001368, Num updates: 120, Wall time: 861.29, ETA: 0m 13s (- 0m 32s)
Iter: 160, Loss 0.001374, Num updates: 160, Wall time: 866.08, ETA: 0m 18s (- 0m 28s)
Iter: 200, Loss 0.001374, Num updates: 200, Wall time: 871.26, ETA: 0m 23s (- 0m 24s)
Iter: 240, Loss 0.001377, Num updates: 240, Wall time: 877.58, ETA: 0m 30s (- 0m 20s)
Iter: 280, Loss 0.001383, Num updates: 280, Wall time: 883.73, ETA: 0m 36s (- 0m 15s)
Iter: 320, Loss 0.001385, Num updates: 320, Wall time: 888.19, ETA: 0m 40s (- 0m 10s)
Iter: 360, Loss 0.001388, Num updates: 360, Wall time: 892.97, ETA: 0m 45s (- 0m 5s)
Iter: 400, Loss 0.001385, Num updates: 400, Wall time: 897.60, ETA: 0m 50s (- 0m 0s)
Evaluating...
epoch 19, time: 51.68
	train_loss: 0.0014, score: 25.86
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001317, Num updates: 40, Wall time: 907.73, ETA: 0m 8s (- 1m 17s)
Iter: 80, Loss 0.001344, Num updates: 80, Wall time: 912.93, ETA: 0m 13s (- 0m 55s)
Iter: 120, Loss 0.001358, Num updates: 120, Wall time: 917.09, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001359, Num updates: 160, Wall time: 921.32, ETA: 0m 21s (- 0m 33s)
Iter: 200, Loss 0.001358, Num updates: 200, Wall time: 925.53, ETA: 0m 26s (- 0m 26s)
Iter: 240, Loss 0.001361, Num updates: 240, Wall time: 929.71, ETA: 0m 30s (- 0m 20s)
Iter: 280, Loss 0.001362, Num updates: 280, Wall time: 934.05, ETA: 0m 34s (- 0m 15s)
Iter: 320, Loss 0.001363, Num updates: 320, Wall time: 938.02, ETA: 0m 38s (- 0m 9s)
Iter: 360, Loss 0.001367, Num updates: 360, Wall time: 942.36, ETA: 0m 43s (- 0m 4s)
Iter: 400, Loss 0.001367, Num updates: 400, Wall time: 946.42, ETA: 0m 47s (- 0m 0s)
Evaluating...
epoch 20, time: 47.98
	train_loss: 0.0014, score: 26.00
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001339, Num updates: 40, Wall time: 952.96, ETA: 0m 5s (- 0m 49s)
Iter: 80, Loss 0.001337, Num updates: 80, Wall time: 957.00, ETA: 0m 9s (- 0m 38s)
Iter: 120, Loss 0.001338, Num updates: 120, Wall time: 961.25, ETA: 0m 13s (- 0m 32s)
Iter: 160, Loss 0.001339, Num updates: 160, Wall time: 965.27, ETA: 0m 17s (- 0m 26s)
Iter: 200, Loss 0.001336, Num updates: 200, Wall time: 969.24, ETA: 0m 21s (- 0m 21s)
Iter: 240, Loss 0.001347, Num updates: 240, Wall time: 973.28, ETA: 0m 25s (- 0m 17s)
Iter: 280, Loss 0.001352, Num updates: 280, Wall time: 977.74, ETA: 0m 30s (- 0m 13s)
Iter: 320, Loss 0.001350, Num updates: 320, Wall time: 981.87, ETA: 0m 34s (- 0m 8s)
Iter: 360, Loss 0.001351, Num updates: 360, Wall time: 985.90, ETA: 0m 38s (- 0m 4s)
Iter: 400, Loss 0.001354, Num updates: 400, Wall time: 989.99, ETA: 0m 42s (- 0m 0s)
Evaluating...
epoch 21, time: 43.29
	train_loss: 0.0014, score: 26.69
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001299, Num updates: 40, Wall time: 996.95, ETA: 0m 5s (- 0m 53s)
Iter: 80, Loss 0.001321, Num updates: 80, Wall time: 1001.11, ETA: 0m 9s (- 0m 40s)
Iter: 120, Loss 0.001330, Num updates: 120, Wall time: 1005.40, ETA: 0m 14s (- 0m 33s)
Iter: 160, Loss 0.001329, Num updates: 160, Wall time: 1010.43, ETA: 0m 19s (- 0m 29s)
Iter: 200, Loss 0.001332, Num updates: 200, Wall time: 1014.52, ETA: 0m 23s (- 0m 23s)
Iter: 240, Loss 0.001337, Num updates: 240, Wall time: 1018.71, ETA: 0m 27s (- 0m 18s)
Iter: 280, Loss 0.001340, Num updates: 280, Wall time: 1022.50, ETA: 0m 31s (- 0m 13s)
Iter: 320, Loss 0.001336, Num updates: 320, Wall time: 1026.46, ETA: 0m 35s (- 0m 8s)
Iter: 360, Loss 0.001338, Num updates: 360, Wall time: 1030.73, ETA: 0m 39s (- 0m 4s)
Iter: 400, Loss 0.001340, Num updates: 400, Wall time: 1034.80, ETA: 0m 43s (- 0m 0s)
Evaluating...
epoch 22, time: 44.52
	train_loss: 0.0013, score: 26.23
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001293, Num updates: 40, Wall time: 1042.98, ETA: 0m 7s (- 1m 5s)
Iter: 80, Loss 0.001314, Num updates: 80, Wall time: 1047.15, ETA: 0m 11s (- 0m 45s)
Iter: 120, Loss 0.001316, Num updates: 120, Wall time: 1051.34, ETA: 0m 15s (- 0m 36s)
Iter: 160, Loss 0.001314, Num updates: 160, Wall time: 1055.46, ETA: 0m 19s (- 0m 29s)
Iter: 200, Loss 0.001317, Num updates: 200, Wall time: 1059.53, ETA: 0m 23s (- 0m 23s)
Iter: 240, Loss 0.001318, Num updates: 240, Wall time: 1064.39, ETA: 0m 28s (- 0m 19s)
Iter: 280, Loss 0.001321, Num updates: 280, Wall time: 1068.60, ETA: 0m 32s (- 0m 14s)
Iter: 320, Loss 0.001325, Num updates: 320, Wall time: 1072.53, ETA: 0m 36s (- 0m 9s)
Iter: 360, Loss 0.001326, Num updates: 360, Wall time: 1076.44, ETA: 0m 40s (- 0m 4s)
Iter: 400, Loss 0.001327, Num updates: 400, Wall time: 1080.52, ETA: 0m 44s (- 0m 0s)
Evaluating...
epoch 23, time: 45.56
	train_loss: 0.0013, score: 27.07
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001241, Num updates: 40, Wall time: 1087.58, ETA: 0m 5s (- 0m 54s)
Iter: 80, Loss 0.001286, Num updates: 80, Wall time: 1091.47, ETA: 0m 9s (- 0m 39s)
Iter: 120, Loss 0.001293, Num updates: 120, Wall time: 1095.52, ETA: 0m 13s (- 0m 32s)
Iter: 160, Loss 0.001304, Num updates: 160, Wall time: 1099.56, ETA: 0m 17s (- 0m 27s)
Iter: 200, Loss 0.001303, Num updates: 200, Wall time: 1104.01, ETA: 0m 22s (- 0m 22s)
Iter: 240, Loss 0.001308, Num updates: 240, Wall time: 1108.26, ETA: 0m 26s (- 0m 17s)
Iter: 280, Loss 0.001311, Num updates: 280, Wall time: 1112.53, ETA: 0m 30s (- 0m 13s)
Iter: 320, Loss 0.001313, Num updates: 320, Wall time: 1116.69, ETA: 0m 34s (- 0m 8s)
Iter: 360, Loss 0.001318, Num updates: 360, Wall time: 1121.12, ETA: 0m 39s (- 0m 4s)
Iter: 400, Loss 0.001317, Num updates: 400, Wall time: 1125.14, ETA: 0m 43s (- 0m 0s)
Evaluating...
epoch 24, time: 44.44
	train_loss: 0.0013, score: 27.64
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001242, Num updates: 40, Wall time: 1132.64, ETA: 0m 6s (- 0m 57s)
Iter: 80, Loss 0.001273, Num updates: 80, Wall time: 1137.01, ETA: 0m 10s (- 0m 43s)
Iter: 120, Loss 0.001275, Num updates: 120, Wall time: 1141.21, ETA: 0m 14s (- 0m 34s)
Iter: 160, Loss 0.001287, Num updates: 160, Wall time: 1145.63, ETA: 0m 19s (- 0m 29s)
Iter: 200, Loss 0.001293, Num updates: 200, Wall time: 1149.74, ETA: 0m 23s (- 0m 23s)
Iter: 240, Loss 0.001293, Num updates: 240, Wall time: 1153.92, ETA: 0m 27s (- 0m 18s)
Iter: 280, Loss 0.001295, Num updates: 280, Wall time: 1158.10, ETA: 0m 31s (- 0m 13s)
Iter: 320, Loss 0.001298, Num updates: 320, Wall time: 1162.33, ETA: 0m 35s (- 0m 9s)
Iter: 360, Loss 0.001301, Num updates: 360, Wall time: 1166.56, ETA: 0m 40s (- 0m 4s)
Iter: 400, Loss 0.001306, Num updates: 400, Wall time: 1170.51, ETA: 0m 44s (- 0m 0s)
Evaluating...
epoch 25, time: 45.13
	train_loss: 0.0013, score: 27.19
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001259, Num updates: 40, Wall time: 1177.68, ETA: 0m 5s (- 0m 54s)
Iter: 80, Loss 0.001284, Num updates: 80, Wall time: 1181.70, ETA: 0m 9s (- 0m 40s)
Iter: 120, Loss 0.001293, Num updates: 120, Wall time: 1185.57, ETA: 0m 13s (- 0m 32s)
Iter: 160, Loss 0.001285, Num updates: 160, Wall time: 1189.96, ETA: 0m 18s (- 0m 27s)
Iter: 200, Loss 0.001289, Num updates: 200, Wall time: 1194.72, ETA: 0m 22s (- 0m 23s)
Iter: 240, Loss 0.001290, Num updates: 240, Wall time: 1198.84, ETA: 0m 27s (- 0m 18s)
Iter: 280, Loss 0.001291, Num updates: 280, Wall time: 1202.98, ETA: 0m 31s (- 0m 13s)
Iter: 320, Loss 0.001289, Num updates: 320, Wall time: 1207.26, ETA: 0m 35s (- 0m 9s)
Iter: 360, Loss 0.001290, Num updates: 360, Wall time: 1211.24, ETA: 0m 39s (- 0m 4s)
Iter: 400, Loss 0.001293, Num updates: 400, Wall time: 1215.11, ETA: 0m 43s (- 0m 0s)
Evaluating...
epoch 26, time: 44.21
	train_loss: 0.0013, score: 27.94
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001223, Num updates: 40, Wall time: 1222.82, ETA: 0m 6s (- 1m 0s)
Iter: 80, Loss 0.001253, Num updates: 80, Wall time: 1227.11, ETA: 0m 10s (- 0m 44s)
Iter: 120, Loss 0.001254, Num updates: 120, Wall time: 1231.26, ETA: 0m 14s (- 0m 35s)
Iter: 160, Loss 0.001261, Num updates: 160, Wall time: 1235.37, ETA: 0m 19s (- 0m 28s)
Iter: 200, Loss 0.001266, Num updates: 200, Wall time: 1239.44, ETA: 0m 23s (- 0m 23s)
Iter: 240, Loss 0.001275, Num updates: 240, Wall time: 1243.50, ETA: 0m 27s (- 0m 18s)
Iter: 280, Loss 0.001281, Num updates: 280, Wall time: 1247.75, ETA: 0m 31s (- 0m 13s)
Iter: 320, Loss 0.001283, Num updates: 320, Wall time: 1252.43, ETA: 0m 36s (- 0m 9s)
Iter: 360, Loss 0.001282, Num updates: 360, Wall time: 1256.70, ETA: 0m 40s (- 0m 4s)
Iter: 400, Loss 0.001284, Num updates: 400, Wall time: 1260.88, ETA: 0m 44s (- 0m 0s)
Evaluating...
epoch 27, time: 45.55
	train_loss: 0.0013, score: 27.15
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001222, Num updates: 40, Wall time: 1268.00, ETA: 0m 5s (- 0m 54s)
Iter: 80, Loss 0.001224, Num updates: 80, Wall time: 1272.08, ETA: 0m 9s (- 0m 40s)
Iter: 120, Loss 0.001242, Num updates: 120, Wall time: 1276.48, ETA: 0m 14s (- 0m 33s)
Iter: 160, Loss 0.001248, Num updates: 160, Wall time: 1280.38, ETA: 0m 18s (- 0m 27s)
Iter: 200, Loss 0.001259, Num updates: 200, Wall time: 1284.39, ETA: 0m 22s (- 0m 22s)
Iter: 240, Loss 0.001264, Num updates: 240, Wall time: 1288.58, ETA: 0m 26s (- 0m 17s)
Iter: 280, Loss 0.001263, Num updates: 280, Wall time: 1293.10, ETA: 0m 30s (- 0m 13s)
Iter: 320, Loss 0.001270, Num updates: 320, Wall time: 1297.38, ETA: 0m 35s (- 0m 8s)
Iter: 360, Loss 0.001273, Num updates: 360, Wall time: 1301.45, ETA: 0m 39s (- 0m 4s)
Iter: 400, Loss 0.001276, Num updates: 400, Wall time: 1305.83, ETA: 0m 43s (- 0m 0s)
Evaluating...
epoch 28, time: 44.58
	train_loss: 0.0013, score: 27.90
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001228, Num updates: 40, Wall time: 1312.61, ETA: 0m 5s (- 0m 52s)
Iter: 80, Loss 0.001234, Num updates: 80, Wall time: 1316.76, ETA: 0m 9s (- 0m 39s)
Iter: 120, Loss 0.001244, Num updates: 120, Wall time: 1320.27, ETA: 0m 13s (- 0m 31s)
Iter: 160, Loss 0.001255, Num updates: 160, Wall time: 1323.86, ETA: 0m 16s (- 0m 25s)
Iter: 200, Loss 0.001250, Num updates: 200, Wall time: 1328.23, ETA: 0m 21s (- 0m 21s)
Iter: 240, Loss 0.001252, Num updates: 240, Wall time: 1332.31, ETA: 0m 25s (- 0m 17s)
Iter: 280, Loss 0.001257, Num updates: 280, Wall time: 1336.10, ETA: 0m 29s (- 0m 12s)
Iter: 320, Loss 0.001256, Num updates: 320, Wall time: 1340.20, ETA: 0m 33s (- 0m 8s)
Iter: 360, Loss 0.001261, Num updates: 360, Wall time: 1344.08, ETA: 0m 37s (- 0m 4s)
Iter: 400, Loss 0.001265, Num updates: 400, Wall time: 1348.21, ETA: 0m 41s (- 0m 0s)
Evaluating...
epoch 29, time: 42.35
	train_loss: 0.0013, score: 28.58
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001201, Num updates: 40, Wall time: 1355.28, ETA: 0m 5s (- 0m 53s)
Iter: 80, Loss 0.001213, Num updates: 80, Wall time: 1359.50, ETA: 0m 9s (- 0m 40s)
Iter: 120, Loss 0.001229, Num updates: 120, Wall time: 1363.65, ETA: 0m 14s (- 0m 33s)
Iter: 160, Loss 0.001234, Num updates: 160, Wall time: 1367.97, ETA: 0m 18s (- 0m 27s)
Iter: 200, Loss 0.001240, Num updates: 200, Wall time: 1372.22, ETA: 0m 22s (- 0m 22s)
Iter: 240, Loss 0.001250, Num updates: 240, Wall time: 1376.54, ETA: 0m 27s (- 0m 18s)
Iter: 280, Loss 0.001250, Num updates: 280, Wall time: 1380.89, ETA: 0m 31s (- 0m 13s)
Iter: 320, Loss 0.001253, Num updates: 320, Wall time: 1384.92, ETA: 0m 35s (- 0m 8s)
Iter: 360, Loss 0.001253, Num updates: 360, Wall time: 1389.31, ETA: 0m 39s (- 0m 4s)
Iter: 400, Loss 0.001258, Num updates: 400, Wall time: 1393.69, ETA: 0m 44s (- 0m 0s)
Evaluating...
epoch 30, time: 45.14
	train_loss: 0.0013, score: 27.46
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001215, Num updates: 40, Wall time: 1400.75, ETA: 0m 5s (- 0m 53s)
Iter: 80, Loss 0.001235, Num updates: 80, Wall time: 1405.15, ETA: 0m 10s (- 0m 41s)
Iter: 120, Loss 0.001237, Num updates: 120, Wall time: 1409.25, ETA: 0m 14s (- 0m 33s)
Iter: 160, Loss 0.001247, Num updates: 160, Wall time: 1413.52, ETA: 0m 18s (- 0m 28s)
Iter: 200, Loss 0.001255, Num updates: 200, Wall time: 1417.59, ETA: 0m 22s (- 0m 22s)
Iter: 240, Loss 0.001256, Num updates: 240, Wall time: 1421.71, ETA: 0m 26s (- 0m 18s)
Iter: 280, Loss 0.001251, Num updates: 280, Wall time: 1425.95, ETA: 0m 31s (- 0m 13s)
Iter: 320, Loss 0.001251, Num updates: 320, Wall time: 1430.09, ETA: 0m 35s (- 0m 8s)
Iter: 360, Loss 0.001249, Num updates: 360, Wall time: 1434.42, ETA: 0m 39s (- 0m 4s)
Iter: 400, Loss 0.001251, Num updates: 400, Wall time: 1438.40, ETA: 0m 43s (- 0m 0s)
Evaluating...
epoch 31, time: 44.33
	train_loss: 0.0013, score: 27.65
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001201, Num updates: 40, Wall time: 1445.20, ETA: 0m 5s (- 0m 52s)
Iter: 80, Loss 0.001216, Num updates: 80, Wall time: 1449.31, ETA: 0m 9s (- 0m 39s)
Iter: 120, Loss 0.001222, Num updates: 120, Wall time: 1453.51, ETA: 0m 13s (- 0m 33s)
Iter: 160, Loss 0.001224, Num updates: 160, Wall time: 1457.87, ETA: 0m 18s (- 0m 27s)
Iter: 200, Loss 0.001227, Num updates: 200, Wall time: 1462.19, ETA: 0m 22s (- 0m 22s)
Iter: 240, Loss 0.001237, Num updates: 240, Wall time: 1466.03, ETA: 0m 26s (- 0m 17s)
Iter: 280, Loss 0.001239, Num updates: 280, Wall time: 1470.08, ETA: 0m 30s (- 0m 13s)
Iter: 320, Loss 0.001239, Num updates: 320, Wall time: 1474.18, ETA: 0m 34s (- 0m 8s)
Iter: 360, Loss 0.001239, Num updates: 360, Wall time: 1478.38, ETA: 0m 38s (- 0m 4s)
Iter: 400, Loss 0.001241, Num updates: 400, Wall time: 1482.78, ETA: 0m 43s (- 0m 0s)
Evaluating...
epoch 32, time: 44.04
	train_loss: 0.0012, score: 28.31
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001198, Num updates: 40, Wall time: 1490.08, ETA: 0m 6s (- 0m 58s)
Iter: 80, Loss 0.001205, Num updates: 80, Wall time: 1494.30, ETA: 0m 10s (- 0m 42s)
Iter: 120, Loss 0.001211, Num updates: 120, Wall time: 1498.48, ETA: 0m 14s (- 0m 34s)
Iter: 160, Loss 0.001213, Num updates: 160, Wall time: 1502.49, ETA: 0m 18s (- 0m 28s)
Iter: 200, Loss 0.001222, Num updates: 200, Wall time: 1506.42, ETA: 0m 22s (- 0m 22s)
Iter: 240, Loss 0.001225, Num updates: 240, Wall time: 1510.43, ETA: 0m 26s (- 0m 17s)
Iter: 280, Loss 0.001228, Num updates: 280, Wall time: 1514.77, ETA: 0m 30s (- 0m 13s)
Iter: 320, Loss 0.001230, Num updates: 320, Wall time: 1518.99, ETA: 0m 35s (- 0m 8s)
Iter: 360, Loss 0.001232, Num updates: 360, Wall time: 1523.23, ETA: 0m 39s (- 0m 4s)
Iter: 400, Loss 0.001235, Num updates: 400, Wall time: 1527.19, ETA: 0m 43s (- 0m 0s)
Evaluating...
epoch 33, time: 44.37
	train_loss: 0.0012, score: 27.62
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001214, Num updates: 40, Wall time: 1534.72, ETA: 0m 6s (- 0m 58s)
Iter: 80, Loss 0.001214, Num updates: 80, Wall time: 1538.82, ETA: 0m 10s (- 0m 42s)
Iter: 120, Loss 0.001209, Num updates: 120, Wall time: 1543.11, ETA: 0m 14s (- 0m 34s)
Iter: 160, Loss 0.001208, Num updates: 160, Wall time: 1547.36, ETA: 0m 18s (- 0m 28s)
Iter: 200, Loss 0.001210, Num updates: 200, Wall time: 1551.61, ETA: 0m 23s (- 0m 23s)
Iter: 240, Loss 0.001210, Num updates: 240, Wall time: 1555.82, ETA: 0m 27s (- 0m 18s)
Iter: 280, Loss 0.001217, Num updates: 280, Wall time: 1559.83, ETA: 0m 31s (- 0m 13s)
Iter: 320, Loss 0.001216, Num updates: 320, Wall time: 1564.04, ETA: 0m 35s (- 0m 9s)
Iter: 360, Loss 0.001221, Num updates: 360, Wall time: 1567.97, ETA: 0m 39s (- 0m 4s)
Iter: 400, Loss 0.001224, Num updates: 400, Wall time: 1572.21, ETA: 0m 43s (- 0m 0s)
Evaluating...
epoch 34, time: 44.69
	train_loss: 0.0012, score: 28.04
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001151, Num updates: 40, Wall time: 1579.25, ETA: 0m 5s (- 0m 54s)
Iter: 80, Loss 0.001184, Num updates: 80, Wall time: 1583.18, ETA: 0m 9s (- 0m 39s)
Iter: 120, Loss 0.001196, Num updates: 120, Wall time: 1587.46, ETA: 0m 14s (- 0m 33s)
Iter: 160, Loss 0.001204, Num updates: 160, Wall time: 1591.58, ETA: 0m 18s (- 0m 27s)
Iter: 200, Loss 0.001205, Num updates: 200, Wall time: 1595.62, ETA: 0m 22s (- 0m 22s)
Iter: 240, Loss 0.001208, Num updates: 240, Wall time: 1599.91, ETA: 0m 26s (- 0m 17s)
Iter: 280, Loss 0.001209, Num updates: 280, Wall time: 1604.34, ETA: 0m 30s (- 0m 13s)
Iter: 320, Loss 0.001214, Num updates: 320, Wall time: 1608.50, ETA: 0m 35s (- 0m 8s)
Iter: 360, Loss 0.001218, Num updates: 360, Wall time: 1612.60, ETA: 0m 39s (- 0m 4s)
Iter: 400, Loss 0.001219, Num updates: 400, Wall time: 1616.51, ETA: 0m 43s (- 0m 0s)
Evaluating...
epoch 35, time: 43.79
	train_loss: 0.0012, score: 28.66
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001163, Num updates: 40, Wall time: 1623.39, ETA: 0m 5s (- 0m 55s)
Iter: 80, Loss 0.001184, Num updates: 80, Wall time: 1627.45, ETA: 0m 10s (- 0m 40s)
Iter: 120, Loss 0.001205, Num updates: 120, Wall time: 1631.35, ETA: 0m 13s (- 0m 32s)
Iter: 160, Loss 0.001205, Num updates: 160, Wall time: 1635.70, ETA: 0m 18s (- 0m 27s)
Iter: 200, Loss 0.001208, Num updates: 200, Wall time: 1639.72, ETA: 0m 22s (- 0m 22s)
Iter: 240, Loss 0.001212, Num updates: 240, Wall time: 1644.18, ETA: 0m 26s (- 0m 18s)
Iter: 280, Loss 0.001214, Num updates: 280, Wall time: 1648.44, ETA: 0m 31s (- 0m 13s)
Iter: 320, Loss 0.001215, Num updates: 320, Wall time: 1653.72, ETA: 0m 36s (- 0m 9s)
Iter: 360, Loss 0.001213, Num updates: 360, Wall time: 1659.43, ETA: 0m 41s (- 0m 4s)
Iter: 400, Loss 0.001214, Num updates: 400, Wall time: 1664.01, ETA: 0m 46s (- 0m 0s)
Evaluating...
epoch 36, time: 48.20
	train_loss: 0.0012, score: 27.85
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001158, Num updates: 40, Wall time: 1672.84, ETA: 0m 6s (- 1m 4s)
Iter: 80, Loss 0.001185, Num updates: 80, Wall time: 1677.73, ETA: 0m 11s (- 0m 48s)
Iter: 120, Loss 0.001184, Num updates: 120, Wall time: 1682.79, ETA: 0m 16s (- 0m 39s)
Iter: 160, Loss 0.001188, Num updates: 160, Wall time: 1687.22, ETA: 0m 21s (- 0m 32s)
Iter: 200, Loss 0.001195, Num updates: 200, Wall time: 1691.58, ETA: 0m 25s (- 0m 25s)
Iter: 240, Loss 0.001197, Num updates: 240, Wall time: 1695.65, ETA: 0m 29s (- 0m 20s)
Iter: 280, Loss 0.001202, Num updates: 280, Wall time: 1699.89, ETA: 0m 34s (- 0m 14s)
Iter: 320, Loss 0.001201, Num updates: 320, Wall time: 1703.95, ETA: 0m 38s (- 0m 9s)
Iter: 360, Loss 0.001205, Num updates: 360, Wall time: 1707.88, ETA: 0m 42s (- 0m 4s)
Iter: 400, Loss 0.001206, Num updates: 400, Wall time: 1711.76, ETA: 0m 45s (- 0m 0s)
Evaluating...
epoch 37, time: 46.83
	train_loss: 0.0012, score: 27.82
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001144, Num updates: 40, Wall time: 1719.66, ETA: 0m 6s (- 1m 1s)
Iter: 80, Loss 0.001166, Num updates: 80, Wall time: 1723.89, ETA: 0m 10s (- 0m 44s)
Iter: 120, Loss 0.001176, Num updates: 120, Wall time: 1728.18, ETA: 0m 15s (- 0m 35s)
Iter: 160, Loss 0.001180, Num updates: 160, Wall time: 1732.36, ETA: 0m 19s (- 0m 29s)
Iter: 200, Loss 0.001187, Num updates: 200, Wall time: 1736.20, ETA: 0m 23s (- 0m 23s)
Iter: 240, Loss 0.001189, Num updates: 240, Wall time: 1740.18, ETA: 0m 27s (- 0m 18s)
Iter: 280, Loss 0.001194, Num updates: 280, Wall time: 1744.14, ETA: 0m 31s (- 0m 13s)
Iter: 320, Loss 0.001193, Num updates: 320, Wall time: 1748.22, ETA: 0m 35s (- 0m 8s)
Iter: 360, Loss 0.001195, Num updates: 360, Wall time: 1752.74, ETA: 0m 39s (- 0m 4s)
Iter: 400, Loss 0.001196, Num updates: 400, Wall time: 1756.80, ETA: 0m 43s (- 0m 0s)
Evaluating...
epoch 38, time: 45.02
	train_loss: 0.0012, score: 28.26
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001179, Num updates: 40, Wall time: 1764.41, ETA: 0m 6s (- 0m 57s)
Iter: 80, Loss 0.001177, Num updates: 80, Wall time: 1769.19, ETA: 0m 10s (- 0m 44s)
Iter: 120, Loss 0.001180, Num updates: 120, Wall time: 1773.78, ETA: 0m 15s (- 0m 36s)
Iter: 160, Loss 0.001182, Num updates: 160, Wall time: 1778.26, ETA: 0m 20s (- 0m 30s)
Iter: 200, Loss 0.001181, Num updates: 200, Wall time: 1782.84, ETA: 0m 24s (- 0m 24s)
Iter: 240, Loss 0.001187, Num updates: 240, Wall time: 1788.06, ETA: 0m 29s (- 0m 20s)
Iter: 280, Loss 0.001192, Num updates: 280, Wall time: 1793.07, ETA: 0m 34s (- 0m 15s)
Iter: 320, Loss 0.001193, Num updates: 320, Wall time: 1798.02, ETA: 0m 39s (- 0m 10s)
Iter: 360, Loss 0.001194, Num updates: 360, Wall time: 1801.94, ETA: 0m 43s (- 0m 4s)
Iter: 400, Loss 0.001195, Num updates: 400, Wall time: 1806.06, ETA: 0m 47s (- 0m 0s)
Evaluating...
epoch 39, time: 49.09
	train_loss: 0.0012, score: 27.66
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001145, Num updates: 40, Wall time: 1814.64, ETA: 0m 7s (- 1m 5s)
Iter: 80, Loss 0.001169, Num updates: 80, Wall time: 1819.02, ETA: 0m 11s (- 0m 46s)
Iter: 120, Loss 0.001184, Num updates: 120, Wall time: 1823.04, ETA: 0m 15s (- 0m 36s)
Iter: 160, Loss 0.001180, Num updates: 160, Wall time: 1826.84, ETA: 0m 19s (- 0m 29s)
Iter: 200, Loss 0.001179, Num updates: 200, Wall time: 1830.92, ETA: 0m 23s (- 0m 23s)
Iter: 240, Loss 0.001180, Num updates: 240, Wall time: 1835.10, ETA: 0m 27s (- 0m 18s)
Iter: 280, Loss 0.001183, Num updates: 280, Wall time: 1839.21, ETA: 0m 31s (- 0m 13s)
Iter: 320, Loss 0.001186, Num updates: 320, Wall time: 1844.25, ETA: 0m 36s (- 0m 9s)
Iter: 360, Loss 0.001190, Num updates: 360, Wall time: 1848.90, ETA: 0m 41s (- 0m 4s)
Iter: 400, Loss 0.001191, Num updates: 400, Wall time: 1853.65, ETA: 0m 46s (- 0m 0s)
Evaluating...
epoch 40, time: 47.72
	train_loss: 0.0012, score: 27.65
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001134, Num updates: 40, Wall time: 1862.17, ETA: 0m 6s (- 1m 1s)
Iter: 80, Loss 0.001168, Num updates: 80, Wall time: 1866.90, ETA: 0m 11s (- 0m 46s)
Iter: 120, Loss 0.001170, Num updates: 120, Wall time: 1871.68, ETA: 0m 16s (- 0m 38s)
Iter: 160, Loss 0.001183, Num updates: 160, Wall time: 1876.22, ETA: 0m 20s (- 0m 31s)
Iter: 200, Loss 0.001183, Num updates: 200, Wall time: 1880.94, ETA: 0m 25s (- 0m 25s)
Iter: 240, Loss 0.001185, Num updates: 240, Wall time: 1885.13, ETA: 0m 29s (- 0m 19s)
Iter: 280, Loss 0.001186, Num updates: 280, Wall time: 1889.59, ETA: 0m 34s (- 0m 14s)
Iter: 320, Loss 0.001186, Num updates: 320, Wall time: 1894.49, ETA: 0m 38s (- 0m 9s)
Iter: 360, Loss 0.001186, Num updates: 360, Wall time: 1899.72, ETA: 0m 44s (- 0m 5s)
Iter: 400, Loss 0.001186, Num updates: 400, Wall time: 1904.71, ETA: 0m 49s (- 0m 0s)
Evaluating...
epoch 41, time: 50.21
	train_loss: 0.0012, score: 28.44
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001139, Num updates: 40, Wall time: 1912.72, ETA: 0m 6s (- 1m 2s)
Iter: 80, Loss 0.001159, Num updates: 80, Wall time: 1917.32, ETA: 0m 11s (- 0m 46s)
Iter: 120, Loss 0.001164, Num updates: 120, Wall time: 1921.77, ETA: 0m 15s (- 0m 37s)
Iter: 160, Loss 0.001170, Num updates: 160, Wall time: 1926.31, ETA: 0m 20s (- 0m 30s)
Iter: 200, Loss 0.001173, Num updates: 200, Wall time: 1931.34, ETA: 0m 25s (- 0m 25s)
Iter: 240, Loss 0.001174, Num updates: 240, Wall time: 1936.04, ETA: 0m 30s (- 0m 20s)
Iter: 280, Loss 0.001175, Num updates: 280, Wall time: 1940.43, ETA: 0m 34s (- 0m 14s)
Iter: 320, Loss 0.001176, Num updates: 320, Wall time: 1945.61, ETA: 0m 39s (- 0m 10s)
Iter: 360, Loss 0.001177, Num updates: 360, Wall time: 1950.71, ETA: 0m 44s (- 0m 5s)
Iter: 400, Loss 0.001179, Num updates: 400, Wall time: 1955.00, ETA: 0m 49s (- 0m 0s)
Evaluating...
epoch 42, time: 50.02
	train_loss: 0.0012, score: 27.35
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001147, Num updates: 40, Wall time: 1962.39, ETA: 0m 6s (- 0m 56s)
Iter: 80, Loss 0.001156, Num updates: 80, Wall time: 1966.83, ETA: 0m 10s (- 0m 42s)
Iter: 120, Loss 0.001163, Num updates: 120, Wall time: 1971.41, ETA: 0m 15s (- 0m 35s)
Iter: 160, Loss 0.001159, Num updates: 160, Wall time: 1975.67, ETA: 0m 19s (- 0m 29s)
Iter: 200, Loss 0.001166, Num updates: 200, Wall time: 1981.20, ETA: 0m 24s (- 0m 25s)
Iter: 240, Loss 0.001168, Num updates: 240, Wall time: 1986.04, ETA: 0m 29s (- 0m 20s)
Iter: 280, Loss 0.001168, Num updates: 280, Wall time: 1990.72, ETA: 0m 34s (- 0m 14s)
Iter: 320, Loss 0.001169, Num updates: 320, Wall time: 1995.34, ETA: 0m 39s (- 0m 9s)
Iter: 360, Loss 0.001170, Num updates: 360, Wall time: 2000.16, ETA: 0m 43s (- 0m 5s)
Iter: 400, Loss 0.001172, Num updates: 400, Wall time: 2004.97, ETA: 0m 48s (- 0m 0s)
Evaluating...
epoch 43, time: 49.59
	train_loss: 0.0012, score: 27.10
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001131, Num updates: 40, Wall time: 2011.78, ETA: 0m 5s (- 0m 52s)
Iter: 80, Loss 0.001157, Num updates: 80, Wall time: 2016.03, ETA: 0m 9s (- 0m 40s)
Iter: 120, Loss 0.001141, Num updates: 120, Wall time: 2019.88, ETA: 0m 13s (- 0m 32s)
Iter: 160, Loss 0.001149, Num updates: 160, Wall time: 2024.46, ETA: 0m 18s (- 0m 27s)
Iter: 200, Loss 0.001154, Num updates: 200, Wall time: 2029.37, ETA: 0m 23s (- 0m 23s)
Iter: 240, Loss 0.001156, Num updates: 240, Wall time: 2034.43, ETA: 0m 28s (- 0m 19s)
Iter: 280, Loss 0.001159, Num updates: 280, Wall time: 2039.24, ETA: 0m 33s (- 0m 14s)
Iter: 320, Loss 0.001163, Num updates: 320, Wall time: 2043.56, ETA: 0m 37s (- 0m 9s)
Iter: 360, Loss 0.001166, Num updates: 360, Wall time: 2048.19, ETA: 0m 42s (- 0m 4s)
Iter: 400, Loss 0.001167, Num updates: 400, Wall time: 2052.39, ETA: 0m 46s (- 0m 0s)
Evaluating...
epoch 44, time: 47.22
	train_loss: 0.0012, score: 28.30
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001145, Num updates: 40, Wall time: 2059.72, ETA: 0m 6s (- 0m 56s)
Iter: 80, Loss 0.001145, Num updates: 80, Wall time: 2064.57, ETA: 0m 10s (- 0m 44s)
Iter: 120, Loss 0.001147, Num updates: 120, Wall time: 2068.92, ETA: 0m 15s (- 0m 36s)
Iter: 160, Loss 0.001158, Num updates: 160, Wall time: 2073.52, ETA: 0m 19s (- 0m 30s)
Iter: 200, Loss 0.001155, Num updates: 200, Wall time: 2078.07, ETA: 0m 24s (- 0m 24s)
Iter: 240, Loss 0.001159, Num updates: 240, Wall time: 2083.16, ETA: 0m 29s (- 0m 19s)
Iter: 280, Loss 0.001164, Num updates: 280, Wall time: 2088.01, ETA: 0m 34s (- 0m 14s)
Iter: 320, Loss 0.001161, Num updates: 320, Wall time: 2093.61, ETA: 0m 39s (- 0m 10s)
Iter: 360, Loss 0.001161, Num updates: 360, Wall time: 2099.65, ETA: 0m 46s (- 0m 5s)
Iter: 400, Loss 0.001161, Num updates: 400, Wall time: 2106.96, ETA: 0m 53s (- 0m 0s)
Evaluating...
epoch 45, time: 55.02
	train_loss: 0.0012, score: 27.62
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001143, Num updates: 40, Wall time: 2116.69, ETA: 0m 7s (- 1m 12s)
Iter: 80, Loss 0.001151, Num updates: 80, Wall time: 2121.71, ETA: 0m 12s (- 0m 52s)
Iter: 120, Loss 0.001159, Num updates: 120, Wall time: 2126.60, ETA: 0m 17s (- 0m 41s)
Iter: 160, Loss 0.001150, Num updates: 160, Wall time: 2131.63, ETA: 0m 22s (- 0m 34s)
Iter: 200, Loss 0.001152, Num updates: 200, Wall time: 2135.94, ETA: 0m 27s (- 0m 27s)
Iter: 240, Loss 0.001151, Num updates: 240, Wall time: 2140.49, ETA: 0m 31s (- 0m 21s)
Iter: 280, Loss 0.001157, Num updates: 280, Wall time: 2145.01, ETA: 0m 36s (- 0m 15s)
Iter: 320, Loss 0.001157, Num updates: 320, Wall time: 2149.63, ETA: 0m 40s (- 0m 10s)
Iter: 360, Loss 0.001157, Num updates: 360, Wall time: 2154.02, ETA: 0m 45s (- 0m 5s)
Iter: 400, Loss 0.001159, Num updates: 400, Wall time: 2157.91, ETA: 0m 49s (- 0m 0s)
Evaluating...
epoch 46, time: 50.00
	train_loss: 0.0012, score: 27.55
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001113, Num updates: 40, Wall time: 2165.13, ETA: 0m 6s (- 0m 55s)
Iter: 80, Loss 0.001136, Num updates: 80, Wall time: 2168.84, ETA: 0m 9s (- 0m 39s)
Iter: 120, Loss 0.001143, Num updates: 120, Wall time: 2172.94, ETA: 0m 13s (- 0m 32s)
Iter: 160, Loss 0.001143, Num updates: 160, Wall time: 2177.04, ETA: 0m 17s (- 0m 27s)
Iter: 200, Loss 0.001148, Num updates: 200, Wall time: 2181.49, ETA: 0m 22s (- 0m 22s)
Iter: 240, Loss 0.001153, Num updates: 240, Wall time: 2185.72, ETA: 0m 26s (- 0m 17s)
Iter: 280, Loss 0.001151, Num updates: 280, Wall time: 2190.10, ETA: 0m 30s (- 0m 13s)
Iter: 320, Loss 0.001149, Num updates: 320, Wall time: 2194.09, ETA: 0m 34s (- 0m 8s)
Iter: 360, Loss 0.001150, Num updates: 360, Wall time: 2198.17, ETA: 0m 39s (- 0m 4s)
Iter: 400, Loss 0.001152, Num updates: 400, Wall time: 2202.36, ETA: 0m 43s (- 0m 0s)
Evaluating...
epoch 47, time: 44.19
	train_loss: 0.0012, score: 28.37
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001107, Num updates: 40, Wall time: 2209.85, ETA: 0m 6s (- 0m 58s)
Iter: 80, Loss 0.001121, Num updates: 80, Wall time: 2214.26, ETA: 0m 10s (- 0m 43s)
Iter: 120, Loss 0.001138, Num updates: 120, Wall time: 2218.50, ETA: 0m 14s (- 0m 35s)
Iter: 160, Loss 0.001146, Num updates: 160, Wall time: 2223.03, ETA: 0m 19s (- 0m 29s)
Iter: 200, Loss 0.001148, Num updates: 200, Wall time: 2227.54, ETA: 0m 23s (- 0m 24s)
Iter: 240, Loss 0.001145, Num updates: 240, Wall time: 2231.71, ETA: 0m 28s (- 0m 18s)
Iter: 280, Loss 0.001140, Num updates: 280, Wall time: 2236.74, ETA: 0m 33s (- 0m 14s)
Iter: 320, Loss 0.001144, Num updates: 320, Wall time: 2241.30, ETA: 0m 37s (- 0m 9s)
Iter: 360, Loss 0.001147, Num updates: 360, Wall time: 2246.26, ETA: 0m 42s (- 0m 4s)
Iter: 400, Loss 0.001148, Num updates: 400, Wall time: 2251.08, ETA: 0m 47s (- 0m 0s)
Evaluating...
epoch 48, time: 48.84
	train_loss: 0.0012, score: 27.48
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001098, Num updates: 40, Wall time: 2259.16, ETA: 0m 6s (- 1m 0s)
Iter: 80, Loss 0.001110, Num updates: 80, Wall time: 2263.85, ETA: 0m 11s (- 0m 45s)
Iter: 120, Loss 0.001123, Num updates: 120, Wall time: 2268.46, ETA: 0m 15s (- 0m 37s)
Iter: 160, Loss 0.001130, Num updates: 160, Wall time: 2273.64, ETA: 0m 20s (- 0m 31s)
Iter: 200, Loss 0.001133, Num updates: 200, Wall time: 2278.50, ETA: 0m 25s (- 0m 26s)
Iter: 240, Loss 0.001133, Num updates: 240, Wall time: 2283.33, ETA: 0m 30s (- 0m 20s)
Iter: 280, Loss 0.001138, Num updates: 280, Wall time: 2288.14, ETA: 0m 35s (- 0m 15s)
Iter: 320, Loss 0.001143, Num updates: 320, Wall time: 2292.85, ETA: 0m 40s (- 0m 10s)
Iter: 360, Loss 0.001143, Num updates: 360, Wall time: 2297.85, ETA: 0m 45s (- 0m 5s)
Iter: 400, Loss 0.001145, Num updates: 400, Wall time: 2302.41, ETA: 0m 49s (- 0m 0s)
Evaluating...
epoch 49, time: 50.67
	train_loss: 0.0011, score: 27.39
	eval score: 0.00 (0.00)
0.00404,0.00179,0.00172,0.00167,0.00165,0.00163,0.00161,0.00159,0.00158,0.00156,0.00154,0.00152,0.00151,0.00149,0.00147,0.00145,0.00144,0.00142,0.0014,0.00139,0.00137,0.00136,0.00134,0.00133,0.00132,0.00131,0.0013,0.00129,0.00128,0.00127,0.00126,0.00125,0.00124,0.00124,0.00123,0.00122,0.00122,0.00121,0.0012,0.0012,0.00119,0.00119,0.00118,0.00117,0.00117,0.00116,0.00116,0.00115,0.00115,0.00115
0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
saved_model_Med2019/BAN_MEVF
Namespace(RAD_dir='/home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019', activation='relu', ae_alpha=0.001, ae_model_path='pretrained_ae.pth', alpha=1.0, autoencoder=True, batch_size=32, clip_norm=0.25, dropout=0.5, epochs=60, eps_cnn=1e-05, feat_dim=32, five_fold=False, gamma=2, gpu=0, input=None, lr=0.03, maml=True, maml_model_path='pretrained_maml.weights', model='SAN', momentum_cnn=0.05, num_hid=1024, num_stacks=2, op='c', output='saved_model_Med2019/BAN_MEVF', pow=2, print_interval=40, qc_model_path='./saved_models/QC/rad_best.pth', question_len=12, record_id=1, rescale_factor=1.5, rnn='LSTM', seed=3, tfidf=True, update_freq='1', use_RAD=True, use_ablation=False, use_ablation_q=False, use_ablation_v=False, use_counter=False, use_grad_cam=False, use_kl_mix=False, use_mix=True, use_mix_all=False, use_mix_cond=True, use_mix_cond_q=True, use_mix_cond_v=False, use_mix_cond_vq_in=False, use_mix_cond_vq_union=False, use_partial_label=False, use_rescale=False, use_sep_mix=False)
loading dictionary from /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/dictionary.pkl
loading MAML image data from file: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/images84x84.pkl
loading DAE image data from file: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/images128x128.pkl
loading MAML image data from file: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/images84x84.pkl
loading DAE image data from file: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/images128x128.pkl
load initial weights MAML from: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/pretrained_maml.weights
load initial weights DAE from: /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/pretrained_ae.pth
loading dictionary from /home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019/dictionary.pkl
Loading embedding tfidf and weights from file
Load embedding tfidf and weights from file successfully
Namespace(RAD_dir='/home/coder/projects/MEVF/MICCAI19-MedVQA/data_Med/VQA-Med-2019', activation='relu', ae_alpha=0.001, ae_model_path='pretrained_ae.pth', alpha=1.0, autoencoder=True, batch_size=32, clip_norm=0.25, device=device(type='cuda', index=0), dropout=0.5, epochs=60, eps_cnn=1e-05, feat_dim=64, five_fold=False, gamma=2, gpu=0, input=None, lr=0.03, maml=True, maml_model_path='pretrained_maml.weights', model='SAN', momentum_cnn=0.05, num_hid=1024, num_stacks=2, op='c', output='saved_model_Med2019/BAN_MEVF', pow=2, print_interval=40, qc_model_path='./saved_models/QC/rad_best.pth', question_len=12, record_id=1, rescale_factor=1.5, rnn='LSTM', seed=3, tfidf=True, update_freq='1', use_RAD=True, use_ablation=False, use_ablation_q=False, use_ablation_v=False, use_counter=False, use_grad_cam=False, use_kl_mix=False, use_mix=True, use_mix_all=False, use_mix_cond=True, use_mix_cond_q=True, use_mix_cond_v=False, use_mix_cond_vq_in=False, use_mix_cond_vq_union=False, use_partial_label=False, use_rescale=False, use_sep_mix=False)
nParams=	15692100
optim: adamax lr=0.0300, decay_step=3, decay_rate=0.75, grad_clip=0.25
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'language_model.WordEmbedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Iter: 40, Loss 0.023748, Num updates: 40, Wall time: 6.72, ETA: 0m 6s (- 0m 56s)
Iter: 80, Loss 0.013084, Num updates: 80, Wall time: 10.40, ETA: 0m 9s (- 0m 39s)
Iter: 120, Loss 0.009461, Num updates: 120, Wall time: 14.05, ETA: 0m 13s (- 0m 31s)
Iter: 160, Loss 0.007651, Num updates: 160, Wall time: 17.73, ETA: 0m 17s (- 0m 25s)
Iter: 200, Loss 0.006556, Num updates: 200, Wall time: 21.47, ETA: 0m 20s (- 0m 21s)
Iter: 240, Loss 0.005825, Num updates: 240, Wall time: 25.06, ETA: 0m 24s (- 0m 16s)
Iter: 280, Loss 0.005292, Num updates: 280, Wall time: 28.71, ETA: 0m 28s (- 0m 12s)
Iter: 320, Loss 0.004888, Num updates: 320, Wall time: 32.57, ETA: 0m 31s (- 0m 8s)
Iter: 360, Loss 0.004570, Num updates: 360, Wall time: 36.38, ETA: 0m 35s (- 0m 4s)
Iter: 400, Loss 0.004304, Num updates: 400, Wall time: 40.61, ETA: 0m 39s (- 0m 0s)
Evaluating...
epoch 0, time: 41.00
	train_loss: 0.0043, score: 11.35
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001900, Num updates: 40, Wall time: 47.07, ETA: 0m 5s (- 0m 48s)
Iter: 80, Loss 0.001889, Num updates: 80, Wall time: 50.80, ETA: 0m 8s (- 0m 36s)
Iter: 120, Loss 0.001896, Num updates: 120, Wall time: 54.59, ETA: 0m 12s (- 0m 30s)
Iter: 160, Loss 0.001903, Num updates: 160, Wall time: 58.38, ETA: 0m 16s (- 0m 25s)
Iter: 200, Loss 0.001900, Num updates: 200, Wall time: 61.63, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001896, Num updates: 240, Wall time: 65.12, ETA: 0m 23s (- 0m 15s)
Iter: 280, Loss 0.001896, Num updates: 280, Wall time: 68.65, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001888, Num updates: 320, Wall time: 72.21, ETA: 0m 30s (- 0m 7s)
Iter: 360, Loss 0.001881, Num updates: 360, Wall time: 75.87, ETA: 0m 34s (- 0m 3s)
Iter: 400, Loss 0.001874, Num updates: 400, Wall time: 79.57, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 1, time: 38.75
	train_loss: 0.0019, score: 17.98
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001748, Num updates: 40, Wall time: 85.82, ETA: 0m 4s (- 0m 45s)
Iter: 80, Loss 0.001784, Num updates: 80, Wall time: 89.45, ETA: 0m 8s (- 0m 34s)
Iter: 120, Loss 0.001795, Num updates: 120, Wall time: 92.71, ETA: 0m 11s (- 0m 27s)
Iter: 160, Loss 0.001810, Num updates: 160, Wall time: 96.36, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001804, Num updates: 200, Wall time: 99.84, ETA: 0m 18s (- 0m 19s)
Iter: 240, Loss 0.001800, Num updates: 240, Wall time: 103.39, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001800, Num updates: 280, Wall time: 106.89, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001799, Num updates: 320, Wall time: 110.46, ETA: 0m 29s (- 0m 7s)
Iter: 360, Loss 0.001794, Num updates: 360, Wall time: 113.98, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001788, Num updates: 400, Wall time: 117.43, ETA: 0m 36s (- 0m 0s)
Evaluating...
epoch 2, time: 37.48
	train_loss: 0.0018, score: 19.20
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001689, Num updates: 40, Wall time: 122.79, ETA: 0m 4s (- 0m 38s)
Iter: 80, Loss 0.001698, Num updates: 80, Wall time: 126.18, ETA: 0m 7s (- 0m 30s)
Iter: 120, Loss 0.001712, Num updates: 120, Wall time: 129.73, ETA: 0m 11s (- 0m 26s)
Iter: 160, Loss 0.001709, Num updates: 160, Wall time: 133.28, ETA: 0m 14s (- 0m 22s)
Iter: 200, Loss 0.001714, Num updates: 200, Wall time: 136.84, ETA: 0m 18s (- 0m 18s)
Iter: 240, Loss 0.001713, Num updates: 240, Wall time: 140.33, ETA: 0m 21s (- 0m 14s)
Iter: 280, Loss 0.001710, Num updates: 280, Wall time: 143.83, ETA: 0m 25s (- 0m 10s)
Iter: 320, Loss 0.001711, Num updates: 320, Wall time: 147.47, ETA: 0m 28s (- 0m 7s)
Iter: 360, Loss 0.001713, Num updates: 360, Wall time: 150.72, ETA: 0m 32s (- 0m 3s)
Iter: 400, Loss 0.001710, Num updates: 400, Wall time: 154.28, ETA: 0m 35s (- 0m 0s)
Evaluating...
epoch 3, time: 36.61
	train_loss: 0.0017, score: 21.51
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001575, Num updates: 40, Wall time: 159.89, ETA: 0m 4s (- 0m 41s)
Iter: 80, Loss 0.001628, Num updates: 80, Wall time: 163.62, ETA: 0m 8s (- 0m 33s)
Iter: 120, Loss 0.001639, Num updates: 120, Wall time: 166.97, ETA: 0m 11s (- 0m 27s)
Iter: 160, Loss 0.001651, Num updates: 160, Wall time: 170.46, ETA: 0m 15s (- 0m 22s)
Iter: 200, Loss 0.001654, Num updates: 200, Wall time: 174.02, ETA: 0m 18s (- 0m 18s)
Iter: 240, Loss 0.001657, Num updates: 240, Wall time: 177.61, ETA: 0m 22s (- 0m 14s)
Iter: 280, Loss 0.001666, Num updates: 280, Wall time: 181.29, ETA: 0m 25s (- 0m 11s)
Iter: 320, Loss 0.001670, Num updates: 320, Wall time: 184.95, ETA: 0m 29s (- 0m 7s)
Iter: 360, Loss 0.001668, Num updates: 360, Wall time: 188.66, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001668, Num updates: 400, Wall time: 192.50, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 4, time: 37.65
	train_loss: 0.0017, score: 21.98
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001628, Num updates: 40, Wall time: 198.08, ETA: 0m 4s (- 0m 44s)
Iter: 80, Loss 0.001635, Num updates: 80, Wall time: 201.65, ETA: 0m 8s (- 0m 33s)
Iter: 120, Loss 0.001633, Num updates: 120, Wall time: 205.18, ETA: 0m 11s (- 0m 28s)
Iter: 160, Loss 0.001644, Num updates: 160, Wall time: 208.75, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001649, Num updates: 200, Wall time: 212.36, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001645, Num updates: 240, Wall time: 215.93, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001649, Num updates: 280, Wall time: 219.19, ETA: 0m 25s (- 0m 11s)
Iter: 320, Loss 0.001644, Num updates: 320, Wall time: 222.73, ETA: 0m 29s (- 0m 7s)
Iter: 360, Loss 0.001645, Num updates: 360, Wall time: 226.34, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001646, Num updates: 400, Wall time: 229.86, ETA: 0m 36s (- 0m 0s)
Evaluating...
epoch 5, time: 37.25
	train_loss: 0.0017, score: 22.46
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001602, Num updates: 40, Wall time: 235.89, ETA: 0m 4s (- 0m 43s)
Iter: 80, Loss 0.001612, Num updates: 80, Wall time: 239.52, ETA: 0m 8s (- 0m 34s)
Iter: 120, Loss 0.001620, Num updates: 120, Wall time: 243.13, ETA: 0m 11s (- 0m 28s)
Iter: 160, Loss 0.001620, Num updates: 160, Wall time: 246.65, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001630, Num updates: 200, Wall time: 250.28, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001628, Num updates: 240, Wall time: 253.70, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001631, Num updates: 280, Wall time: 257.40, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001630, Num updates: 320, Wall time: 261.08, ETA: 0m 29s (- 0m 7s)
Iter: 360, Loss 0.001629, Num updates: 360, Wall time: 264.42, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001630, Num updates: 400, Wall time: 268.09, ETA: 0m 36s (- 0m 0s)
Evaluating...
epoch 6, time: 37.80
	train_loss: 0.0016, score: 22.66
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001569, Num updates: 40, Wall time: 273.81, ETA: 0m 4s (- 0m 42s)
Iter: 80, Loss 0.001612, Num updates: 80, Wall time: 277.59, ETA: 0m 8s (- 0m 34s)
Iter: 120, Loss 0.001602, Num updates: 120, Wall time: 281.18, ETA: 0m 11s (- 0m 28s)
Iter: 160, Loss 0.001608, Num updates: 160, Wall time: 284.79, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001613, Num updates: 200, Wall time: 288.29, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001613, Num updates: 240, Wall time: 291.76, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001612, Num updates: 280, Wall time: 295.37, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001612, Num updates: 320, Wall time: 299.15, ETA: 0m 29s (- 0m 7s)
Iter: 360, Loss 0.001615, Num updates: 360, Wall time: 302.94, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001614, Num updates: 400, Wall time: 306.61, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 7, time: 38.37
	train_loss: 0.0016, score: 22.95
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001560, Num updates: 40, Wall time: 312.47, ETA: 0m 4s (- 0m 43s)
Iter: 80, Loss 0.001579, Num updates: 80, Wall time: 315.99, ETA: 0m 8s (- 0m 33s)
Iter: 120, Loss 0.001578, Num updates: 120, Wall time: 319.47, ETA: 0m 11s (- 0m 27s)
Iter: 160, Loss 0.001582, Num updates: 160, Wall time: 322.95, ETA: 0m 15s (- 0m 22s)
Iter: 200, Loss 0.001581, Num updates: 200, Wall time: 326.37, ETA: 0m 18s (- 0m 18s)
Iter: 240, Loss 0.001590, Num updates: 240, Wall time: 329.81, ETA: 0m 22s (- 0m 14s)
Iter: 280, Loss 0.001590, Num updates: 280, Wall time: 333.44, ETA: 0m 25s (- 0m 11s)
Iter: 320, Loss 0.001593, Num updates: 320, Wall time: 337.06, ETA: 0m 29s (- 0m 7s)
Iter: 360, Loss 0.001596, Num updates: 360, Wall time: 340.89, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001599, Num updates: 400, Wall time: 344.49, ETA: 0m 36s (- 0m 0s)
Evaluating...
epoch 8, time: 37.37
	train_loss: 0.0016, score: 23.31
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001519, Num updates: 40, Wall time: 350.12, ETA: 0m 4s (- 0m 43s)
Iter: 80, Loss 0.001533, Num updates: 80, Wall time: 353.64, ETA: 0m 8s (- 0m 33s)
Iter: 120, Loss 0.001554, Num updates: 120, Wall time: 357.19, ETA: 0m 11s (- 0m 27s)
Iter: 160, Loss 0.001565, Num updates: 160, Wall time: 360.90, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001564, Num updates: 200, Wall time: 364.55, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001566, Num updates: 240, Wall time: 368.32, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001574, Num updates: 280, Wall time: 372.06, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001578, Num updates: 320, Wall time: 375.65, ETA: 0m 30s (- 0m 7s)
Iter: 360, Loss 0.001580, Num updates: 360, Wall time: 379.25, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001583, Num updates: 400, Wall time: 382.89, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 9, time: 38.31
	train_loss: 0.0016, score: 23.41
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001543, Num updates: 40, Wall time: 388.79, ETA: 0m 4s (- 0m 44s)
Iter: 80, Loss 0.001566, Num updates: 80, Wall time: 392.34, ETA: 0m 8s (- 0m 33s)
Iter: 120, Loss 0.001570, Num updates: 120, Wall time: 396.09, ETA: 0m 12s (- 0m 28s)
Iter: 160, Loss 0.001569, Num updates: 160, Wall time: 399.87, ETA: 0m 15s (- 0m 24s)
Iter: 200, Loss 0.001574, Num updates: 200, Wall time: 403.61, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001572, Num updates: 240, Wall time: 406.83, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001573, Num updates: 280, Wall time: 410.47, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001572, Num updates: 320, Wall time: 414.15, ETA: 0m 30s (- 0m 7s)
Iter: 360, Loss 0.001572, Num updates: 360, Wall time: 417.54, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001569, Num updates: 400, Wall time: 421.16, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 10, time: 38.09
	train_loss: 0.0016, score: 23.83
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001527, Num updates: 40, Wall time: 427.10, ETA: 0m 4s (- 0m 43s)
Iter: 80, Loss 0.001540, Num updates: 80, Wall time: 430.80, ETA: 0m 8s (- 0m 34s)
Iter: 120, Loss 0.001547, Num updates: 120, Wall time: 434.57, ETA: 0m 12s (- 0m 28s)
Iter: 160, Loss 0.001550, Num updates: 160, Wall time: 438.15, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001560, Num updates: 200, Wall time: 441.72, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001567, Num updates: 240, Wall time: 445.35, ETA: 0m 23s (- 0m 15s)
Iter: 280, Loss 0.001564, Num updates: 280, Wall time: 448.84, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001561, Num updates: 320, Wall time: 452.40, ETA: 0m 30s (- 0m 7s)
Iter: 360, Loss 0.001560, Num updates: 360, Wall time: 456.12, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001557, Num updates: 400, Wall time: 459.60, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 11, time: 38.16
	train_loss: 0.0016, score: 24.57
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001543, Num updates: 40, Wall time: 465.60, ETA: 0m 4s (- 0m 45s)
Iter: 80, Loss 0.001536, Num updates: 80, Wall time: 468.96, ETA: 0m 8s (- 0m 33s)
Iter: 120, Loss 0.001541, Num updates: 120, Wall time: 472.49, ETA: 0m 11s (- 0m 27s)
Iter: 160, Loss 0.001537, Num updates: 160, Wall time: 476.25, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001540, Num updates: 200, Wall time: 479.89, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001545, Num updates: 240, Wall time: 483.62, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001543, Num updates: 280, Wall time: 487.27, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001543, Num updates: 320, Wall time: 490.93, ETA: 0m 30s (- 0m 7s)
Iter: 360, Loss 0.001547, Num updates: 360, Wall time: 494.58, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001546, Num updates: 400, Wall time: 498.24, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 12, time: 38.38
	train_loss: 0.0015, score: 24.48
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001492, Num updates: 40, Wall time: 503.81, ETA: 0m 4s (- 0m 41s)
Iter: 80, Loss 0.001508, Num updates: 80, Wall time: 507.42, ETA: 0m 8s (- 0m 32s)
Iter: 120, Loss 0.001521, Num updates: 120, Wall time: 511.28, ETA: 0m 11s (- 0m 28s)
Iter: 160, Loss 0.001527, Num updates: 160, Wall time: 515.05, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001519, Num updates: 200, Wall time: 518.83, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001524, Num updates: 240, Wall time: 522.32, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001520, Num updates: 280, Wall time: 525.84, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001525, Num updates: 320, Wall time: 529.43, ETA: 0m 30s (- 0m 7s)
Iter: 360, Loss 0.001524, Num updates: 360, Wall time: 533.22, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001528, Num updates: 400, Wall time: 536.85, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 13, time: 38.43
	train_loss: 0.0015, score: 24.42
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001489, Num updates: 40, Wall time: 542.62, ETA: 0m 4s (- 0m 42s)
Iter: 80, Loss 0.001494, Num updates: 80, Wall time: 546.25, ETA: 0m 8s (- 0m 33s)
Iter: 120, Loss 0.001501, Num updates: 120, Wall time: 549.76, ETA: 0m 11s (- 0m 27s)
Iter: 160, Loss 0.001499, Num updates: 160, Wall time: 553.19, ETA: 0m 15s (- 0m 22s)
Iter: 200, Loss 0.001504, Num updates: 200, Wall time: 556.83, ETA: 0m 18s (- 0m 18s)
Iter: 240, Loss 0.001499, Num updates: 240, Wall time: 560.34, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001506, Num updates: 280, Wall time: 563.89, ETA: 0m 25s (- 0m 11s)
Iter: 320, Loss 0.001505, Num updates: 320, Wall time: 567.46, ETA: 0m 29s (- 0m 7s)
Iter: 360, Loss 0.001509, Num updates: 360, Wall time: 571.03, ETA: 0m 32s (- 0m 3s)
Iter: 400, Loss 0.001515, Num updates: 400, Wall time: 574.65, ETA: 0m 36s (- 0m 0s)
Evaluating...
epoch 14, time: 37.53
	train_loss: 0.0015, score: 24.69
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001452, Num updates: 40, Wall time: 580.71, ETA: 0m 4s (- 0m 45s)
Iter: 80, Loss 0.001470, Num updates: 80, Wall time: 584.30, ETA: 0m 8s (- 0m 34s)
Iter: 120, Loss 0.001480, Num updates: 120, Wall time: 587.69, ETA: 0m 11s (- 0m 28s)
Iter: 160, Loss 0.001486, Num updates: 160, Wall time: 591.34, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001498, Num updates: 200, Wall time: 595.22, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001511, Num updates: 240, Wall time: 598.63, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001506, Num updates: 280, Wall time: 601.95, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001501, Num updates: 320, Wall time: 605.53, ETA: 0m 29s (- 0m 7s)
Iter: 360, Loss 0.001499, Num updates: 360, Wall time: 609.14, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001499, Num updates: 400, Wall time: 612.67, ETA: 0m 36s (- 0m 0s)
Evaluating...
epoch 15, time: 37.74
	train_loss: 0.0015, score: 24.53
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001425, Num updates: 40, Wall time: 618.29, ETA: 0m 4s (- 0m 42s)
Iter: 80, Loss 0.001451, Num updates: 80, Wall time: 621.85, ETA: 0m 8s (- 0m 32s)
Iter: 120, Loss 0.001462, Num updates: 120, Wall time: 625.38, ETA: 0m 11s (- 0m 27s)
Iter: 160, Loss 0.001470, Num updates: 160, Wall time: 629.21, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001475, Num updates: 200, Wall time: 632.66, ETA: 0m 18s (- 0m 19s)
Iter: 240, Loss 0.001479, Num updates: 240, Wall time: 636.48, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001477, Num updates: 280, Wall time: 640.23, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001479, Num updates: 320, Wall time: 643.86, ETA: 0m 30s (- 0m 7s)
Iter: 360, Loss 0.001483, Num updates: 360, Wall time: 647.46, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001486, Num updates: 400, Wall time: 650.89, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 16, time: 38.07
	train_loss: 0.0015, score: 24.75
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001434, Num updates: 40, Wall time: 656.83, ETA: 0m 4s (- 0m 43s)
Iter: 80, Loss 0.001445, Num updates: 80, Wall time: 660.48, ETA: 0m 8s (- 0m 34s)
Iter: 120, Loss 0.001443, Num updates: 120, Wall time: 664.25, ETA: 0m 12s (- 0m 28s)
Iter: 160, Loss 0.001446, Num updates: 160, Wall time: 667.94, ETA: 0m 15s (- 0m 24s)
Iter: 200, Loss 0.001450, Num updates: 200, Wall time: 671.49, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001452, Num updates: 240, Wall time: 674.98, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001451, Num updates: 280, Wall time: 678.62, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001455, Num updates: 320, Wall time: 682.46, ETA: 0m 30s (- 0m 7s)
Iter: 360, Loss 0.001463, Num updates: 360, Wall time: 686.19, ETA: 0m 34s (- 0m 3s)
Iter: 400, Loss 0.001465, Num updates: 400, Wall time: 689.72, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 17, time: 38.48
	train_loss: 0.0015, score: 25.77
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001459, Num updates: 40, Wall time: 695.53, ETA: 0m 4s (- 0m 43s)
Iter: 80, Loss 0.001454, Num updates: 80, Wall time: 699.47, ETA: 0m 8s (- 0m 35s)
Iter: 120, Loss 0.001456, Num updates: 120, Wall time: 702.87, ETA: 0m 12s (- 0m 28s)
Iter: 160, Loss 0.001460, Num updates: 160, Wall time: 706.39, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001460, Num updates: 200, Wall time: 710.09, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001452, Num updates: 240, Wall time: 713.69, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001454, Num updates: 280, Wall time: 716.97, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001452, Num updates: 320, Wall time: 720.48, ETA: 0m 29s (- 0m 7s)
Iter: 360, Loss 0.001452, Num updates: 360, Wall time: 724.13, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001452, Num updates: 400, Wall time: 727.98, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 18, time: 37.96
	train_loss: 0.0015, score: 25.67
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001393, Num updates: 40, Wall time: 733.85, ETA: 0m 4s (- 0m 44s)
Iter: 80, Loss 0.001403, Num updates: 80, Wall time: 737.56, ETA: 0m 8s (- 0m 34s)
Iter: 120, Loss 0.001415, Num updates: 120, Wall time: 741.15, ETA: 0m 12s (- 0m 28s)
Iter: 160, Loss 0.001421, Num updates: 160, Wall time: 744.90, ETA: 0m 15s (- 0m 24s)
Iter: 200, Loss 0.001423, Num updates: 200, Wall time: 748.55, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001427, Num updates: 240, Wall time: 752.18, ETA: 0m 23s (- 0m 15s)
Iter: 280, Loss 0.001428, Num updates: 280, Wall time: 755.86, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001429, Num updates: 320, Wall time: 759.75, ETA: 0m 30s (- 0m 7s)
Iter: 360, Loss 0.001429, Num updates: 360, Wall time: 763.33, ETA: 0m 34s (- 0m 3s)
Iter: 400, Loss 0.001435, Num updates: 400, Wall time: 766.65, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 19, time: 38.54
	train_loss: 0.0014, score: 25.99
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001423, Num updates: 40, Wall time: 772.91, ETA: 0m 5s (- 0m 46s)
Iter: 80, Loss 0.001413, Num updates: 80, Wall time: 776.35, ETA: 0m 8s (- 0m 34s)
Iter: 120, Loss 0.001404, Num updates: 120, Wall time: 779.94, ETA: 0m 12s (- 0m 28s)
Iter: 160, Loss 0.001413, Num updates: 160, Wall time: 783.79, ETA: 0m 15s (- 0m 24s)
Iter: 200, Loss 0.001408, Num updates: 200, Wall time: 787.38, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001413, Num updates: 240, Wall time: 790.90, ETA: 0m 23s (- 0m 15s)
Iter: 280, Loss 0.001414, Num updates: 280, Wall time: 794.74, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001419, Num updates: 320, Wall time: 798.12, ETA: 0m 30s (- 0m 7s)
Iter: 360, Loss 0.001420, Num updates: 360, Wall time: 801.56, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001420, Num updates: 400, Wall time: 805.06, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 20, time: 38.06
	train_loss: 0.0014, score: 25.90
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001348, Num updates: 40, Wall time: 810.75, ETA: 0m 4s (- 0m 42s)
Iter: 80, Loss 0.001375, Num updates: 80, Wall time: 814.31, ETA: 0m 8s (- 0m 33s)
Iter: 120, Loss 0.001379, Num updates: 120, Wall time: 818.29, ETA: 0m 12s (- 0m 28s)
Iter: 160, Loss 0.001390, Num updates: 160, Wall time: 821.93, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001398, Num updates: 200, Wall time: 825.63, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001402, Num updates: 240, Wall time: 829.21, ETA: 0m 23s (- 0m 15s)
Iter: 280, Loss 0.001407, Num updates: 280, Wall time: 832.63, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001406, Num updates: 320, Wall time: 836.06, ETA: 0m 29s (- 0m 7s)
Iter: 360, Loss 0.001407, Num updates: 360, Wall time: 839.78, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001404, Num updates: 400, Wall time: 843.35, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 21, time: 38.11
	train_loss: 0.0014, score: 26.80
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001359, Num updates: 40, Wall time: 849.13, ETA: 0m 4s (- 0m 42s)
Iter: 80, Loss 0.001376, Num updates: 80, Wall time: 852.65, ETA: 0m 8s (- 0m 33s)
Iter: 120, Loss 0.001375, Num updates: 120, Wall time: 856.28, ETA: 0m 11s (- 0m 27s)
Iter: 160, Loss 0.001379, Num updates: 160, Wall time: 860.22, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001383, Num updates: 200, Wall time: 863.84, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001381, Num updates: 240, Wall time: 867.44, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001378, Num updates: 280, Wall time: 871.10, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001385, Num updates: 320, Wall time: 874.68, ETA: 0m 30s (- 0m 7s)
Iter: 360, Loss 0.001388, Num updates: 360, Wall time: 878.40, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001389, Num updates: 400, Wall time: 882.08, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 22, time: 38.58
	train_loss: 0.0014, score: 26.84
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001317, Num updates: 40, Wall time: 888.11, ETA: 0m 4s (- 0m 43s)
Iter: 80, Loss 0.001343, Num updates: 80, Wall time: 891.78, ETA: 0m 8s (- 0m 34s)
Iter: 120, Loss 0.001360, Num updates: 120, Wall time: 895.53, ETA: 0m 12s (- 0m 28s)
Iter: 160, Loss 0.001363, Num updates: 160, Wall time: 898.81, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001366, Num updates: 200, Wall time: 902.40, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001368, Num updates: 240, Wall time: 905.91, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001371, Num updates: 280, Wall time: 909.72, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001368, Num updates: 320, Wall time: 913.29, ETA: 0m 29s (- 0m 7s)
Iter: 360, Loss 0.001371, Num updates: 360, Wall time: 916.70, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001370, Num updates: 400, Wall time: 920.21, ETA: 0m 36s (- 0m 0s)
Evaluating...
epoch 23, time: 37.64
	train_loss: 0.0014, score: 27.06
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001328, Num updates: 40, Wall time: 926.13, ETA: 0m 4s (- 0m 45s)
Iter: 80, Loss 0.001343, Num updates: 80, Wall time: 929.80, ETA: 0m 8s (- 0m 34s)
Iter: 120, Loss 0.001346, Num updates: 120, Wall time: 933.35, ETA: 0m 12s (- 0m 28s)
Iter: 160, Loss 0.001354, Num updates: 160, Wall time: 937.09, ETA: 0m 15s (- 0m 24s)
Iter: 200, Loss 0.001360, Num updates: 200, Wall time: 940.45, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001356, Num updates: 240, Wall time: 943.83, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001359, Num updates: 280, Wall time: 947.57, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001359, Num updates: 320, Wall time: 951.31, ETA: 0m 30s (- 0m 7s)
Iter: 360, Loss 0.001357, Num updates: 360, Wall time: 954.88, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001355, Num updates: 400, Wall time: 958.56, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 24, time: 38.18
	train_loss: 0.0014, score: 27.22
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001288, Num updates: 40, Wall time: 964.40, ETA: 0m 4s (- 0m 43s)
Iter: 80, Loss 0.001326, Num updates: 80, Wall time: 968.00, ETA: 0m 8s (- 0m 33s)
Iter: 120, Loss 0.001331, Num updates: 120, Wall time: 971.49, ETA: 0m 11s (- 0m 27s)
Iter: 160, Loss 0.001327, Num updates: 160, Wall time: 975.08, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001335, Num updates: 200, Wall time: 978.64, ETA: 0m 18s (- 0m 19s)
Iter: 240, Loss 0.001343, Num updates: 240, Wall time: 982.17, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001342, Num updates: 280, Wall time: 985.54, ETA: 0m 25s (- 0m 11s)
Iter: 320, Loss 0.001342, Num updates: 320, Wall time: 989.38, ETA: 0m 29s (- 0m 7s)
Iter: 360, Loss 0.001343, Num updates: 360, Wall time: 993.01, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001340, Num updates: 400, Wall time: 996.51, ETA: 0m 36s (- 0m 0s)
Evaluating...
epoch 25, time: 37.83
	train_loss: 0.0013, score: 28.14
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001280, Num updates: 40, Wall time: 1002.80, ETA: 0m 5s (- 0m 46s)
Iter: 80, Loss 0.001296, Num updates: 80, Wall time: 1006.45, ETA: 0m 8s (- 0m 35s)
Iter: 120, Loss 0.001298, Num updates: 120, Wall time: 1009.92, ETA: 0m 12s (- 0m 28s)
Iter: 160, Loss 0.001301, Num updates: 160, Wall time: 1013.76, ETA: 0m 16s (- 0m 24s)
Iter: 200, Loss 0.001307, Num updates: 200, Wall time: 1017.40, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001313, Num updates: 240, Wall time: 1020.82, ETA: 0m 23s (- 0m 15s)
Iter: 280, Loss 0.001316, Num updates: 280, Wall time: 1024.37, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001319, Num updates: 320, Wall time: 1027.92, ETA: 0m 30s (- 0m 7s)
Iter: 360, Loss 0.001320, Num updates: 360, Wall time: 1031.59, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001325, Num updates: 400, Wall time: 1035.32, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 26, time: 38.52
	train_loss: 0.0013, score: 28.02
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001244, Num updates: 40, Wall time: 1041.39, ETA: 0m 4s (- 0m 45s)
Iter: 80, Loss 0.001265, Num updates: 80, Wall time: 1044.91, ETA: 0m 8s (- 0m 34s)
Iter: 120, Loss 0.001293, Num updates: 120, Wall time: 1048.46, ETA: 0m 11s (- 0m 28s)
Iter: 160, Loss 0.001294, Num updates: 160, Wall time: 1051.91, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001294, Num updates: 200, Wall time: 1055.61, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001304, Num updates: 240, Wall time: 1059.20, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001311, Num updates: 280, Wall time: 1062.82, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001311, Num updates: 320, Wall time: 1066.53, ETA: 0m 30s (- 0m 7s)
Iter: 360, Loss 0.001310, Num updates: 360, Wall time: 1070.16, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001315, Num updates: 400, Wall time: 1074.01, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 27, time: 38.42
	train_loss: 0.0013, score: 27.98
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001263, Num updates: 40, Wall time: 1079.42, ETA: 0m 4s (- 0m 39s)
Iter: 80, Loss 0.001276, Num updates: 80, Wall time: 1083.11, ETA: 0m 7s (- 0m 32s)
Iter: 120, Loss 0.001293, Num updates: 120, Wall time: 1086.83, ETA: 0m 11s (- 0m 27s)
Iter: 160, Loss 0.001290, Num updates: 160, Wall time: 1090.43, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001295, Num updates: 200, Wall time: 1093.90, ETA: 0m 18s (- 0m 18s)
Iter: 240, Loss 0.001299, Num updates: 240, Wall time: 1097.44, ETA: 0m 22s (- 0m 14s)
Iter: 280, Loss 0.001301, Num updates: 280, Wall time: 1101.15, ETA: 0m 25s (- 0m 11s)
Iter: 320, Loss 0.001301, Num updates: 320, Wall time: 1104.70, ETA: 0m 29s (- 0m 7s)
Iter: 360, Loss 0.001302, Num updates: 360, Wall time: 1108.41, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001303, Num updates: 400, Wall time: 1111.89, ETA: 0m 36s (- 0m 0s)
Evaluating...
epoch 28, time: 37.53
	train_loss: 0.0013, score: 28.09
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001263, Num updates: 40, Wall time: 1117.54, ETA: 0m 4s (- 0m 42s)
Iter: 80, Loss 0.001257, Num updates: 80, Wall time: 1121.25, ETA: 0m 8s (- 0m 33s)
Iter: 120, Loss 0.001277, Num updates: 120, Wall time: 1124.94, ETA: 0m 11s (- 0m 28s)
Iter: 160, Loss 0.001278, Num updates: 160, Wall time: 1128.36, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001283, Num updates: 200, Wall time: 1131.80, ETA: 0m 18s (- 0m 19s)
Iter: 240, Loss 0.001282, Num updates: 240, Wall time: 1135.43, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001285, Num updates: 280, Wall time: 1139.07, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001286, Num updates: 320, Wall time: 1142.57, ETA: 0m 29s (- 0m 7s)
Iter: 360, Loss 0.001288, Num updates: 360, Wall time: 1145.95, ETA: 0m 32s (- 0m 3s)
Iter: 400, Loss 0.001288, Num updates: 400, Wall time: 1149.39, ETA: 0m 36s (- 0m 0s)
Evaluating...
epoch 29, time: 37.39
	train_loss: 0.0013, score: 28.29
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001229, Num updates: 40, Wall time: 1155.59, ETA: 0m 4s (- 0m 46s)
Iter: 80, Loss 0.001241, Num updates: 80, Wall time: 1159.02, ETA: 0m 8s (- 0m 34s)
Iter: 120, Loss 0.001265, Num updates: 120, Wall time: 1162.51, ETA: 0m 11s (- 0m 28s)
Iter: 160, Loss 0.001270, Num updates: 160, Wall time: 1166.29, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001273, Num updates: 200, Wall time: 1169.90, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001275, Num updates: 240, Wall time: 1173.37, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001272, Num updates: 280, Wall time: 1177.04, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001274, Num updates: 320, Wall time: 1180.68, ETA: 0m 30s (- 0m 7s)
Iter: 360, Loss 0.001277, Num updates: 360, Wall time: 1184.31, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001278, Num updates: 400, Wall time: 1188.10, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 30, time: 38.46
	train_loss: 0.0013, score: 28.13
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001197, Num updates: 40, Wall time: 1194.07, ETA: 0m 4s (- 0m 43s)
Iter: 80, Loss 0.001235, Num updates: 80, Wall time: 1197.65, ETA: 0m 8s (- 0m 33s)
Iter: 120, Loss 0.001239, Num updates: 120, Wall time: 1201.19, ETA: 0m 11s (- 0m 28s)
Iter: 160, Loss 0.001241, Num updates: 160, Wall time: 1204.63, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001250, Num updates: 200, Wall time: 1208.09, ETA: 0m 18s (- 0m 18s)
Iter: 240, Loss 0.001253, Num updates: 240, Wall time: 1211.57, ETA: 0m 22s (- 0m 14s)
Iter: 280, Loss 0.001259, Num updates: 280, Wall time: 1215.16, ETA: 0m 25s (- 0m 11s)
Iter: 320, Loss 0.001258, Num updates: 320, Wall time: 1218.65, ETA: 0m 29s (- 0m 7s)
Iter: 360, Loss 0.001261, Num updates: 360, Wall time: 1222.22, ETA: 0m 32s (- 0m 3s)
Iter: 400, Loss 0.001261, Num updates: 400, Wall time: 1225.69, ETA: 0m 36s (- 0m 0s)
Evaluating...
epoch 31, time: 37.26
	train_loss: 0.0013, score: 28.91
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001209, Num updates: 40, Wall time: 1231.60, ETA: 0m 4s (- 0m 44s)
Iter: 80, Loss 0.001211, Num updates: 80, Wall time: 1235.27, ETA: 0m 8s (- 0m 34s)
Iter: 120, Loss 0.001230, Num updates: 120, Wall time: 1238.83, ETA: 0m 12s (- 0m 28s)
Iter: 160, Loss 0.001239, Num updates: 160, Wall time: 1242.52, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001247, Num updates: 200, Wall time: 1246.21, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001245, Num updates: 240, Wall time: 1249.82, ETA: 0m 23s (- 0m 15s)
Iter: 280, Loss 0.001247, Num updates: 280, Wall time: 1253.82, ETA: 0m 27s (- 0m 11s)
Iter: 320, Loss 0.001248, Num updates: 320, Wall time: 1257.56, ETA: 0m 30s (- 0m 7s)
Iter: 360, Loss 0.001250, Num updates: 360, Wall time: 1261.25, ETA: 0m 34s (- 0m 3s)
Iter: 400, Loss 0.001254, Num updates: 400, Wall time: 1264.76, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 32, time: 38.94
	train_loss: 0.0013, score: 28.62
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001227, Num updates: 40, Wall time: 1270.44, ETA: 0m 4s (- 0m 41s)
Iter: 80, Loss 0.001240, Num updates: 80, Wall time: 1273.86, ETA: 0m 7s (- 0m 32s)
Iter: 120, Loss 0.001239, Num updates: 120, Wall time: 1277.35, ETA: 0m 11s (- 0m 26s)
Iter: 160, Loss 0.001235, Num updates: 160, Wall time: 1280.97, ETA: 0m 15s (- 0m 22s)
Iter: 200, Loss 0.001234, Num updates: 200, Wall time: 1284.56, ETA: 0m 18s (- 0m 18s)
Iter: 240, Loss 0.001238, Num updates: 240, Wall time: 1288.17, ETA: 0m 22s (- 0m 14s)
Iter: 280, Loss 0.001240, Num updates: 280, Wall time: 1291.73, ETA: 0m 25s (- 0m 11s)
Iter: 320, Loss 0.001240, Num updates: 320, Wall time: 1295.17, ETA: 0m 29s (- 0m 7s)
Iter: 360, Loss 0.001239, Num updates: 360, Wall time: 1298.77, ETA: 0m 32s (- 0m 3s)
Iter: 400, Loss 0.001242, Num updates: 400, Wall time: 1302.28, ETA: 0m 36s (- 0m 0s)
Evaluating...
epoch 33, time: 37.09
	train_loss: 0.0012, score: 28.76
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001206, Num updates: 40, Wall time: 1308.08, ETA: 0m 4s (- 0m 44s)
Iter: 80, Loss 0.001225, Num updates: 80, Wall time: 1311.37, ETA: 0m 8s (- 0m 32s)
Iter: 120, Loss 0.001230, Num updates: 120, Wall time: 1315.02, ETA: 0m 11s (- 0m 27s)
Iter: 160, Loss 0.001229, Num updates: 160, Wall time: 1318.71, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001225, Num updates: 200, Wall time: 1322.16, ETA: 0m 18s (- 0m 19s)
Iter: 240, Loss 0.001228, Num updates: 240, Wall time: 1325.59, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001230, Num updates: 280, Wall time: 1329.36, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001233, Num updates: 320, Wall time: 1332.92, ETA: 0m 29s (- 0m 7s)
Iter: 360, Loss 0.001234, Num updates: 360, Wall time: 1336.65, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001233, Num updates: 400, Wall time: 1340.36, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 34, time: 37.55
	train_loss: 0.0012, score: 27.98
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001171, Num updates: 40, Wall time: 1346.08, ETA: 0m 4s (- 0m 45s)
Iter: 80, Loss 0.001186, Num updates: 80, Wall time: 1349.93, ETA: 0m 8s (- 0m 35s)
Iter: 120, Loss 0.001197, Num updates: 120, Wall time: 1353.38, ETA: 0m 12s (- 0m 28s)
Iter: 160, Loss 0.001202, Num updates: 160, Wall time: 1356.88, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001204, Num updates: 200, Wall time: 1360.33, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001206, Num updates: 240, Wall time: 1363.84, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001211, Num updates: 280, Wall time: 1367.36, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001215, Num updates: 320, Wall time: 1370.81, ETA: 0m 29s (- 0m 7s)
Iter: 360, Loss 0.001216, Num updates: 360, Wall time: 1374.32, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001220, Num updates: 400, Wall time: 1377.78, ETA: 0m 36s (- 0m 0s)
Evaluating...
epoch 35, time: 37.61
	train_loss: 0.0012, score: 29.36
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001169, Num updates: 40, Wall time: 1383.86, ETA: 0m 4s (- 0m 45s)
Iter: 80, Loss 0.001194, Num updates: 80, Wall time: 1387.49, ETA: 0m 8s (- 0m 34s)
Iter: 120, Loss 0.001200, Num updates: 120, Wall time: 1391.13, ETA: 0m 12s (- 0m 28s)
Iter: 160, Loss 0.001206, Num updates: 160, Wall time: 1394.98, ETA: 0m 16s (- 0m 24s)
Iter: 200, Loss 0.001208, Num updates: 200, Wall time: 1398.50, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001209, Num updates: 240, Wall time: 1402.09, ETA: 0m 23s (- 0m 15s)
Iter: 280, Loss 0.001211, Num updates: 280, Wall time: 1405.67, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001214, Num updates: 320, Wall time: 1409.35, ETA: 0m 30s (- 0m 7s)
Iter: 360, Loss 0.001212, Num updates: 360, Wall time: 1413.00, ETA: 0m 34s (- 0m 3s)
Iter: 400, Loss 0.001215, Num updates: 400, Wall time: 1416.62, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 36, time: 38.64
	train_loss: 0.0012, score: 28.88
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001163, Num updates: 40, Wall time: 1422.61, ETA: 0m 4s (- 0m 44s)
Iter: 80, Loss 0.001168, Num updates: 80, Wall time: 1426.15, ETA: 0m 8s (- 0m 33s)
Iter: 120, Loss 0.001189, Num updates: 120, Wall time: 1429.94, ETA: 0m 12s (- 0m 28s)
Iter: 160, Loss 0.001191, Num updates: 160, Wall time: 1433.53, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001194, Num updates: 200, Wall time: 1437.08, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001197, Num updates: 240, Wall time: 1440.68, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001200, Num updates: 280, Wall time: 1444.39, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001200, Num updates: 320, Wall time: 1448.14, ETA: 0m 30s (- 0m 7s)
Iter: 360, Loss 0.001203, Num updates: 360, Wall time: 1451.94, ETA: 0m 34s (- 0m 3s)
Iter: 400, Loss 0.001204, Num updates: 400, Wall time: 1455.60, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 37, time: 38.70
	train_loss: 0.0012, score: 28.82
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001162, Num updates: 40, Wall time: 1461.45, ETA: 0m 4s (- 0m 43s)
Iter: 80, Loss 0.001193, Num updates: 80, Wall time: 1465.02, ETA: 0m 8s (- 0m 33s)
Iter: 120, Loss 0.001189, Num updates: 120, Wall time: 1468.49, ETA: 0m 11s (- 0m 27s)
Iter: 160, Loss 0.001189, Num updates: 160, Wall time: 1471.94, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001195, Num updates: 200, Wall time: 1475.50, ETA: 0m 18s (- 0m 18s)
Iter: 240, Loss 0.001196, Num updates: 240, Wall time: 1479.12, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001198, Num updates: 280, Wall time: 1482.99, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001201, Num updates: 320, Wall time: 1486.51, ETA: 0m 29s (- 0m 7s)
Iter: 360, Loss 0.001201, Num updates: 360, Wall time: 1490.19, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001199, Num updates: 400, Wall time: 1493.70, ETA: 0m 36s (- 0m 0s)
Evaluating...
epoch 38, time: 37.85
	train_loss: 0.0012, score: 27.84
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001137, Num updates: 40, Wall time: 1499.82, ETA: 0m 4s (- 0m 46s)
Iter: 80, Loss 0.001152, Num updates: 80, Wall time: 1503.40, ETA: 0m 8s (- 0m 34s)
Iter: 120, Loss 0.001159, Num updates: 120, Wall time: 1506.73, ETA: 0m 11s (- 0m 28s)
Iter: 160, Loss 0.001161, Num updates: 160, Wall time: 1510.39, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001169, Num updates: 200, Wall time: 1514.04, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001172, Num updates: 240, Wall time: 1517.74, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001175, Num updates: 280, Wall time: 1521.26, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001179, Num updates: 320, Wall time: 1524.73, ETA: 0m 29s (- 0m 7s)
Iter: 360, Loss 0.001182, Num updates: 360, Wall time: 1528.33, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001184, Num updates: 400, Wall time: 1531.68, ETA: 0m 36s (- 0m 0s)
Evaluating...
epoch 39, time: 37.93
	train_loss: 0.0012, score: 28.65
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001144, Num updates: 40, Wall time: 1537.67, ETA: 0m 4s (- 0m 43s)
Iter: 80, Loss 0.001150, Num updates: 80, Wall time: 1541.05, ETA: 0m 8s (- 0m 32s)
Iter: 120, Loss 0.001161, Num updates: 120, Wall time: 1544.42, ETA: 0m 11s (- 0m 27s)
Iter: 160, Loss 0.001163, Num updates: 160, Wall time: 1548.04, ETA: 0m 15s (- 0m 22s)
Iter: 200, Loss 0.001163, Num updates: 200, Wall time: 1551.70, ETA: 0m 18s (- 0m 18s)
Iter: 240, Loss 0.001168, Num updates: 240, Wall time: 1555.27, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001173, Num updates: 280, Wall time: 1558.59, ETA: 0m 25s (- 0m 11s)
Iter: 320, Loss 0.001174, Num updates: 320, Wall time: 1562.21, ETA: 0m 29s (- 0m 7s)
Iter: 360, Loss 0.001172, Num updates: 360, Wall time: 1566.03, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001177, Num updates: 400, Wall time: 1569.56, ETA: 0m 36s (- 0m 0s)
Evaluating...
epoch 40, time: 37.48
	train_loss: 0.0012, score: 28.45
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001132, Num updates: 40, Wall time: 1575.50, ETA: 0m 4s (- 0m 44s)
Iter: 80, Loss 0.001153, Num updates: 80, Wall time: 1578.91, ETA: 0m 8s (- 0m 33s)
Iter: 120, Loss 0.001158, Num updates: 120, Wall time: 1582.59, ETA: 0m 11s (- 0m 28s)
Iter: 160, Loss 0.001158, Num updates: 160, Wall time: 1586.30, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001162, Num updates: 200, Wall time: 1589.76, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001167, Num updates: 240, Wall time: 1593.32, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001167, Num updates: 280, Wall time: 1596.91, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001169, Num updates: 320, Wall time: 1600.64, ETA: 0m 29s (- 0m 7s)
Iter: 360, Loss 0.001171, Num updates: 360, Wall time: 1604.28, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001171, Num updates: 400, Wall time: 1607.92, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 41, time: 38.29
	train_loss: 0.0012, score: 28.71
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001141, Num updates: 40, Wall time: 1614.37, ETA: 0m 5s (- 0m 48s)
Iter: 80, Loss 0.001148, Num updates: 80, Wall time: 1617.84, ETA: 0m 8s (- 0m 35s)
Iter: 120, Loss 0.001155, Num updates: 120, Wall time: 1621.33, ETA: 0m 12s (- 0m 28s)
Iter: 160, Loss 0.001156, Num updates: 160, Wall time: 1624.99, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001161, Num updates: 200, Wall time: 1628.71, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001156, Num updates: 240, Wall time: 1632.54, ETA: 0m 23s (- 0m 15s)
Iter: 280, Loss 0.001160, Num updates: 280, Wall time: 1636.37, ETA: 0m 27s (- 0m 11s)
Iter: 320, Loss 0.001160, Num updates: 320, Wall time: 1639.98, ETA: 0m 30s (- 0m 7s)
Iter: 360, Loss 0.001162, Num updates: 360, Wall time: 1643.51, ETA: 0m 34s (- 0m 3s)
Iter: 400, Loss 0.001161, Num updates: 400, Wall time: 1647.34, ETA: 0m 38s (- 0m 0s)
Evaluating...
epoch 42, time: 38.82
	train_loss: 0.0012, score: 28.64
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001138, Num updates: 40, Wall time: 1652.90, ETA: 0m 4s (- 0m 43s)
Iter: 80, Loss 0.001147, Num updates: 80, Wall time: 1656.38, ETA: 0m 8s (- 0m 33s)
Iter: 120, Loss 0.001150, Num updates: 120, Wall time: 1660.05, ETA: 0m 11s (- 0m 27s)
Iter: 160, Loss 0.001151, Num updates: 160, Wall time: 1663.74, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001150, Num updates: 200, Wall time: 1667.38, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001151, Num updates: 240, Wall time: 1671.01, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001155, Num updates: 280, Wall time: 1674.46, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001154, Num updates: 320, Wall time: 1678.21, ETA: 0m 29s (- 0m 7s)
Iter: 360, Loss 0.001154, Num updates: 360, Wall time: 1681.73, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001155, Num updates: 400, Wall time: 1685.28, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 43, time: 37.92
	train_loss: 0.0012, score: 28.76
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001090, Num updates: 40, Wall time: 1691.19, ETA: 0m 4s (- 0m 44s)
Iter: 80, Loss 0.001106, Num updates: 80, Wall time: 1694.80, ETA: 0m 8s (- 0m 34s)
Iter: 120, Loss 0.001120, Num updates: 120, Wall time: 1698.37, ETA: 0m 11s (- 0m 28s)
Iter: 160, Loss 0.001132, Num updates: 160, Wall time: 1701.90, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001134, Num updates: 200, Wall time: 1705.54, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001139, Num updates: 240, Wall time: 1708.98, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001141, Num updates: 280, Wall time: 1712.78, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001142, Num updates: 320, Wall time: 1716.31, ETA: 0m 29s (- 0m 7s)
Iter: 360, Loss 0.001144, Num updates: 360, Wall time: 1719.84, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001148, Num updates: 400, Wall time: 1723.47, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 44, time: 37.99
	train_loss: 0.0012, score: 28.50
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001112, Num updates: 40, Wall time: 1729.52, ETA: 0m 4s (- 0m 44s)
Iter: 80, Loss 0.001131, Num updates: 80, Wall time: 1733.20, ETA: 0m 8s (- 0m 34s)
Iter: 120, Loss 0.001137, Num updates: 120, Wall time: 1737.04, ETA: 0m 12s (- 0m 29s)
Iter: 160, Loss 0.001131, Num updates: 160, Wall time: 1740.74, ETA: 0m 16s (- 0m 24s)
Iter: 200, Loss 0.001137, Num updates: 200, Wall time: 1744.51, ETA: 0m 19s (- 0m 20s)
Iter: 240, Loss 0.001134, Num updates: 240, Wall time: 1748.10, ETA: 0m 23s (- 0m 15s)
Iter: 280, Loss 0.001135, Num updates: 280, Wall time: 1751.54, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001137, Num updates: 320, Wall time: 1755.15, ETA: 0m 30s (- 0m 7s)
Iter: 360, Loss 0.001140, Num updates: 360, Wall time: 1758.93, ETA: 0m 34s (- 0m 3s)
Iter: 400, Loss 0.001143, Num updates: 400, Wall time: 1762.50, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 45, time: 38.71
	train_loss: 0.0011, score: 27.96
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001093, Num updates: 40, Wall time: 1768.66, ETA: 0m 5s (- 0m 46s)
Iter: 80, Loss 0.001116, Num updates: 80, Wall time: 1772.12, ETA: 0m 8s (- 0m 34s)
Iter: 120, Loss 0.001119, Num updates: 120, Wall time: 1775.70, ETA: 0m 12s (- 0m 28s)
Iter: 160, Loss 0.001124, Num updates: 160, Wall time: 1779.57, ETA: 0m 15s (- 0m 24s)
Iter: 200, Loss 0.001128, Num updates: 200, Wall time: 1783.51, ETA: 0m 19s (- 0m 20s)
Iter: 240, Loss 0.001129, Num updates: 240, Wall time: 1787.23, ETA: 0m 23s (- 0m 15s)
Iter: 280, Loss 0.001129, Num updates: 280, Wall time: 1791.03, ETA: 0m 27s (- 0m 11s)
Iter: 320, Loss 0.001130, Num updates: 320, Wall time: 1794.80, ETA: 0m 31s (- 0m 7s)
Iter: 360, Loss 0.001131, Num updates: 360, Wall time: 1798.37, ETA: 0m 34s (- 0m 3s)
Iter: 400, Loss 0.001133, Num updates: 400, Wall time: 1801.97, ETA: 0m 38s (- 0m 0s)
Evaluating...
epoch 46, time: 39.31
	train_loss: 0.0011, score: 28.47
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001092, Num updates: 40, Wall time: 1807.83, ETA: 0m 4s (- 0m 43s)
Iter: 80, Loss 0.001096, Num updates: 80, Wall time: 1811.34, ETA: 0m 8s (- 0m 33s)
Iter: 120, Loss 0.001102, Num updates: 120, Wall time: 1815.02, ETA: 0m 11s (- 0m 28s)
Iter: 160, Loss 0.001105, Num updates: 160, Wall time: 1818.56, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001113, Num updates: 200, Wall time: 1822.20, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001115, Num updates: 240, Wall time: 1825.78, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001118, Num updates: 280, Wall time: 1829.36, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001120, Num updates: 320, Wall time: 1832.73, ETA: 0m 29s (- 0m 7s)
Iter: 360, Loss 0.001121, Num updates: 360, Wall time: 1836.33, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001124, Num updates: 400, Wall time: 1839.62, ETA: 0m 36s (- 0m 0s)
Evaluating...
epoch 47, time: 37.38
	train_loss: 0.0011, score: 28.89
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001079, Num updates: 40, Wall time: 1845.81, ETA: 0m 5s (- 0m 46s)
Iter: 80, Loss 0.001090, Num updates: 80, Wall time: 1849.37, ETA: 0m 8s (- 0m 34s)
Iter: 120, Loss 0.001104, Num updates: 120, Wall time: 1852.92, ETA: 0m 12s (- 0m 28s)
Iter: 160, Loss 0.001106, Num updates: 160, Wall time: 1856.51, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001111, Num updates: 200, Wall time: 1860.19, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001114, Num updates: 240, Wall time: 1863.75, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001115, Num updates: 280, Wall time: 1867.53, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001119, Num updates: 320, Wall time: 1871.16, ETA: 0m 30s (- 0m 7s)
Iter: 360, Loss 0.001121, Num updates: 360, Wall time: 1874.82, ETA: 0m 34s (- 0m 3s)
Iter: 400, Loss 0.001120, Num updates: 400, Wall time: 1878.33, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 48, time: 38.36
	train_loss: 0.0011, score: 28.30
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001127, Num updates: 40, Wall time: 1884.05, ETA: 0m 4s (- 0m 43s)
Iter: 80, Loss 0.001119, Num updates: 80, Wall time: 1887.52, ETA: 0m 8s (- 0m 33s)
Iter: 120, Loss 0.001112, Num updates: 120, Wall time: 1891.18, ETA: 0m 11s (- 0m 27s)
Iter: 160, Loss 0.001112, Num updates: 160, Wall time: 1894.91, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001118, Num updates: 200, Wall time: 1898.69, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001117, Num updates: 240, Wall time: 1902.41, ETA: 0m 23s (- 0m 15s)
Iter: 280, Loss 0.001117, Num updates: 280, Wall time: 1906.14, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001115, Num updates: 320, Wall time: 1909.48, ETA: 0m 30s (- 0m 7s)
Iter: 360, Loss 0.001115, Num updates: 360, Wall time: 1912.96, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001114, Num updates: 400, Wall time: 1916.60, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 49, time: 38.07
	train_loss: 0.0011, score: 28.62
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001079, Num updates: 40, Wall time: 1922.56, ETA: 0m 4s (- 0m 45s)
Iter: 80, Loss 0.001096, Num updates: 80, Wall time: 1926.10, ETA: 0m 8s (- 0m 34s)
Iter: 120, Loss 0.001104, Num updates: 120, Wall time: 1929.39, ETA: 0m 11s (- 0m 27s)
Iter: 160, Loss 0.001110, Num updates: 160, Wall time: 1932.85, ETA: 0m 15s (- 0m 22s)
Iter: 200, Loss 0.001110, Num updates: 200, Wall time: 1936.44, ETA: 0m 18s (- 0m 18s)
Iter: 240, Loss 0.001107, Num updates: 240, Wall time: 1940.24, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001109, Num updates: 280, Wall time: 1943.81, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001112, Num updates: 320, Wall time: 1947.22, ETA: 0m 29s (- 0m 7s)
Iter: 360, Loss 0.001112, Num updates: 360, Wall time: 1950.79, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001110, Num updates: 400, Wall time: 1954.30, ETA: 0m 36s (- 0m 0s)
Evaluating...
epoch 50, time: 37.47
	train_loss: 0.0011, score: 28.25
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001085, Num updates: 40, Wall time: 1960.33, ETA: 0m 4s (- 0m 45s)
Iter: 80, Loss 0.001088, Num updates: 80, Wall time: 1964.10, ETA: 0m 8s (- 0m 35s)
Iter: 120, Loss 0.001090, Num updates: 120, Wall time: 1967.69, ETA: 0m 12s (- 0m 29s)
Iter: 160, Loss 0.001095, Num updates: 160, Wall time: 1971.21, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001095, Num updates: 200, Wall time: 1974.82, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001101, Num updates: 240, Wall time: 1978.39, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001101, Num updates: 280, Wall time: 1982.04, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001103, Num updates: 320, Wall time: 1985.91, ETA: 0m 30s (- 0m 7s)
Iter: 360, Loss 0.001103, Num updates: 360, Wall time: 1989.35, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001104, Num updates: 400, Wall time: 1992.79, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 51, time: 38.36
	train_loss: 0.0011, score: 28.16
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001064, Num updates: 40, Wall time: 1998.85, ETA: 0m 4s (- 0m 44s)
Iter: 80, Loss 0.001087, Num updates: 80, Wall time: 2002.62, ETA: 0m 8s (- 0m 34s)
Iter: 120, Loss 0.001087, Num updates: 120, Wall time: 2006.32, ETA: 0m 12s (- 0m 29s)
Iter: 160, Loss 0.001091, Num updates: 160, Wall time: 2009.82, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001094, Num updates: 200, Wall time: 2013.47, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001095, Num updates: 240, Wall time: 2017.08, ETA: 0m 23s (- 0m 15s)
Iter: 280, Loss 0.001096, Num updates: 280, Wall time: 2020.81, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001099, Num updates: 320, Wall time: 2024.45, ETA: 0m 30s (- 0m 7s)
Iter: 360, Loss 0.001096, Num updates: 360, Wall time: 2028.02, ETA: 0m 34s (- 0m 3s)
Iter: 400, Loss 0.001099, Num updates: 400, Wall time: 2031.58, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 52, time: 38.51
	train_loss: 0.0011, score: 28.77
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001074, Num updates: 40, Wall time: 2037.82, ETA: 0m 5s (- 0m 46s)
Iter: 80, Loss 0.001085, Num updates: 80, Wall time: 2041.45, ETA: 0m 8s (- 0m 35s)
Iter: 120, Loss 0.001082, Num updates: 120, Wall time: 2045.05, ETA: 0m 12s (- 0m 28s)
Iter: 160, Loss 0.001086, Num updates: 160, Wall time: 2048.63, ETA: 0m 15s (- 0m 24s)
Iter: 200, Loss 0.001085, Num updates: 200, Wall time: 2052.12, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001089, Num updates: 240, Wall time: 2055.44, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001090, Num updates: 280, Wall time: 2058.97, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001093, Num updates: 320, Wall time: 2062.50, ETA: 0m 29s (- 0m 7s)
Iter: 360, Loss 0.001095, Num updates: 360, Wall time: 2066.19, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001093, Num updates: 400, Wall time: 2069.98, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 53, time: 38.03
	train_loss: 0.0011, score: 27.94
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001075, Num updates: 40, Wall time: 2075.99, ETA: 0m 4s (- 0m 45s)
Iter: 80, Loss 0.001076, Num updates: 80, Wall time: 2079.66, ETA: 0m 8s (- 0m 34s)
Iter: 120, Loss 0.001081, Num updates: 120, Wall time: 2083.28, ETA: 0m 12s (- 0m 28s)
Iter: 160, Loss 0.001082, Num updates: 160, Wall time: 2086.90, ETA: 0m 15s (- 0m 24s)
Iter: 200, Loss 0.001081, Num updates: 200, Wall time: 2090.47, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001081, Num updates: 240, Wall time: 2093.75, ETA: 0m 22s (- 0m 15s)
Iter: 280, Loss 0.001085, Num updates: 280, Wall time: 2097.11, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001086, Num updates: 320, Wall time: 2100.76, ETA: 0m 29s (- 0m 7s)
Iter: 360, Loss 0.001088, Num updates: 360, Wall time: 2104.54, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001089, Num updates: 400, Wall time: 2108.14, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 54, time: 37.91
	train_loss: 0.0011, score: 28.12
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001068, Num updates: 40, Wall time: 2114.32, ETA: 0m 5s (- 0m 47s)
Iter: 80, Loss 0.001070, Num updates: 80, Wall time: 2118.02, ETA: 0m 8s (- 0m 35s)
Iter: 120, Loss 0.001066, Num updates: 120, Wall time: 2121.69, ETA: 0m 12s (- 0m 29s)
Iter: 160, Loss 0.001079, Num updates: 160, Wall time: 2125.19, ETA: 0m 15s (- 0m 24s)
Iter: 200, Loss 0.001079, Num updates: 200, Wall time: 2128.84, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001081, Num updates: 240, Wall time: 2132.46, ETA: 0m 23s (- 0m 15s)
Iter: 280, Loss 0.001080, Num updates: 280, Wall time: 2136.13, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001080, Num updates: 320, Wall time: 2139.58, ETA: 0m 30s (- 0m 7s)
Iter: 360, Loss 0.001081, Num updates: 360, Wall time: 2143.36, ETA: 0m 34s (- 0m 3s)
Iter: 400, Loss 0.001081, Num updates: 400, Wall time: 2146.90, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 55, time: 38.45
	train_loss: 0.0011, score: 28.20
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001054, Num updates: 40, Wall time: 2152.80, ETA: 0m 4s (- 0m 44s)
Iter: 80, Loss 0.001058, Num updates: 80, Wall time: 2156.23, ETA: 0m 8s (- 0m 33s)
Iter: 120, Loss 0.001063, Num updates: 120, Wall time: 2159.62, ETA: 0m 11s (- 0m 27s)
Iter: 160, Loss 0.001069, Num updates: 160, Wall time: 2163.23, ETA: 0m 15s (- 0m 23s)
Iter: 200, Loss 0.001075, Num updates: 200, Wall time: 2166.59, ETA: 0m 18s (- 0m 18s)
Iter: 240, Loss 0.001075, Num updates: 240, Wall time: 2170.08, ETA: 0m 22s (- 0m 14s)
Iter: 280, Loss 0.001071, Num updates: 280, Wall time: 2173.54, ETA: 0m 25s (- 0m 11s)
Iter: 320, Loss 0.001072, Num updates: 320, Wall time: 2177.06, ETA: 0m 29s (- 0m 7s)
Iter: 360, Loss 0.001073, Num updates: 360, Wall time: 2180.57, ETA: 0m 32s (- 0m 3s)
Iter: 400, Loss 0.001077, Num updates: 400, Wall time: 2184.12, ETA: 0m 36s (- 0m 0s)
Evaluating...
epoch 56, time: 37.10
	train_loss: 0.0011, score: 28.45
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001031, Num updates: 40, Wall time: 2190.13, ETA: 0m 4s (- 0m 44s)
Iter: 80, Loss 0.001053, Num updates: 80, Wall time: 2193.75, ETA: 0m 8s (- 0m 34s)
Iter: 120, Loss 0.001062, Num updates: 120, Wall time: 2197.47, ETA: 0m 12s (- 0m 28s)
Iter: 160, Loss 0.001067, Num updates: 160, Wall time: 2201.33, ETA: 0m 16s (- 0m 24s)
Iter: 200, Loss 0.001067, Num updates: 200, Wall time: 2205.16, ETA: 0m 19s (- 0m 20s)
Iter: 240, Loss 0.001070, Num updates: 240, Wall time: 2208.89, ETA: 0m 23s (- 0m 15s)
Iter: 280, Loss 0.001072, Num updates: 280, Wall time: 2212.39, ETA: 0m 27s (- 0m 11s)
Iter: 320, Loss 0.001074, Num updates: 320, Wall time: 2216.10, ETA: 0m 30s (- 0m 7s)
Iter: 360, Loss 0.001072, Num updates: 360, Wall time: 2219.80, ETA: 0m 34s (- 0m 3s)
Iter: 400, Loss 0.001076, Num updates: 400, Wall time: 2223.30, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 57, time: 38.86
	train_loss: 0.0011, score: 27.89
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001027, Num updates: 40, Wall time: 2229.39, ETA: 0m 4s (- 0m 45s)
Iter: 80, Loss 0.001036, Num updates: 80, Wall time: 2232.88, ETA: 0m 8s (- 0m 34s)
Iter: 120, Loss 0.001036, Num updates: 120, Wall time: 2236.76, ETA: 0m 12s (- 0m 28s)
Iter: 160, Loss 0.001047, Num updates: 160, Wall time: 2240.50, ETA: 0m 16s (- 0m 24s)
Iter: 200, Loss 0.001054, Num updates: 200, Wall time: 2244.02, ETA: 0m 19s (- 0m 19s)
Iter: 240, Loss 0.001058, Num updates: 240, Wall time: 2247.51, ETA: 0m 23s (- 0m 15s)
Iter: 280, Loss 0.001061, Num updates: 280, Wall time: 2251.04, ETA: 0m 26s (- 0m 11s)
Iter: 320, Loss 0.001061, Num updates: 320, Wall time: 2254.77, ETA: 0m 30s (- 0m 7s)
Iter: 360, Loss 0.001064, Num updates: 360, Wall time: 2258.42, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001066, Num updates: 400, Wall time: 2262.19, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 58, time: 38.48
	train_loss: 0.0011, score: 27.81
	eval score: 0.00 (0.00)
Iter: 40, Loss 0.001034, Num updates: 40, Wall time: 2267.84, ETA: 0m 4s (- 0m 43s)
Iter: 80, Loss 0.001040, Num updates: 80, Wall time: 2271.11, ETA: 0m 7s (- 0m 32s)
Iter: 120, Loss 0.001049, Num updates: 120, Wall time: 2274.55, ETA: 0m 11s (- 0m 26s)
Iter: 160, Loss 0.001051, Num updates: 160, Wall time: 2278.08, ETA: 0m 14s (- 0m 22s)
Iter: 200, Loss 0.001053, Num updates: 200, Wall time: 2281.80, ETA: 0m 18s (- 0m 18s)
Iter: 240, Loss 0.001055, Num updates: 240, Wall time: 2285.41, ETA: 0m 22s (- 0m 14s)
Iter: 280, Loss 0.001057, Num updates: 280, Wall time: 2288.93, ETA: 0m 25s (- 0m 11s)
Iter: 320, Loss 0.001062, Num updates: 320, Wall time: 2292.62, ETA: 0m 29s (- 0m 7s)
Iter: 360, Loss 0.001061, Num updates: 360, Wall time: 2296.46, ETA: 0m 33s (- 0m 3s)
Iter: 400, Loss 0.001064, Num updates: 400, Wall time: 2300.25, ETA: 0m 37s (- 0m 0s)
Evaluating...
epoch 59, time: 37.96
	train_loss: 0.0011, score: 27.50
	eval score: 0.00 (0.00)
0.00431,0.00188,0.00179,0.00171,0.00167,0.00165,0.00163,0.00162,0.0016,0.00159,0.00157,0.00156,0.00155,0.00153,0.00152,0.0015,0.00149,0.00147,0.00146,0.00144,0.00142,0.00141,0.00139,0.00137,0.00136,0.00134,0.00133,0.00132,0.00131,0.00129,0.00128,0.00126,0.00126,0.00125,0.00124,0.00122,0.00122,0.00121,0.0012,0.00119,0.00118,0.00117,0.00116,0.00116,0.00115,0.00115,0.00114,0.00113,0.00112,0.00112,0.00111,0.00111,0.0011,0.0011,0.00109,0.00108,0.00108,0.00108,0.00107,0.00107
0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
<pymysql.connections.Connection object at 0x7fe24f1d1820>
saved_model_OVQA/SAN_MEVF
Namespace(RAD_dir='/home/coder/projects/SystemDataset/data_OVQA_as_RAD', activation='relu', ae_alpha=0.001, ae_model_path='pretrained_ae.pth', alpha=1.0, autoencoder=True, batch_size=64, clip_norm=0.25, dropout=0.5, epochs=80, eps_cnn=1e-05, feat_dim=32, five_fold=False, gamma=2, gpu=0, input=None, lr=0.03, maml=True, maml_model_path='pretrained_maml.weights', model='SAN', momentum_cnn=0.05, num_hid=1024, num_stacks=2, op='c', output='saved_model_OVQA/SAN_MEVF', pow=2, print_interval=40, qc_model_path='./saved_models/QC/rad_best.pth', question_len=12, record_id=1, rescale_factor=1.5, rnn='LSTM', seed=3, tfidf=True, update_freq='1', use_RAD=True, use_ablation=False, use_ablation_q=False, use_ablation_v=False, use_counter=False, use_grad_cam=False, use_kl_mix=False, use_mix=True, use_mix_all=False, use_mix_cond=True, use_mix_cond_q=True, use_mix_cond_v=False, use_mix_cond_vq_in=False, use_mix_cond_vq_union=False, use_partial_label=False, use_rescale=False, use_sep_mix=False)
loading dictionary from /home/coder/projects/SystemDataset/data_OVQA_as_RAD/dictionary.pkl
loading MAML image data from file: /home/coder/projects/SystemDataset/data_OVQA_as_RAD/images84x84.pkl
loading DAE image data from file: /home/coder/projects/SystemDataset/data_OVQA_as_RAD/images128x128.pkl
loading MAML image data from file: /home/coder/projects/SystemDataset/data_OVQA_as_RAD/images84x84.pkl
loading DAE image data from file: /home/coder/projects/SystemDataset/data_OVQA_as_RAD/images128x128.pkl
load initial weights MAML from: /home/coder/projects/SystemDataset/data_OVQA_as_RAD/pretrained_maml.weights
load initial weights DAE from: /home/coder/projects/SystemDataset/data_OVQA_as_RAD/pretrained_ae.pth
loading dictionary from /home/coder/projects/SystemDataset/data_OVQA_as_RAD/dictionary.pkl
Loading embedding tfidf and weights from file
Load embedding tfidf and weights from file successfully
Namespace(RAD_dir='/home/coder/projects/SystemDataset/data_OVQA_as_RAD', activation='relu', ae_alpha=0.001, ae_model_path='pretrained_ae.pth', alpha=1.0, autoencoder=True, batch_size=64, clip_norm=0.25, device=device(type='cuda', index=0), dropout=0.5, epochs=80, eps_cnn=1e-05, feat_dim=64, five_fold=False, gamma=2, gpu=0, input=None, lr=0.03, maml=True, maml_model_path='pretrained_maml.weights', model='SAN', momentum_cnn=0.05, num_hid=1024, num_stacks=2, op='c', output='saved_model_OVQA/SAN_MEVF', pow=2, print_interval=40, qc_model_path='./saved_models/QC/rad_best.pth', question_len=12, record_id=1, rescale_factor=1.5, rnn='LSTM', seed=3, tfidf=True, update_freq='1', use_RAD=True, use_ablation=False, use_ablation_q=False, use_ablation_v=False, use_counter=False, use_grad_cam=False, use_kl_mix=False, use_mix=True, use_mix_all=False, use_mix_cond=True, use_mix_cond_q=True, use_mix_cond_v=False, use_mix_cond_vq_in=False, use_mix_cond_vq_union=False, use_partial_label=False, use_rescale=False, use_sep_mix=False)
nParams=	15101955
optim: adamax lr=0.0300, decay_step=3, decay_rate=0.75, grad_clip=0.25
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'language_model.WordEmbedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
/home/coder/miniconda/envs/VQAMix/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Iter: 40, Loss 0.024542, Num updates: 40, Wall time: 6.19, ETA: 0m 6s (- 0m 31s)
Iter: 80, Loss 0.013598, Num updates: 80, Wall time: 11.24, ETA: 0m 11s (- 0m 22s)
Iter: 120, Loss 0.009854, Num updates: 120, Wall time: 16.26, ETA: 0m 16s (- 0m 16s)
Iter: 160, Loss 0.007921, Num updates: 160, Wall time: 21.09, ETA: 0m 21s (- 0m 10s)
Iter: 200, Loss 0.006753, Num updates: 200, Wall time: 26.10, ETA: 0m 26s (- 0m 5s)
Evaluating...
epoch 0, time: 55.47
	train_loss: 0.0060, score: 31.22
	eval score: 235.06 (617.53)
Iter: 40, Loss 0.001836, Num updates: 40, Wall time: 62.52, ETA: 0m 6s (- 0m 32s)
Iter: 80, Loss 0.001867, Num updates: 80, Wall time: 66.96, ETA: 0m 10s (- 0m 21s)
Iter: 120, Loss 0.001863, Num updates: 120, Wall time: 72.54, ETA: 0m 16s (- 0m 16s)
Iter: 160, Loss 0.001861, Num updates: 160, Wall time: 78.12, ETA: 0m 21s (- 0m 10s)
Iter: 200, Loss 0.001853, Num updates: 200, Wall time: 83.27, ETA: 0m 27s (- 0m 5s)
Evaluating...
epoch 1, time: 59.54
	train_loss: 0.0019, score: 40.01
	eval score: 260.06 (617.53)
Iter: 40, Loss 0.001739, Num updates: 40, Wall time: 123.20, ETA: 0m 6s (- 0m 33s)
Iter: 80, Loss 0.001752, Num updates: 80, Wall time: 128.97, ETA: 0m 12s (- 0m 24s)
Iter: 120, Loss 0.001760, Num updates: 120, Wall time: 134.39, ETA: 0m 17s (- 0m 17s)
Iter: 160, Loss 0.001754, Num updates: 160, Wall time: 139.40, ETA: 0m 22s (- 0m 11s)
Iter: 200, Loss 0.001763, Num updates: 200, Wall time: 144.44, ETA: 0m 27s (- 0m 5s)
Evaluating...
epoch 2, time: 59.49
	train_loss: 0.0018, score: 44.03
	eval score: 273.38 (617.53)
Iter: 40, Loss 0.001678, Num updates: 40, Wall time: 181.84, ETA: 0m 5s (- 0m 25s)
Iter: 80, Loss 0.001688, Num updates: 80, Wall time: 186.70, ETA: 0m 9s (- 0m 19s)
Iter: 120, Loss 0.001707, Num updates: 120, Wall time: 191.63, ETA: 0m 14s (- 0m 14s)
Iter: 160, Loss 0.001700, Num updates: 160, Wall time: 196.38, ETA: 0m 19s (- 0m 9s)
Iter: 200, Loss 0.001707, Num updates: 200, Wall time: 201.86, ETA: 0m 25s (- 0m 4s)
Evaluating...
epoch 3, time: 54.41
	train_loss: 0.0017, score: 45.75
	eval score: 278.90 (617.53)
Iter: 40, Loss 0.001599, Num updates: 40, Wall time: 238.73, ETA: 0m 6s (- 0m 34s)
Iter: 80, Loss 0.001643, Num updates: 80, Wall time: 243.69, ETA: 0m 11s (- 0m 23s)
Iter: 120, Loss 0.001652, Num updates: 120, Wall time: 248.57, ETA: 0m 16s (- 0m 16s)
Iter: 160, Loss 0.001664, Num updates: 160, Wall time: 253.62, ETA: 0m 21s (- 0m 10s)
Iter: 200, Loss 0.001668, Num updates: 200, Wall time: 259.10, ETA: 0m 27s (- 0m 5s)
Evaluating...
epoch 4, time: 63.89
	train_loss: 0.0017, score: 46.74
	eval score: 284.42 (617.53)
Iter: 40, Loss 0.001637, Num updates: 40, Wall time: 302.13, ETA: 0m 5s (- 0m 27s)
Iter: 80, Loss 0.001644, Num updates: 80, Wall time: 307.73, ETA: 0m 10s (- 0m 22s)
Iter: 120, Loss 0.001657, Num updates: 120, Wall time: 313.14, ETA: 0m 16s (- 0m 16s)
Iter: 160, Loss 0.001652, Num updates: 160, Wall time: 318.40, ETA: 0m 21s (- 0m 10s)
Iter: 200, Loss 0.001645, Num updates: 200, Wall time: 323.27, ETA: 0m 26s (- 0m 5s)
Evaluating...
epoch 5, time: 55.87
	train_loss: 0.0016, score: 47.31
	eval score: 296.43 (617.53)
Iter: 40, Loss 0.001626, Num updates: 40, Wall time: 358.99, ETA: 0m 5s (- 0m 28s)
Iter: 80, Loss 0.001616, Num updates: 80, Wall time: 363.65, ETA: 0m 10s (- 0m 20s)
Iter: 120, Loss 0.001612, Num updates: 120, Wall time: 368.94, ETA: 0m 15s (- 0m 15s)
Iter: 160, Loss 0.001617, Num updates: 160, Wall time: 373.96, ETA: 0m 20s (- 0m 10s)
Iter: 200, Loss 0.001621, Num updates: 200, Wall time: 379.51, ETA: 0m 26s (- 0m 5s)
Evaluating...
epoch 6, time: 56.66
	train_loss: 0.0016, score: 47.03
	eval score: 294.48 (617.53)
Iter: 40, Loss 0.001548, Num updates: 40, Wall time: 415.45, ETA: 0m 5s (- 0m 27s)
Iter: 80, Loss 0.001589, Num updates: 80, Wall time: 420.27, ETA: 0m 10s (- 0m 20s)
Iter: 120, Loss 0.001592, Num updates: 120, Wall time: 425.09, ETA: 0m 15s (- 0m 15s)
Iter: 160, Loss 0.001596, Num updates: 160, Wall time: 429.86, ETA: 0m 19s (- 0m 9s)
Iter: 200, Loss 0.001591, Num updates: 200, Wall time: 435.55, ETA: 0m 25s (- 0m 5s)
Evaluating...
epoch 7, time: 60.61
	train_loss: 0.0016, score: 47.03
	eval score: 295.78 (617.53)
Iter: 40, Loss 0.001543, Num updates: 40, Wall time: 477.04, ETA: 0m 6s (- 0m 32s)
Iter: 80, Loss 0.001552, Num updates: 80, Wall time: 481.87, ETA: 0m 11s (- 0m 22s)
Iter: 120, Loss 0.001563, Num updates: 120, Wall time: 486.51, ETA: 0m 15s (- 0m 15s)
Iter: 160, Loss 0.001566, Num updates: 160, Wall time: 491.69, ETA: 0m 21s (- 0m 10s)
Iter: 200, Loss 0.001573, Num updates: 200, Wall time: 497.22, ETA: 0m 26s (- 0m 5s)
Evaluating...
epoch 8, time: 56.14
	train_loss: 0.0016, score: 47.63
	eval score: 287.99 (617.53)
Iter: 40, Loss 0.001537, Num updates: 40, Wall time: 532.19, ETA: 0m 5s (- 0m 27s)
Iter: 80, Loss 0.001557, Num updates: 80, Wall time: 536.96, ETA: 0m 10s (- 0m 20s)
Iter: 120, Loss 0.001570, Num updates: 120, Wall time: 542.12, ETA: 0m 15s (- 0m 15s)
Iter: 160, Loss 0.001559, Num updates: 160, Wall time: 547.64, ETA: 0m 20s (- 0m 10s)
Iter: 200, Loss 0.001560, Num updates: 200, Wall time: 552.73, ETA: 0m 25s (- 0m 5s)
Evaluating...
epoch 9, time: 59.70
	train_loss: 0.0016, score: 48.35
	eval score: 310.06 (617.53)
Iter: 40, Loss 0.001538, Num updates: 40, Wall time: 593.62, ETA: 0m 6s (- 0m 31s)
Iter: 80, Loss 0.001548, Num updates: 80, Wall time: 598.23, ETA: 0m 10s (- 0m 21s)
Iter: 120, Loss 0.001549, Num updates: 120, Wall time: 603.24, ETA: 0m 15s (- 0m 15s)
Iter: 160, Loss 0.001555, Num updates: 160, Wall time: 608.45, ETA: 0m 20s (- 0m 10s)
Iter: 200, Loss 0.001554, Num updates: 200, Wall time: 613.84, ETA: 0m 26s (- 0m 5s)
Evaluating...
epoch 10, time: 60.08
	train_loss: 0.0016, score: 47.47
	eval score: 310.71 (617.53)
Iter: 40, Loss 0.001493, Num updates: 40, Wall time: 654.57, ETA: 0m 5s (- 0m 30s)
Iter: 80, Loss 0.001512, Num updates: 80, Wall time: 659.77, ETA: 0m 11s (- 0m 22s)
Iter: 120, Loss 0.001520, Num updates: 120, Wall time: 665.02, ETA: 0m 16s (- 0m 16s)
Iter: 160, Loss 0.001533, Num updates: 160, Wall time: 670.20, ETA: 0m 21s (- 0m 10s)
Iter: 200, Loss 0.001531, Num updates: 200, Wall time: 675.38, ETA: 0m 26s (- 0m 5s)
Evaluating...
epoch 11, time: 58.61
	train_loss: 0.0015, score: 47.58
	eval score: 304.22 (617.53)
Iter: 40, Loss 0.001483, Num updates: 40, Wall time: 713.00, ETA: 0m 5s (- 0m 29s)
Iter: 80, Loss 0.001516, Num updates: 80, Wall time: 717.94, ETA: 0m 10s (- 0m 21s)
Iter: 120, Loss 0.001513, Num updates: 120, Wall time: 722.81, ETA: 0m 15s (- 0m 15s)
Iter: 160, Loss 0.001521, Num updates: 160, Wall time: 727.75, ETA: 0m 20s (- 0m 10s)
Iter: 200, Loss 0.001519, Num updates: 200, Wall time: 732.49, ETA: 0m 25s (- 0m 4s)
Evaluating...
epoch 12, time: 53.62
	train_loss: 0.0015, score: 47.95
	eval score: 306.17 (617.53)
Iter: 40, Loss 0.001442, Num updates: 40, Wall time: 766.46, ETA: 0m 5s (- 0m 28s)
Iter: 80, Loss 0.001470, Num updates: 80, Wall time: 771.29, ETA: 0m 10s (- 0m 20s)
Iter: 120, Loss 0.001484, Num updates: 120, Wall time: 775.75, ETA: 0m 14s (- 0m 14s)
Iter: 160, Loss 0.001490, Num updates: 160, Wall time: 780.64, ETA: 0m 19s (- 0m 9s)
Iter: 200, Loss 0.001501, Num updates: 200, Wall time: 785.43, ETA: 0m 24s (- 0m 4s)
Evaluating...
epoch 13, time: 52.93
	train_loss: 0.0015, score: 47.92
	eval score: 317.86 (617.53)
Iter: 40, Loss 0.001481, Num updates: 40, Wall time: 819.73, ETA: 0m 5s (- 0m 26s)
Iter: 80, Loss 0.001488, Num updates: 80, Wall time: 824.35, ETA: 0m 9s (- 0m 19s)
Iter: 120, Loss 0.001500, Num updates: 120, Wall time: 829.38, ETA: 0m 14s (- 0m 14s)
Iter: 160, Loss 0.001501, Num updates: 160, Wall time: 834.28, ETA: 0m 19s (- 0m 9s)
Iter: 200, Loss 0.001496, Num updates: 200, Wall time: 839.79, ETA: 0m 25s (- 0m 4s)
Evaluating...
epoch 14, time: 55.02
	train_loss: 0.0015, score: 47.65
	eval score: 322.40 (617.53)
Iter: 40, Loss 0.001475, Num updates: 40, Wall time: 875.81, ETA: 0m 5s (- 0m 27s)
Iter: 80, Loss 0.001478, Num updates: 80, Wall time: 880.42, ETA: 0m 10s (- 0m 20s)
Iter: 120, Loss 0.001479, Num updates: 120, Wall time: 884.81, ETA: 0m 14s (- 0m 14s)
Iter: 160, Loss 0.001472, Num updates: 160, Wall time: 889.45, ETA: 0m 19s (- 0m 9s)
Iter: 200, Loss 0.001479, Num updates: 200, Wall time: 894.44, ETA: 0m 24s (- 0m 4s)
Evaluating...
epoch 15, time: 53.18
	train_loss: 0.0015, score: 47.97
	eval score: 321.43 (617.53)
Iter: 40, Loss 0.001441, Num updates: 40, Wall time: 928.98, ETA: 0m 5s (- 0m 27s)
Iter: 80, Loss 0.001466, Num updates: 80, Wall time: 933.77, ETA: 0m 10s (- 0m 20s)
Iter: 120, Loss 0.001464, Num updates: 120, Wall time: 938.69, ETA: 0m 15s (- 0m 15s)
Iter: 160, Loss 0.001469, Num updates: 160, Wall time: 943.59, ETA: 0m 19s (- 0m 9s)
Iter: 200, Loss 0.001463, Num updates: 200, Wall time: 948.28, ETA: 0m 24s (- 0m 4s)
Evaluating...
epoch 16, time: 54.51
	train_loss: 0.0015, score: 48.33
	eval score: 320.78 (617.53)
Iter: 40, Loss 0.001411, Num updates: 40, Wall time: 983.62, ETA: 0m 5s (- 0m 28s)
Iter: 80, Loss 0.001420, Num updates: 80, Wall time: 988.47, ETA: 0m 10s (- 0m 20s)
Iter: 120, Loss 0.001433, Num updates: 120, Wall time: 994.40, ETA: 0m 16s (- 0m 16s)
Iter: 160, Loss 0.001443, Num updates: 160, Wall time: 999.45, ETA: 0m 21s (- 0m 10s)
Iter: 200, Loss 0.001443, Num updates: 200, Wall time: 1004.52, ETA: 0m 26s (- 0m 5s)
Evaluating...
epoch 17, time: 54.79
	train_loss: 0.0015, score: 48.34
	eval score: 325.00 (617.53)
Iter: 40, Loss 0.001387, Num updates: 40, Wall time: 1039.20, ETA: 0m 5s (- 0m 28s)
Iter: 80, Loss 0.001416, Num updates: 80, Wall time: 1043.85, ETA: 0m 10s (- 0m 20s)
Iter: 120, Loss 0.001419, Num updates: 120, Wall time: 1049.44, ETA: 0m 15s (- 0m 15s)
Iter: 160, Loss 0.001426, Num updates: 160, Wall time: 1056.21, ETA: 0m 22s (- 0m 11s)
Iter: 200, Loss 0.001432, Num updates: 200, Wall time: 1061.80, ETA: 0m 28s (- 0m 5s)
Evaluating...
epoch 18, time: 56.96
	train_loss: 0.0014, score: 47.50
	eval score: 328.25 (617.53)
Iter: 40, Loss 0.001353, Num updates: 40, Wall time: 1097.11, ETA: 0m 5s (- 0m 28s)
Iter: 80, Loss 0.001381, Num updates: 80, Wall time: 1101.88, ETA: 0m 10s (- 0m 20s)
Iter: 120, Loss 0.001403, Num updates: 120, Wall time: 1106.74, ETA: 0m 15s (- 0m 15s)
Iter: 160, Loss 0.001416, Num updates: 160, Wall time: 1111.82, ETA: 0m 20s (- 0m 10s)
Iter: 200, Loss 0.001421, Num updates: 200, Wall time: 1116.73, ETA: 0m 25s (- 0m 4s)
Evaluating...
epoch 19, time: 58.70
	train_loss: 0.0014, score: 48.00
	eval score: 325.65 (617.53)
Iter: 40, Loss 0.001364, Num updates: 40, Wall time: 1156.29, ETA: 0m 6s (- 0m 30s)
Iter: 80, Loss 0.001394, Num updates: 80, Wall time: 1161.33, ETA: 0m 11s (- 0m 22s)
Iter: 120, Loss 0.001393, Num updates: 120, Wall time: 1166.56, ETA: 0m 16s (- 0m 16s)
Iter: 160, Loss 0.001397, Num updates: 160, Wall time: 1171.51, ETA: 0m 21s (- 0m 10s)
Iter: 200, Loss 0.001403, Num updates: 200, Wall time: 1176.76, ETA: 0m 26s (- 0m 5s)
Evaluating...
epoch 20, time: 58.72
	train_loss: 0.0014, score: 48.63
	eval score: 325.65 (617.53)
Iter: 40, Loss 0.001329, Num updates: 40, Wall time: 1214.33, ETA: 0m 5s (- 0m 27s)
Iter: 80, Loss 0.001351, Num updates: 80, Wall time: 1219.06, ETA: 0m 10s (- 0m 20s)
Iter: 120, Loss 0.001372, Num updates: 120, Wall time: 1223.58, ETA: 0m 14s (- 0m 14s)
Iter: 160, Loss 0.001377, Num updates: 160, Wall time: 1228.45, ETA: 0m 19s (- 0m 9s)
Iter: 200, Loss 0.001384, Num updates: 200, Wall time: 1233.89, ETA: 0m 24s (- 0m 4s)
Evaluating...
epoch 21, time: 55.28
	train_loss: 0.0014, score: 48.11
	eval score: 327.27 (617.53)
Iter: 40, Loss 0.001329, Num updates: 40, Wall time: 1269.93, ETA: 0m 5s (- 0m 28s)
Iter: 80, Loss 0.001360, Num updates: 80, Wall time: 1274.61, ETA: 0m 10s (- 0m 20s)
Iter: 120, Loss 0.001354, Num updates: 120, Wall time: 1279.26, ETA: 0m 14s (- 0m 14s)
Iter: 160, Loss 0.001360, Num updates: 160, Wall time: 1283.91, ETA: 0m 19s (- 0m 9s)
Iter: 200, Loss 0.001363, Num updates: 200, Wall time: 1288.87, ETA: 0m 24s (- 0m 4s)
Evaluating...
epoch 22, time: 55.47
	train_loss: 0.0014, score: 48.75
	eval score: 329.87 (617.53)
Iter: 40, Loss 0.001329, Num updates: 40, Wall time: 1326.05, ETA: 0m 5s (- 0m 28s)
Iter: 80, Loss 0.001338, Num updates: 80, Wall time: 1330.91, ETA: 0m 10s (- 0m 20s)
Iter: 120, Loss 0.001351, Num updates: 120, Wall time: 1336.56, ETA: 0m 16s (- 0m 16s)
Iter: 160, Loss 0.001355, Num updates: 160, Wall time: 1341.78, ETA: 0m 21s (- 0m 10s)
Iter: 200, Loss 0.001357, Num updates: 200, Wall time: 1346.72, ETA: 0m 26s (- 0m 5s)
Evaluating...
epoch 23, time: 55.72
	train_loss: 0.0014, score: 48.92
	eval score: 326.95 (617.53)
Iter: 40, Loss 0.001295, Num updates: 40, Wall time: 1381.66, ETA: 0m 5s (- 0m 27s)
Iter: 80, Loss 0.001325, Num updates: 80, Wall time: 1387.13, ETA: 0m 10s (- 0m 21s)
Iter: 120, Loss 0.001332, Num updates: 120, Wall time: 1392.11, ETA: 0m 15s (- 0m 15s)
Iter: 160, Loss 0.001336, Num updates: 160, Wall time: 1397.33, ETA: 0m 21s (- 0m 10s)
Iter: 200, Loss 0.001339, Num updates: 200, Wall time: 1402.60, ETA: 0m 26s (- 0m 5s)
Evaluating...
epoch 24, time: 57.46
	train_loss: 0.0013, score: 49.53
	eval score: 335.39 (617.53)
Iter: 40, Loss 0.001299, Num updates: 40, Wall time: 1440.03, ETA: 0m 5s (- 0m 27s)
Iter: 80, Loss 0.001314, Num updates: 80, Wall time: 1444.93, ETA: 0m 10s (- 0m 20s)
Iter: 120, Loss 0.001322, Num updates: 120, Wall time: 1449.49, ETA: 0m 14s (- 0m 14s)
Iter: 160, Loss 0.001320, Num updates: 160, Wall time: 1454.13, ETA: 0m 19s (- 0m 9s)
Iter: 200, Loss 0.001318, Num updates: 200, Wall time: 1459.03, ETA: 0m 24s (- 0m 4s)
Evaluating...
epoch 25, time: 52.91
	train_loss: 0.0013, score: 48.48
	eval score: 344.16 (617.53)
Iter: 40, Loss 0.001273, Num updates: 40, Wall time: 1493.62, ETA: 0m 5s (- 0m 27s)
Iter: 80, Loss 0.001279, Num updates: 80, Wall time: 1498.54, ETA: 0m 10s (- 0m 20s)
Iter: 120, Loss 0.001290, Num updates: 120, Wall time: 1503.42, ETA: 0m 15s (- 0m 15s)
Iter: 160, Loss 0.001299, Num updates: 160, Wall time: 1508.19, ETA: 0m 19s (- 0m 9s)
Iter: 200, Loss 0.001302, Num updates: 200, Wall time: 1513.39, ETA: 0m 25s (- 0m 4s)
Evaluating...
epoch 26, time: 59.85
	train_loss: 0.0013, score: 48.49
	eval score: 346.75 (617.53)
Iter: 40, Loss 0.001254, Num updates: 40, Wall time: 1555.02, ETA: 0m 6s (- 0m 30s)
Iter: 80, Loss 0.001261, Num updates: 80, Wall time: 1559.99, ETA: 0m 10s (- 0m 22s)
Iter: 120, Loss 0.001273, Num updates: 120, Wall time: 1565.11, ETA: 0m 16s (- 0m 16s)
Iter: 160, Loss 0.001279, Num updates: 160, Wall time: 1570.40, ETA: 0m 21s (- 0m 10s)
Iter: 200, Loss 0.001283, Num updates: 200, Wall time: 1575.61, ETA: 0m 26s (- 0m 5s)
Evaluating...
epoch 27, time: 60.23
	train_loss: 0.0013, score: 48.60
	eval score: 345.13 (617.53)
Iter: 40, Loss 0.001226, Num updates: 40, Wall time: 1615.45, ETA: 0m 6s (- 0m 31s)
Iter: 80, Loss 0.001249, Num updates: 80, Wall time: 1620.58, ETA: 0m 11s (- 0m 22s)
Iter: 120, Loss 0.001254, Num updates: 120, Wall time: 1625.69, ETA: 0m 16s (- 0m 16s)
Iter: 160, Loss 0.001265, Num updates: 160, Wall time: 1630.55, ETA: 0m 21s (- 0m 10s)
Iter: 200, Loss 0.001270, Num updates: 200, Wall time: 1635.31, ETA: 0m 26s (- 0m 5s)
Evaluating...
epoch 28, time: 58.98
	train_loss: 0.0013, score: 49.33
	eval score: 351.30 (617.53)
Iter: 40, Loss 0.001210, Num updates: 40, Wall time: 1674.37, ETA: 0m 5s (- 0m 27s)
Iter: 80, Loss 0.001227, Num updates: 80, Wall time: 1679.24, ETA: 0m 10s (- 0m 20s)
Iter: 120, Loss 0.001239, Num updates: 120, Wall time: 1684.50, ETA: 0m 15s (- 0m 15s)
Iter: 160, Loss 0.001245, Num updates: 160, Wall time: 1689.29, ETA: 0m 20s (- 0m 10s)
Iter: 200, Loss 0.001247, Num updates: 200, Wall time: 1694.71, ETA: 0m 25s (- 0m 5s)
Evaluating...
epoch 29, time: 57.61
	train_loss: 0.0013, score: 49.56
	eval score: 352.92 (617.53)
Iter: 40, Loss 0.001199, Num updates: 40, Wall time: 1733.42, ETA: 0m 6s (- 0m 30s)
Iter: 80, Loss 0.001210, Num updates: 80, Wall time: 1738.33, ETA: 0m 10s (- 0m 22s)
Iter: 120, Loss 0.001224, Num updates: 120, Wall time: 1743.68, ETA: 0m 16s (- 0m 16s)
Iter: 160, Loss 0.001231, Num updates: 160, Wall time: 1748.85, ETA: 0m 21s (- 0m 10s)
Iter: 200, Loss 0.001235, Num updates: 200, Wall time: 1754.95, ETA: 0m 27s (- 0m 5s)
Evaluating...
epoch 30, time: 56.20
	train_loss: 0.0012, score: 49.63
	eval score: 362.01 (617.53)
Iter: 40, Loss 0.001196, Num updates: 40, Wall time: 1789.79, ETA: 0m 5s (- 0m 27s)
Iter: 80, Loss 0.001212, Num updates: 80, Wall time: 1794.74, ETA: 0m 10s (- 0m 20s)
Iter: 120, Loss 0.001214, Num updates: 120, Wall time: 1799.41, ETA: 0m 15s (- 0m 15s)
Iter: 160, Loss 0.001217, Num updates: 160, Wall time: 1804.16, ETA: 0m 19s (- 0m 9s)
Iter: 200, Loss 0.001222, Num updates: 200, Wall time: 1808.83, ETA: 0m 24s (- 0m 4s)
Evaluating...
epoch 31, time: 52.63
	train_loss: 0.0012, score: 49.09
	eval score: 358.12 (617.53)
Iter: 40, Loss 0.001167, Num updates: 40, Wall time: 1842.23, ETA: 0m 5s (- 0m 26s)
Iter: 80, Loss 0.001187, Num updates: 80, Wall time: 1846.88, ETA: 0m 9s (- 0m 19s)
Iter: 120, Loss 0.001194, Num updates: 120, Wall time: 1851.30, ETA: 0m 14s (- 0m 14s)
Iter: 160, Loss 0.001205, Num updates: 160, Wall time: 1856.38, ETA: 0m 19s (- 0m 9s)
Iter: 200, Loss 0.001210, Num updates: 200, Wall time: 1861.08, ETA: 0m 24s (- 0m 4s)
Evaluating...
epoch 32, time: 56.64
	train_loss: 0.0012, score: 48.91
	eval score: 365.91 (617.53)
Iter: 40, Loss 0.001177, Num updates: 40, Wall time: 1900.52, ETA: 0m 5s (- 0m 29s)
Iter: 80, Loss 0.001186, Num updates: 80, Wall time: 1905.50, ETA: 0m 10s (- 0m 21s)
Iter: 120, Loss 0.001194, Num updates: 120, Wall time: 1910.22, ETA: 0m 15s (- 0m 15s)
Iter: 160, Loss 0.001194, Num updates: 160, Wall time: 1914.84, ETA: 0m 20s (- 0m 9s)
Iter: 200, Loss 0.001200, Num updates: 200, Wall time: 1919.50, ETA: 0m 24s (- 0m 4s)
Evaluating...
epoch 33, time: 53.48
	train_loss: 0.0012, score: 49.85
	eval score: 367.86 (617.53)
Iter: 40, Loss 0.001155, Num updates: 40, Wall time: 1955.03, ETA: 0m 6s (- 0m 30s)
Iter: 80, Loss 0.001175, Num updates: 80, Wall time: 1960.04, ETA: 0m 11s (- 0m 22s)
Iter: 120, Loss 0.001182, Num updates: 120, Wall time: 1964.87, ETA: 0m 15s (- 0m 15s)
Iter: 160, Loss 0.001182, Num updates: 160, Wall time: 1969.76, ETA: 0m 20s (- 0m 10s)
Iter: 200, Loss 0.001184, Num updates: 200, Wall time: 1975.12, ETA: 0m 26s (- 0m 5s)
Evaluating...
epoch 34, time: 57.02
	train_loss: 0.0012, score: 49.55
	eval score: 364.29 (617.53)
Iter: 40, Loss 0.001147, Num updates: 40, Wall time: 2011.84, ETA: 0m 5s (- 0m 29s)
Iter: 80, Loss 0.001159, Num updates: 80, Wall time: 2016.86, ETA: 0m 10s (- 0m 21s)
Iter: 120, Loss 0.001166, Num updates: 120, Wall time: 2021.37, ETA: 0m 15s (- 0m 15s)
Iter: 160, Loss 0.001175, Num updates: 160, Wall time: 2026.34, ETA: 0m 20s (- 0m 10s)
Iter: 200, Loss 0.001179, Num updates: 200, Wall time: 2031.06, ETA: 0m 25s (- 0m 4s)
Evaluating...
epoch 35, time: 58.02
	train_loss: 0.0012, score: 49.47
	eval score: 371.75 (617.53)
Iter: 40, Loss 0.001124, Num updates: 40, Wall time: 2070.21, ETA: 0m 5s (- 0m 27s)
Iter: 80, Loss 0.001145, Num updates: 80, Wall time: 2074.91, ETA: 0m 10s (- 0m 20s)
Iter: 120, Loss 0.001154, Num updates: 120, Wall time: 2079.57, ETA: 0m 14s (- 0m 14s)
Iter: 160, Loss 0.001158, Num updates: 160, Wall time: 2084.51, ETA: 0m 19s (- 0m 9s)
Iter: 200, Loss 0.001162, Num updates: 200, Wall time: 2089.17, ETA: 0m 24s (- 0m 4s)
Evaluating...
epoch 36, time: 56.02
	train_loss: 0.0012, score: 49.84
	eval score: 374.03 (617.53)
Iter: 40, Loss 0.001133, Num updates: 40, Wall time: 2128.00, ETA: 0m 6s (- 0m 32s)
Iter: 80, Loss 0.001143, Num updates: 80, Wall time: 2133.33, ETA: 0m 11s (- 0m 23s)
Iter: 120, Loss 0.001151, Num updates: 120, Wall time: 2138.72, ETA: 0m 17s (- 0m 17s)
Iter: 160, Loss 0.001155, Num updates: 160, Wall time: 2143.43, ETA: 0m 21s (- 0m 10s)
Iter: 200, Loss 0.001154, Num updates: 200, Wall time: 2148.02, ETA: 0m 26s (- 0m 5s)
Evaluating...
epoch 37, time: 55.41
	train_loss: 0.0012, score: 49.43
	eval score: 381.17 (617.53)
Iter: 40, Loss 0.001117, Num updates: 40, Wall time: 2183.28, ETA: 0m 5s (- 0m 28s)
Iter: 80, Loss 0.001137, Num updates: 80, Wall time: 2187.94, ETA: 0m 10s (- 0m 20s)
Iter: 120, Loss 0.001141, Num updates: 120, Wall time: 2193.08, ETA: 0m 15s (- 0m 15s)
Iter: 160, Loss 0.001146, Num updates: 160, Wall time: 2198.09, ETA: 0m 20s (- 0m 10s)
Iter: 200, Loss 0.001148, Num updates: 200, Wall time: 2203.01, ETA: 0m 25s (- 0m 4s)
Evaluating...
epoch 38, time: 56.95
	train_loss: 0.0012, score: 50.18
	eval score: 376.62 (617.53)
Iter: 40, Loss 0.001131, Num updates: 40, Wall time: 2240.75, ETA: 0m 5s (- 0m 30s)
Iter: 80, Loss 0.001143, Num updates: 80, Wall time: 2246.09, ETA: 0m 11s (- 0m 22s)
Iter: 120, Loss 0.001140, Num updates: 120, Wall time: 2250.91, ETA: 0m 16s (- 0m 16s)
Iter: 160, Loss 0.001142, Num updates: 160, Wall time: 2255.53, ETA: 0m 20s (- 0m 10s)
Iter: 200, Loss 0.001144, Num updates: 200, Wall time: 2260.22, ETA: 0m 25s (- 0m 4s)
Evaluating...
epoch 39, time: 58.64
	train_loss: 0.0011, score: 49.52
	eval score: 384.42 (617.53)
Iter: 40, Loss 0.001096, Num updates: 40, Wall time: 2299.53, ETA: 0m 5s (- 0m 26s)
Iter: 80, Loss 0.001115, Num updates: 80, Wall time: 2304.41, ETA: 0m 10s (- 0m 20s)
Iter: 120, Loss 0.001124, Num updates: 120, Wall time: 2309.15, ETA: 0m 14s (- 0m 14s)
Iter: 160, Loss 0.001130, Num updates: 160, Wall time: 2314.04, ETA: 0m 19s (- 0m 9s)
Iter: 200, Loss 0.001129, Num updates: 200, Wall time: 2318.81, ETA: 0m 24s (- 0m 4s)
Evaluating...
epoch 40, time: 52.64
	train_loss: 0.0011, score: 49.75
	eval score: 381.49 (617.53)
Iter: 40, Loss 0.001089, Num updates: 40, Wall time: 2352.46, ETA: 0m 5s (- 0m 28s)
Iter: 80, Loss 0.001112, Num updates: 80, Wall time: 2357.04, ETA: 0m 10s (- 0m 20s)
Iter: 120, Loss 0.001123, Num updates: 120, Wall time: 2361.67, ETA: 0m 14s (- 0m 14s)
Iter: 160, Loss 0.001124, Num updates: 160, Wall time: 2366.37, ETA: 0m 19s (- 0m 9s)
Iter: 200, Loss 0.001126, Num updates: 200, Wall time: 2371.01, ETA: 0m 24s (- 0m 4s)
Evaluating...
epoch 41, time: 52.39
	train_loss: 0.0011, score: 49.89
	eval score: 386.04 (617.53)
Iter: 40, Loss 0.001093, Num updates: 40, Wall time: 2405.50, ETA: 0m 5s (- 0m 27s)
Iter: 80, Loss 0.001110, Num updates: 80, Wall time: 2410.58, ETA: 0m 10s (- 0m 20s)
Iter: 120, Loss 0.001115, Num updates: 120, Wall time: 2414.96, ETA: 0m 14s (- 0m 14s)
Iter: 160, Loss 0.001119, Num updates: 160, Wall time: 2419.74, ETA: 0m 19s (- 0m 9s)
Iter: 200, Loss 0.001120, Num updates: 200, Wall time: 2424.64, ETA: 0m 24s (- 0m 4s)
Evaluating...
epoch 42, time: 52.49
	train_loss: 0.0011, score: 49.97
	eval score: 393.18 (617.53)
Iter: 40, Loss 0.001087, Num updates: 40, Wall time: 2458.67, ETA: 0m 5s (- 0m 26s)
Iter: 80, Loss 0.001100, Num updates: 80, Wall time: 2463.16, ETA: 0m 9s (- 0m 19s)
Iter: 120, Loss 0.001106, Num updates: 120, Wall time: 2467.89, ETA: 0m 14s (- 0m 14s)
Iter: 160, Loss 0.001106, Num updates: 160, Wall time: 2472.62, ETA: 0m 19s (- 0m 9s)
Iter: 200, Loss 0.001109, Num updates: 200, Wall time: 2477.56, ETA: 0m 24s (- 0m 4s)
Evaluating...
epoch 43, time: 53.33
	train_loss: 0.0011, score: 49.38
	eval score: 395.45 (617.53)
Iter: 40, Loss 0.001071, Num updates: 40, Wall time: 2513.03, ETA: 0m 5s (- 0m 28s)
Iter: 80, Loss 0.001086, Num updates: 80, Wall time: 2517.72, ETA: 0m 10s (- 0m 20s)
Iter: 120, Loss 0.001099, Num updates: 120, Wall time: 2522.65, ETA: 0m 15s (- 0m 15s)
Iter: 160, Loss 0.001104, Num updates: 160, Wall time: 2527.41, ETA: 0m 19s (- 0m 9s)
Iter: 200, Loss 0.001106, Num updates: 200, Wall time: 2532.44, ETA: 0m 25s (- 0m 4s)
Evaluating...
epoch 44, time: 57.70
	train_loss: 0.0011, score: 50.34
	eval score: 390.26 (617.53)
Iter: 40, Loss 0.001080, Num updates: 40, Wall time: 2571.46, ETA: 0m 6s (- 0m 32s)
Iter: 80, Loss 0.001097, Num updates: 80, Wall time: 2576.25, ETA: 0m 11s (- 0m 22s)
Iter: 120, Loss 0.001098, Num updates: 120, Wall time: 2581.04, ETA: 0m 15s (- 0m 15s)
Iter: 160, Loss 0.001100, Num updates: 160, Wall time: 2585.84, ETA: 0m 20s (- 0m 10s)
Iter: 200, Loss 0.001099, Num updates: 200, Wall time: 2590.86, ETA: 0m 25s (- 0m 5s)
Evaluating...
epoch 45, time: 54.63
	train_loss: 0.0011, score: 49.56
	eval score: 392.53 (617.53)
Iter: 40, Loss 0.001070, Num updates: 40, Wall time: 2625.07, ETA: 0m 5s (- 0m 26s)
Iter: 80, Loss 0.001082, Num updates: 80, Wall time: 2629.82, ETA: 0m 10s (- 0m 20s)
Iter: 120, Loss 0.001082, Num updates: 120, Wall time: 2634.47, ETA: 0m 14s (- 0m 14s)
Iter: 160, Loss 0.001088, Num updates: 160, Wall time: 2639.04, ETA: 0m 19s (- 0m 9s)
Iter: 200, Loss 0.001091, Num updates: 200, Wall time: 2643.91, ETA: 0m 24s (- 0m 4s)
Evaluating...
epoch 46, time: 53.46
	train_loss: 0.0011, score: 49.44
	eval score: 395.45 (617.53)
Iter: 40, Loss 0.001096, Num updates: 40, Wall time: 2679.12, ETA: 0m 5s (- 0m 29s)
Iter: 80, Loss 0.001094, Num updates: 80, Wall time: 2684.41, ETA: 0m 11s (- 0m 22s)
Iter: 120, Loss 0.001091, Num updates: 120, Wall time: 2689.44, ETA: 0m 16s (- 0m 16s)
Iter: 160, Loss 0.001090, Num updates: 160, Wall time: 2694.60, ETA: 0m 21s (- 0m 10s)
Iter: 200, Loss 0.001094, Num updates: 200, Wall time: 2699.54, ETA: 0m 26s (- 0m 5s)
Evaluating...
epoch 47, time: 55.48
	train_loss: 0.0011, score: 49.18
	eval score: 393.51 (617.53)
Iter: 40, Loss 0.001062, Num updates: 40, Wall time: 2734.31, ETA: 0m 5s (- 0m 28s)
Iter: 80, Loss 0.001073, Num updates: 80, Wall time: 2738.90, ETA: 0m 10s (- 0m 20s)
Iter: 120, Loss 0.001083, Num updates: 120, Wall time: 2744.13, ETA: 0m 15s (- 0m 15s)
Iter: 160, Loss 0.001087, Num updates: 160, Wall time: 2748.98, ETA: 0m 20s (- 0m 10s)
Iter: 200, Loss 0.001091, Num updates: 200, Wall time: 2753.63, ETA: 0m 24s (- 0m 4s)
Evaluating...
epoch 48, time: 58.33
	train_loss: 0.0011, score: 48.56
	eval score: 392.53 (617.53)
Iter: 40, Loss 0.001054, Num updates: 40, Wall time: 2794.34, ETA: 0m 7s (- 0m 36s)
Iter: 80, Loss 0.001072, Num updates: 80, Wall time: 2799.49, ETA: 0m 12s (- 0m 24s)
Iter: 120, Loss 0.001072, Num updates: 120, Wall time: 2804.54, ETA: 0m 17s (- 0m 17s)
Iter: 160, Loss 0.001075, Num updates: 160, Wall time: 2809.83, ETA: 0m 22s (- 0m 11s)
Iter: 200, Loss 0.001077, Num updates: 200, Wall time: 2815.05, ETA: 0m 27s (- 0m 5s)
Evaluating...
epoch 49, time: 56.69
	train_loss: 0.0011, score: 49.71
	eval score: 393.83 (617.53)
Iter: 40, Loss 0.001059, Num updates: 40, Wall time: 2849.66, ETA: 0m 5s (- 0m 29s)
Iter: 80, Loss 0.001071, Num updates: 80, Wall time: 2854.44, ETA: 0m 10s (- 0m 21s)
Iter: 120, Loss 0.001078, Num updates: 120, Wall time: 2859.25, ETA: 0m 15s (- 0m 15s)
Iter: 160, Loss 0.001079, Num updates: 160, Wall time: 2864.00, ETA: 0m 20s (- 0m 10s)
Iter: 200, Loss 0.001079, Num updates: 200, Wall time: 2868.83, ETA: 0m 25s (- 0m 4s)
Evaluating...
epoch 50, time: 53.34
	train_loss: 0.0011, score: 49.61
	eval score: 397.08 (617.53)
Iter: 40, Loss 0.001050, Num updates: 40, Wall time: 2903.68, ETA: 0m 5s (- 0m 29s)
Iter: 80, Loss 0.001067, Num updates: 80, Wall time: 2908.71, ETA: 0m 10s (- 0m 21s)
Iter: 120, Loss 0.001074, Num updates: 120, Wall time: 2913.49, ETA: 0m 15s (- 0m 15s)
Iter: 160, Loss 0.001077, Num updates: 160, Wall time: 2918.26, ETA: 0m 20s (- 0m 10s)
Iter: 200, Loss 0.001078, Num updates: 200, Wall time: 2922.90, ETA: 0m 24s (- 0m 4s)
Evaluating...
epoch 51, time: 53.32
	train_loss: 0.0011, score: 48.32
	eval score: 400.32 (617.53)
Iter: 40, Loss 0.001051, Num updates: 40, Wall time: 2957.36, ETA: 0m 5s (- 0m 27s)
Iter: 80, Loss 0.001057, Num updates: 80, Wall time: 2962.37, ETA: 0m 10s (- 0m 21s)
Iter: 120, Loss 0.001062, Num updates: 120, Wall time: 2967.51, ETA: 0m 15s (- 0m 15s)
Iter: 160, Loss 0.001070, Num updates: 160, Wall time: 2972.66, ETA: 0m 20s (- 0m 10s)
Iter: 200, Loss 0.001068, Num updates: 200, Wall time: 2977.79, ETA: 0m 25s (- 0m 5s)
Evaluating...
epoch 52, time: 53.97
	train_loss: 0.0011, score: 49.03
	eval score: 398.38 (617.53)
Iter: 40, Loss 0.001043, Num updates: 40, Wall time: 3011.53, ETA: 0m 5s (- 0m 28s)
Iter: 80, Loss 0.001058, Num updates: 80, Wall time: 3016.49, ETA: 0m 10s (- 0m 21s)
Iter: 120, Loss 0.001063, Num updates: 120, Wall time: 3021.23, ETA: 0m 15s (- 0m 15s)
Iter: 160, Loss 0.001067, Num updates: 160, Wall time: 3025.99, ETA: 0m 20s (- 0m 9s)
Iter: 200, Loss 0.001067, Num updates: 200, Wall time: 3030.81, ETA: 0m 24s (- 0m 4s)
Evaluating...
epoch 53, time: 53.53
	train_loss: 0.0011, score: 48.63
	eval score: 401.62 (617.53)
Iter: 40, Loss 0.001041, Num updates: 40, Wall time: 3065.80, ETA: 0m 5s (- 0m 28s)
Iter: 80, Loss 0.001053, Num updates: 80, Wall time: 3070.96, ETA: 0m 10s (- 0m 21s)
Iter: 120, Loss 0.001060, Num updates: 120, Wall time: 3075.96, ETA: 0m 15s (- 0m 15s)
Iter: 160, Loss 0.001061, Num updates: 160, Wall time: 3080.93, ETA: 0m 20s (- 0m 10s)
Iter: 200, Loss 0.001063, Num updates: 200, Wall time: 3085.76, ETA: 0m 25s (- 0m 4s)
Evaluating...
epoch 54, time: 56.64
	train_loss: 0.0011, score: 49.08
	eval score: 402.92 (617.53)
Iter: 40, Loss 0.001036, Num updates: 40, Wall time: 3124.66, ETA: 0m 6s (- 0m 34s)
Iter: 80, Loss 0.001044, Num updates: 80, Wall time: 3129.67, ETA: 0m 11s (- 0m 23s)
Iter: 120, Loss 0.001051, Num updates: 120, Wall time: 3134.89, ETA: 0m 16s (- 0m 16s)
Iter: 160, Loss 0.001056, Num updates: 160, Wall time: 3139.99, ETA: 0m 22s (- 0m 10s)
Iter: 200, Loss 0.001060, Num updates: 200, Wall time: 3145.66, ETA: 0m 27s (- 0m 5s)
Evaluating...
epoch 55, time: 63.31
	train_loss: 0.0011, score: 48.79
	eval score: 399.03 (617.53)
Iter: 40, Loss 0.001025, Num updates: 40, Wall time: 3186.40, ETA: 0m 5s (- 0m 26s)
Iter: 80, Loss 0.001046, Num updates: 80, Wall time: 3191.44, ETA: 0m 10s (- 0m 20s)
Iter: 120, Loss 0.001052, Num updates: 120, Wall time: 3196.22, ETA: 0m 14s (- 0m 14s)
Iter: 160, Loss 0.001055, Num updates: 160, Wall time: 3200.97, ETA: 0m 19s (- 0m 9s)
Iter: 200, Loss 0.001058, Num updates: 200, Wall time: 3205.77, ETA: 0m 24s (- 0m 4s)
Evaluating...
epoch 56, time: 53.11
	train_loss: 0.0011, score: 48.40
	eval score: 401.95 (617.53)
Iter: 40, Loss 0.001032, Num updates: 40, Wall time: 3240.21, ETA: 0m 5s (- 0m 29s)
Iter: 80, Loss 0.001044, Num updates: 80, Wall time: 3245.48, ETA: 0m 11s (- 0m 22s)
Iter: 120, Loss 0.001052, Num updates: 120, Wall time: 3250.34, ETA: 0m 15s (- 0m 15s)
Iter: 160, Loss 0.001052, Num updates: 160, Wall time: 3255.16, ETA: 0m 20s (- 0m 10s)
Iter: 200, Loss 0.001056, Num updates: 200, Wall time: 3260.29, ETA: 0m 25s (- 0m 5s)
Evaluating...
epoch 57, time: 61.92
	train_loss: 0.0011, score: 48.90
	eval score: 400.97 (617.53)
Iter: 40, Loss 0.001023, Num updates: 40, Wall time: 3303.27, ETA: 0m 6s (- 0m 35s)
Iter: 80, Loss 0.001044, Num updates: 80, Wall time: 3309.13, ETA: 0m 12s (- 0m 25s)
Iter: 120, Loss 0.001050, Num updates: 120, Wall time: 3315.35, ETA: 0m 19s (- 0m 19s)
Iter: 160, Loss 0.001053, Num updates: 160, Wall time: 3320.90, ETA: 0m 24s (- 0m 12s)
Iter: 200, Loss 0.001053, Num updates: 200, Wall time: 3326.65, ETA: 0m 30s (- 0m 5s)
Evaluating...
epoch 58, time: 59.97
	train_loss: 0.0011, score: 48.53
	eval score: 400.32 (617.53)
Iter: 40, Loss 0.001020, Num updates: 40, Wall time: 3362.21, ETA: 0m 5s (- 0m 30s)
Iter: 80, Loss 0.001044, Num updates: 80, Wall time: 3367.11, ETA: 0m 10s (- 0m 21s)
Iter: 120, Loss 0.001045, Num updates: 120, Wall time: 3372.02, ETA: 0m 15s (- 0m 15s)
Iter: 160, Loss 0.001043, Num updates: 160, Wall time: 3376.68, ETA: 0m 20s (- 0m 10s)
Iter: 200, Loss 0.001047, Num updates: 200, Wall time: 3381.10, ETA: 0m 24s (- 0m 4s)
Evaluating...
epoch 59, time: 53.24
	train_loss: 0.0011, score: 48.90
	eval score: 406.82 (617.53)
Iter: 40, Loss 0.001014, Num updates: 40, Wall time: 3416.21, ETA: 0m 5s (- 0m 28s)
Iter: 80, Loss 0.001032, Num updates: 80, Wall time: 3421.08, ETA: 0m 10s (- 0m 21s)
Iter: 120, Loss 0.001039, Num updates: 120, Wall time: 3425.89, ETA: 0m 15s (- 0m 15s)
Iter: 160, Loss 0.001046, Num updates: 160, Wall time: 3430.95, ETA: 0m 20s (- 0m 10s)
Iter: 200, Loss 0.001047, Num updates: 200, Wall time: 3435.51, ETA: 0m 24s (- 0m 4s)
Evaluating...
epoch 60, time: 53.09
	train_loss: 0.0011, score: 48.92
	eval score: 405.19 (617.53)
Iter: 40, Loss 0.001023, Num updates: 40, Wall time: 3469.41, ETA: 0m 5s (- 0m 29s)
Iter: 80, Loss 0.001033, Num updates: 80, Wall time: 3474.50, ETA: 0m 10s (- 0m 21s)
Iter: 120, Loss 0.001041, Num updates: 120, Wall time: 3479.03, ETA: 0m 15s (- 0m 15s)
Iter: 160, Loss 0.001042, Num updates: 160, Wall time: 3483.82, ETA: 0m 20s (- 0m 9s)
Iter: 200, Loss 0.001047, Num updates: 200, Wall time: 3488.53, ETA: 0m 24s (- 0m 4s)
Evaluating...
epoch 61, time: 53.39
	train_loss: 0.0011, score: 48.91
	eval score: 400.65 (617.53)
Iter: 40, Loss 0.001020, Num updates: 40, Wall time: 3522.46, ETA: 0m 5s (- 0m 27s)
Iter: 80, Loss 0.001039, Num updates: 80, Wall time: 3527.08, ETA: 0m 9s (- 0m 20s)
Iter: 120, Loss 0.001042, Num updates: 120, Wall time: 3532.15, ETA: 0m 15s (- 0m 15s)
Iter: 160, Loss 0.001043, Num updates: 160, Wall time: 3537.13, ETA: 0m 20s (- 0m 9s)
Iter: 200, Loss 0.001043, Num updates: 200, Wall time: 3541.83, ETA: 0m 24s (- 0m 4s)
Evaluating...
epoch 62, time: 53.15
	train_loss: 0.0010, score: 48.29
	eval score: 404.55 (617.53)
Iter: 40, Loss 0.001003, Num updates: 40, Wall time: 3575.74, ETA: 0m 5s (- 0m 27s)
Iter: 80, Loss 0.001012, Num updates: 80, Wall time: 3580.63, ETA: 0m 10s (- 0m 20s)
Iter: 120, Loss 0.001021, Num updates: 120, Wall time: 3585.71, ETA: 0m 15s (- 0m 15s)
Iter: 160, Loss 0.001031, Num updates: 160, Wall time: 3590.44, ETA: 0m 20s (- 0m 10s)
Iter: 200, Loss 0.001036, Num updates: 200, Wall time: 3595.19, ETA: 0m 24s (- 0m 4s)
Evaluating...
epoch 63, time: 53.76
	train_loss: 0.0010, score: 48.72
	eval score: 409.42 (617.53)
Iter: 40, Loss 0.001014, Num updates: 40, Wall time: 3629.83, ETA: 0m 5s (- 0m 26s)
Iter: 80, Loss 0.001028, Num updates: 80, Wall time: 3634.65, ETA: 0m 9s (- 0m 19s)
Iter: 120, Loss 0.001030, Num updates: 120, Wall time: 3639.41, ETA: 0m 14s (- 0m 14s)
Iter: 160, Loss 0.001035, Num updates: 160, Wall time: 3644.15, ETA: 0m 19s (- 0m 9s)
Iter: 200, Loss 0.001038, Num updates: 200, Wall time: 3648.62, ETA: 0m 23s (- 0m 4s)
Evaluating...
epoch 64, time: 52.45
	train_loss: 0.0010, score: 48.75
	eval score: 409.09 (617.53)
Iter: 40, Loss 0.001006, Num updates: 40, Wall time: 3682.62, ETA: 0m 5s (- 0m 27s)
Iter: 80, Loss 0.001022, Num updates: 80, Wall time: 3687.61, ETA: 0m 10s (- 0m 20s)
Iter: 120, Loss 0.001024, Num updates: 120, Wall time: 3692.22, ETA: 0m 15s (- 0m 15s)
Iter: 160, Loss 0.001030, Num updates: 160, Wall time: 3697.25, ETA: 0m 20s (- 0m 9s)
Iter: 200, Loss 0.001033, Num updates: 200, Wall time: 3702.17, ETA: 0m 24s (- 0m 4s)
Evaluating...
epoch 65, time: 45.23
	train_loss: 0.0010, score: 48.31
	eval score: 410.71 (617.53)
Iter: 40, Loss 0.001004, Num updates: 40, Wall time: 3726.91, ETA: 0m 3s (- 0m 19s)
Iter: 80, Loss 0.001025, Num updates: 80, Wall time: 3730.01, ETA: 0m 6s (- 0m 13s)
Iter: 120, Loss 0.001034, Num updates: 120, Wall time: 3733.09, ETA: 0m 10s (- 0m 10s)
Iter: 160, Loss 0.001034, Num updates: 160, Wall time: 3736.38, ETA: 0m 13s (- 0m 6s)
Iter: 200, Loss 0.001035, Num updates: 200, Wall time: 3739.44, ETA: 0m 16s (- 0m 3s)
Evaluating...
epoch 66, time: 29.97
	train_loss: 0.0010, score: 48.81
	eval score: 411.36 (617.53)
Iter: 40, Loss 0.001011, Num updates: 40, Wall time: 3756.76, ETA: 0m 3s (- 0m 16s)
Iter: 80, Loss 0.001023, Num updates: 80, Wall time: 3760.19, ETA: 0m 6s (- 0m 13s)
Iter: 120, Loss 0.001027, Num updates: 120, Wall time: 3763.35, ETA: 0m 9s (- 0m 9s)
Iter: 160, Loss 0.001028, Num updates: 160, Wall time: 3766.41, ETA: 0m 12s (- 0m 6s)
Iter: 200, Loss 0.001031, Num updates: 200, Wall time: 3769.75, ETA: 0m 16s (- 0m 3s)
Evaluating...
epoch 67, time: 29.57
	train_loss: 0.0010, score: 48.36
	eval score: 408.12 (617.53)
Iter: 40, Loss 0.001015, Num updates: 40, Wall time: 3786.67, ETA: 0m 3s (- 0m 18s)
Iter: 80, Loss 0.001022, Num updates: 80, Wall time: 3789.92, ETA: 0m 6s (- 0m 13s)
Iter: 120, Loss 0.001027, Num updates: 120, Wall time: 3793.36, ETA: 0m 10s (- 0m 10s)
Iter: 160, Loss 0.001030, Num updates: 160, Wall time: 3796.24, ETA: 0m 13s (- 0m 6s)
Iter: 200, Loss 0.001030, Num updates: 200, Wall time: 3799.48, ETA: 0m 16s (- 0m 3s)
Evaluating...
epoch 68, time: 30.35
	train_loss: 0.0010, score: 48.47
	eval score: 411.69 (617.53)
Iter: 40, Loss 0.001012, Num updates: 40, Wall time: 3818.24, ETA: 0m 3s (- 0m 17s)
Iter: 80, Loss 0.001022, Num updates: 80, Wall time: 3821.55, ETA: 0m 6s (- 0m 13s)
Iter: 120, Loss 0.001025, Num updates: 120, Wall time: 3824.70, ETA: 0m 9s (- 0m 9s)
Iter: 160, Loss 0.001031, Num updates: 160, Wall time: 3827.74, ETA: 0m 12s (- 0m 6s)
Iter: 200, Loss 0.001031, Num updates: 200, Wall time: 3830.89, ETA: 0m 15s (- 0m 3s)
Evaluating...
epoch 69, time: 29.78
	train_loss: 0.0010, score: 48.05
	eval score: 403.90 (617.53)
Iter: 40, Loss 0.001001, Num updates: 40, Wall time: 3848.20, ETA: 0m 3s (- 0m 17s)
Iter: 80, Loss 0.001018, Num updates: 80, Wall time: 3851.64, ETA: 0m 6s (- 0m 14s)
Iter: 120, Loss 0.001024, Num updates: 120, Wall time: 3854.63, ETA: 0m 9s (- 0m 9s)
Iter: 160, Loss 0.001023, Num updates: 160, Wall time: 3858.06, ETA: 0m 13s (- 0m 6s)
Iter: 200, Loss 0.001025, Num updates: 200, Wall time: 3861.04, ETA: 0m 16s (- 0m 3s)
Evaluating...
epoch 70, time: 29.67
	train_loss: 0.0010, score: 48.77
	eval score: 404.87 (617.53)
Iter: 40, Loss 0.001001, Num updates: 40, Wall time: 3877.95, ETA: 0m 3s (- 0m 18s)
Iter: 80, Loss 0.001016, Num updates: 80, Wall time: 3880.77, ETA: 0m 6s (- 0m 12s)
Iter: 120, Loss 0.001020, Num updates: 120, Wall time: 3883.96, ETA: 0m 9s (- 0m 9s)
Iter: 160, Loss 0.001021, Num updates: 160, Wall time: 3887.07, ETA: 0m 12s (- 0m 6s)
Iter: 200, Loss 0.001023, Num updates: 200, Wall time: 3890.01, ETA: 0m 15s (- 0m 3s)
Evaluating...
epoch 71, time: 29.30
	train_loss: 0.0010, score: 48.08
	eval score: 411.36 (617.53)
Iter: 40, Loss 0.001000, Num updates: 40, Wall time: 3907.48, ETA: 0m 3s (- 0m 19s)
Iter: 80, Loss 0.001012, Num updates: 80, Wall time: 3910.56, ETA: 0m 6s (- 0m 13s)
Iter: 120, Loss 0.001020, Num updates: 120, Wall time: 3913.87, ETA: 0m 10s (- 0m 10s)
Iter: 160, Loss 0.001021, Num updates: 160, Wall time: 3917.07, ETA: 0m 13s (- 0m 6s)
Iter: 200, Loss 0.001024, Num updates: 200, Wall time: 3920.09, ETA: 0m 16s (- 0m 3s)
Evaluating...
epoch 72, time: 29.94
	train_loss: 0.0010, score: 47.79
	eval score: 403.90 (617.53)
Iter: 40, Loss 0.001004, Num updates: 40, Wall time: 3937.23, ETA: 0m 3s (- 0m 18s)
Iter: 80, Loss 0.001012, Num updates: 80, Wall time: 3940.09, ETA: 0m 6s (- 0m 13s)
Iter: 120, Loss 0.001023, Num updates: 120, Wall time: 3943.54, ETA: 0m 9s (- 0m 9s)
Iter: 160, Loss 0.001023, Num updates: 160, Wall time: 3946.78, ETA: 0m 13s (- 0m 6s)
Iter: 200, Loss 0.001023, Num updates: 200, Wall time: 3950.00, ETA: 0m 16s (- 0m 3s)
Evaluating...
epoch 73, time: 29.90
	train_loss: 0.0010, score: 47.66
	eval score: 401.62 (617.53)
Iter: 40, Loss 0.000998, Num updates: 40, Wall time: 3967.65, ETA: 0m 4s (- 0m 21s)
Iter: 80, Loss 0.001016, Num updates: 80, Wall time: 3971.03, ETA: 0m 7s (- 0m 15s)
Iter: 120, Loss 0.001019, Num updates: 120, Wall time: 3974.23, ETA: 0m 10s (- 0m 10s)
Iter: 160, Loss 0.001020, Num updates: 160, Wall time: 3977.40, ETA: 0m 13s (- 0m 6s)
Iter: 200, Loss 0.001018, Num updates: 200, Wall time: 3980.47, ETA: 0m 16s (- 0m 3s)
Evaluating...
epoch 74, time: 30.72
	train_loss: 0.0010, score: 48.00
	eval score: 413.64 (617.53)
Iter: 40, Loss 0.000994, Num updates: 40, Wall time: 3998.28, ETA: 0m 3s (- 0m 17s)
Iter: 80, Loss 0.001010, Num updates: 80, Wall time: 4001.47, ETA: 0m 6s (- 0m 13s)
Iter: 120, Loss 0.001016, Num updates: 120, Wall time: 4004.66, ETA: 0m 9s (- 0m 9s)
Iter: 160, Loss 0.001020, Num updates: 160, Wall time: 4007.91, ETA: 0m 12s (- 0m 6s)
Iter: 200, Loss 0.001022, Num updates: 200, Wall time: 4011.00, ETA: 0m 16s (- 0m 3s)
Evaluating...
epoch 75, time: 29.87
	train_loss: 0.0010, score: 47.29
	eval score: 410.39 (617.53)
Iter: 40, Loss 0.001003, Num updates: 40, Wall time: 4028.52, ETA: 0m 3s (- 0m 18s)
Iter: 80, Loss 0.001004, Num updates: 80, Wall time: 4031.75, ETA: 0m 6s (- 0m 13s)
Iter: 120, Loss 0.001010, Num updates: 120, Wall time: 4034.89, ETA: 0m 10s (- 0m 10s)
Iter: 160, Loss 0.001012, Num updates: 160, Wall time: 4038.10, ETA: 0m 13s (- 0m 6s)
Iter: 200, Loss 0.001017, Num updates: 200, Wall time: 4041.31, ETA: 0m 16s (- 0m 3s)
Evaluating...
epoch 76, time: 29.97
	train_loss: 0.0010, score: 48.26
	eval score: 408.12 (617.53)
Iter: 40, Loss 0.000984, Num updates: 40, Wall time: 4058.65, ETA: 0m 3s (- 0m 19s)
Iter: 80, Loss 0.001000, Num updates: 80, Wall time: 4062.27, ETA: 0m 7s (- 0m 15s)
Iter: 120, Loss 0.001007, Num updates: 120, Wall time: 4065.08, ETA: 0m 10s (- 0m 10s)
Iter: 160, Loss 0.001008, Num updates: 160, Wall time: 4068.34, ETA: 0m 13s (- 0m 6s)
Iter: 200, Loss 0.001011, Num updates: 200, Wall time: 4071.55, ETA: 0m 16s (- 0m 3s)
Evaluating...
epoch 77, time: 30.29
	train_loss: 0.0010, score: 47.99
	eval score: 414.94 (617.53)
Iter: 40, Loss 0.000989, Num updates: 40, Wall time: 4088.98, ETA: 0m 3s (- 0m 16s)
Iter: 80, Loss 0.001000, Num updates: 80, Wall time: 4092.16, ETA: 0m 6s (- 0m 12s)
Iter: 120, Loss 0.001002, Num updates: 120, Wall time: 4095.54, ETA: 0m 9s (- 0m 9s)
Iter: 160, Loss 0.001005, Num updates: 160, Wall time: 4098.63, ETA: 0m 12s (- 0m 6s)
Iter: 200, Loss 0.001009, Num updates: 200, Wall time: 4101.93, ETA: 0m 16s (- 0m 3s)
Evaluating...
epoch 78, time: 29.73
	train_loss: 0.0010, score: 47.81
	eval score: 408.12 (617.53)
Iter: 40, Loss 0.000993, Num updates: 40, Wall time: 4118.68, ETA: 0m 3s (- 0m 16s)
Iter: 80, Loss 0.001005, Num updates: 80, Wall time: 4121.90, ETA: 0m 6s (- 0m 12s)
Iter: 120, Loss 0.001008, Num updates: 120, Wall time: 4125.09, ETA: 0m 9s (- 0m 9s)
Iter: 160, Loss 0.001012, Num updates: 160, Wall time: 4128.07, ETA: 0m 12s (- 0m 6s)
Iter: 200, Loss 0.001014, Num updates: 200, Wall time: 4131.50, ETA: 0m 16s (- 0m 3s)
Evaluating...
epoch 79, time: 29.19
	train_loss: 0.0010, score: 47.59
	eval score: 407.14 (617.53)
0.00601,0.00186,0.00176,0.00171,0.00167,0.00165,0.00163,0.0016,0.00159,0.00157,0.00156,0.00154,0.00153,0.00151,0.0015,0.00148,0.00147,0.00146,0.00145,0.00143,0.00141,0.00139,0.00137,0.00136,0.00134,0.00132,0.00131,0.00129,0.00128,0.00126,0.00125,0.00123,0.00122,0.00121,0.00119,0.00118,0.00117,0.00116,0.00115,0.00115,0.00114,0.00113,0.00113,0.00112,0.00111,0.00111,0.0011,0.0011,0.0011,0.00109,0.00108,0.00108,0.00108,0.00107,0.00107,0.00107,0.00106,0.00106,0.00106,0.00105,0.00105,0.00105,0.00105,0.00104,0.00104,0.00104,0.00104,0.00104,0.00103,0.00104,0.00103,0.00103,0.00103,0.00103,0.00102,0.00103,0.00102,0.00102,0.00102,0.00102
0.02454,0.0238,0.02264,0.02183,0.022,0.02205,0.02142,0.02093,0.02179,0.02075,0.02083,0.02169,0.02208,0.02087,0.02054,0.02051,0.02053,0.01979,0.02027,0.02021,0.02019,0.01984,0.01989,0.02045,0.01942,0.02012,0.01998,0.01946,0.01952,0.02,0.01981,0.01905,0.01988,0.02017,0.0197,0.01928,0.01891,0.01985,0.02056,0.02031,0.01983,0.02025,0.02067,0.02039,0.02024,0.02106,0.02101,0.02184,0.02103,0.02171,0.02239,0.02085,0.02097,0.02201,0.02174,0.02169,0.02264,0.02274,0.02199,0.0221,0.02207,0.02197,0.02229,0.02216,0.02192,0.0221,0.02228,0.0234,0.02288,0.02272,0.02305,0.02237,0.02229,0.0237,0.02216,0.02245,0.02219,0.02144,0.02281,0.02303
